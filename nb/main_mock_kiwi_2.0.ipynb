{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyrr\n",
    "import itertools\n",
    "\n",
    "# basedir = os.path.dirname(os.getcwd())\n",
    "basedir = os.path.abspath(os.path.join(os.getcwd() ,\"../\"))\n",
    "_py = os.path.join(basedir, 'py')\n",
    "_data = os.path.join(basedir, 'data')\n",
    "\n",
    "sys.path.insert(1, _py)\n",
    "import loads\n",
    "import lia\n",
    "import ray as rayt\n",
    "import lad\n",
    "import figures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `downsample` is not `None`, a random downsampling will be implemented. If `None`, the pipeline will use the voxel-based downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# mockname = 'test_kiwi_2'\n",
    "mockname = 'test_simple'\n",
    "voxel_size = 0.05\n",
    "downsample = None\n",
    "# downsample = 0.5\n",
    "\n",
    "Nleaves = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree and leaves segmentation\n",
    "\n",
    "Now we create the module to segmentate trees. This will be tuned acordingly for each data set, so below module only works for this particular data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segtree(df, leaves, show=False):\n",
    "\n",
    "    trees = {}\n",
    "\n",
    "    if show:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # centres\n",
    "    x, y = [0], [0]\n",
    "    num = 0\n",
    "    dx, dy = 2, 2\n",
    "    # dx, dy = 5, 5\n",
    "\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            \n",
    "            keep = np.ones(len(df['x']), dtype=bool)\n",
    "            keep &= (df['x'] < i+dx) & (df['x'] > i-dx)\n",
    "            keep &= (df['y'] < j+dy) & (df['y'] > j-dy)\n",
    "\n",
    "            trees['tree_%s' %(str(num))] = keep\n",
    "            \n",
    "            if show:\n",
    "                plt.scatter(df['x'][leaves & keep], df['y'][leaves & keep], s=0.5, label=num)\n",
    "                        \n",
    "            num += 1\n",
    "\n",
    "    if show:\n",
    "        plt.legend()\n",
    "    \n",
    "    return trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We segmentate the trees below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cover `numpy` to `npy`\n",
    "loads.numpy2npy(mockname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 1\n",
      "160000\n"
     ]
    }
   ],
   "source": [
    "# load data into a pandas data frame\n",
    "df = loads.npy2pandas(mockname)\n",
    "N = len(df)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def voxel_subsampling(voxel_size, POINTS):\n",
    "\n",
    "    nb_vox = np.ceil((np.max(POINTS, axis=0) - np.min(POINTS, axis=0))/voxel_size)\n",
    "    ni, nj, nk = nb_vox\n",
    "    print('min point:', np.min(POINTS, axis=0))\n",
    "    print('max point:', np.max(POINTS, axis=0))\n",
    "    print('Number of voxels: i:%d, j:%d, k:%d --> Total: %d' %(ni, nj, nk, np.product(nb_vox)))\n",
    "\n",
    "    non_empty_voxel_keys, inverse, nb_pts_per_voxel = np.unique(((POINTS - np.min(POINTS, axis=0)) // voxel_size).astype(int), axis=0, return_inverse=True, return_counts=True)\n",
    "    idx_pts_vox_sorted = np.argsort(inverse)\n",
    "    print('Number of non-empty voxels: %d' %(len(non_empty_voxel_keys)))\n",
    "\n",
    "    voxel_grid={}\n",
    "    voxel_grid_ptsidx = {}\n",
    "    grid_barycenter,grid_candidate_center = [], []\n",
    "    last_seen=0\n",
    "\n",
    "    for idx, vox in enumerate(non_empty_voxel_keys):\n",
    "\n",
    "        idxs_per_vox = idx_pts_vox_sorted[last_seen:last_seen+nb_pts_per_voxel[idx]]\n",
    "        voxel_grid[tuple(vox)] = POINTS[idxs_per_vox]\n",
    "        voxel_grid_ptsidx[tuple(vox)] = idxs_per_vox\n",
    "\n",
    "        # grid_barycenter.append(np.mean(voxel_grid[tuple(vox)],axis=0))\n",
    "\n",
    "        idx_grid_candidate_center = np.linalg.norm(voxel_grid[tuple(vox)] - np.mean(voxel_grid[tuple(vox)],axis=0),axis=1).argmin()\n",
    "        grid_candidate_center.append(voxel_grid_ptsidx[tuple(vox)][idx_grid_candidate_center])\n",
    "\n",
    "        last_seen+=nb_pts_per_voxel[idx]\n",
    "\n",
    "    # print('Downsampling percentage: %.1f %%' %(100 * len(grid_candidate_center) / len(POINTS)))\n",
    "    # minpoint = np.min(POINTS, axis=0)\n",
    "\n",
    "    return list(grid_candidate_center) #, minpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_downsample(N, downsample):\n",
    "\n",
    "    resdir = os.path.join(_data, mockname, 'random_%s' %(str(downsample)))\n",
    "    if not os.path.exists(resdir):\n",
    "        os.makedirs(resdir)\n",
    "\n",
    "    outdir = os.path.join(resdir, 'inds.npy')\n",
    "    if os.path.exists(outdir):\n",
    "        print('inds file already exists for donwnsample of %.3f at %s' %(downsample, outdir))\n",
    "\n",
    "        idx = np.load(outdir)\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('inds not been created yet for donwnsample of %.3f' %(downsample))\n",
    "        idx = np.random.randint(0, N, int(N * downsample))\n",
    "        # inds = np.zeros(N, dtype=bool)\n",
    "        # inds[idx] = True\n",
    "\n",
    "        np.save(outdir, idx)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement and keep Downsampled points\n",
    "\n",
    "Below code will implement a downsampling using either `random` or `voxel`. The donsampling is performed by saving the corresponding indexes list of the downsampled percentage from the original data size. If index list already exists we just take it to make the downsampling, if it does not exist yet, we created and save ir under its corresponding directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min point: [-5.00000525e+00 -3.05086732e+00  6.78168490e-08]\n",
      "max point: [10.          3.03561211  8.62389851]\n",
      "Number of voxels: i:301, j:122, k:173 --> Total: 6352906\n",
      "Number of non-empty voxels: 17829\n",
      "Voxel downsampling...\n",
      "Downsampling percentage: 11.1 %\n",
      "minpoint: [-5.00000429e+00 -3.03243113e+00  7.05785340e-07]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if downsample is not None:\n",
    "    inds = random_downsample(N, downsample)\n",
    "    print('Random downsampling...')\n",
    "else:\n",
    "    inds = voxel_subsampling(voxel_size, df[['x', 'y', 'z']].to_numpy())\n",
    "    print('Voxel downsampling...')\n",
    "\n",
    "print('Downsampling percentage: %.1f %%' %(100 *  len(inds) / len(df['x'])))\n",
    "\n",
    "df = df.iloc[inds]\n",
    "POINTS = df[['x', 'y', 'z']].to_numpy()\n",
    "SENSORS = df[['sx', 'sy', 'sz']].to_numpy()\n",
    "\n",
    "# Compute lower point\n",
    "minpoint = np.min(POINTS, axis=0) # check this...\n",
    "print('minpoint:', minpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "leaves = np.ones(len(df), dtype=bool)\n",
    "for i in ['x', 'y']:\n",
    "    leaves &= (df[i] > -1) & (df[i] < 1)\n",
    "\n",
    "# print(len(df), np.sum(leaves))\n",
    "loads.showPCfromDF(df[['x', 'y', 'z']][leaves])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leave and tree segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract leaves. Boolean array output\n",
    "# leaves = loads.extract_leaves(df, show=True)\n",
    "# extract trees. Dictionary with boolean arrays output\n",
    "trees = segtree(df, leaves, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "loads.showPCfromDF(df[['x', 'y', 'z']][trees['tree_0']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second downsampling: keep only points that colide with Plant Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "inPR = (leaves) & (trees['tree_0'])\n",
    "minBB, maxBB = np.min(POINTS[inPR.values], axis=0), np.max(POINTS[inPR.values], axis=0)\n",
    "\n",
    "# Make sure Plant Region min & max points are multiples of voxel size\n",
    "# to match first voxelization where we implemented the downsampling\n",
    "minpointPR = minpoint + np.floor(np.abs(minpoint - minBB)/voxel_size) * voxel_size\n",
    "maxpointPR = minpoint + np.ceil(np.abs(minpoint - maxBB)/voxel_size) * voxel_size\n",
    "\n",
    "boxPR = pyrr.aabb.create_from_bounds(minpointPR, maxpointPR)\n",
    "\n",
    "lines = np.stack((POINTS, SENSORS), axis=1)\n",
    "f = lambda line: pyrr.geometric_tests.ray_intersect_aabb(pyrr.ray.create_from_line(line), boxPR) is not None\n",
    "res = np.array(list(map(f, lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "POINTS, SENSORS = POINTS[res], SENSORS[res]\n",
    "\n",
    "leaves = leaves[res]\n",
    "\n",
    "for key, val in trees.items():\n",
    "    trees[key] = val[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save indexes of voxel-based downsample\n",
    "\n",
    "idxs = np.array(inds)[res]\n",
    "\n",
    "if downsample is not None:\n",
    "    dirname = 'random_%s' %(str(downsample))\n",
    "    resdir = os.path.join(_data, mockname, dirname, 'lad_%s' %(str(voxel_size)))\n",
    "else:\n",
    "    dirname = 'voxel'\n",
    "    resdir = os.path.join(_data, mockname, dirname, 'lad_%s' %(str(voxel_size)))\n",
    "\n",
    "if not os.path.exists(resdir): os.makedirs(resdir)\n",
    "outdir = os.path.join(resdir, 'inds.npy')\n",
    "np.save(outdir, idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# iter... 12051\n",
      "Results will be saved at /Users/omar/projects/planttech/data/test_simple/voxel/lad_0.05\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12051it [03:06, 64.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 101680\n",
      "voxels hitted: \t 60700\n",
      "Percentage of voxels hitted by beam: 0.60\n",
      "voxels hitted (OLD): \t 0\n",
      "Percentage of voxels hitted by beam (OLD): 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sample = None\n",
    "\n",
    "inPR = (leaves) & (trees['tree_0'])\n",
    "\n",
    "if sample is not None:\n",
    "    print('# iter...', len(POINTS[::sample]))\n",
    "    m3s = rayt.main2(POINTS[::sample], SENSORS[::sample], POINTS[inPR], voxel_size, resdir, 'tree_0', (minpointPR, maxpointPR), show=True)\n",
    "else:\n",
    "    print('# iter...', len(POINTS))\n",
    "    print('Results will be saved at %s' %(resdir))\n",
    "    print('-------------')\n",
    "    m3s = rayt.main2(POINTS, SENSORS, POINTS[inPR], voxel_size, resdir, 'tree_0', (minpointPR, maxpointPR), show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inPR = (leaves) & (trees['tree_0'])\n",
    "# resdir = os.path.join(_data, mockname, 'lad_%s' %(str(voxel_size)))\n",
    "NI, N0, NP0, NP = lad.get_attributes_per_k(POINTS[inPR], voxel_size, (minpointPR, maxpointPR), 'tree_0', kval=2, resdir=resdir, showall=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_fit_lia(mockname, Nleaves):\n",
    "\n",
    "    df = loads.npy2pandas(mockname)\n",
    "    # extract leaves. Boolean array output\n",
    "    \n",
    "    # leaves = loads.extract_leaves(df, show=False)\n",
    "    leaves = np.ones(len(df), dtype=bool)\n",
    "    for i in ['x', 'y']:\n",
    "        leaves &= (df[i] > -1) & (df[i] < 1)\n",
    "\n",
    "    # extract trees. Dictionary with boolean arrays output\n",
    "    trees = segtree(df, leaves, show=False)\n",
    "\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        keep = (val) & (leaves) # take the LPC per tree\n",
    "        points = df[['x', 'y', 'z']].to_numpy()[keep]\n",
    "\n",
    "        res = lia.bestfit_pars_la(points, mockname, Nleaves, treename=key)\n",
    "        lia.best_fit_pars_plot(res, key, mockname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lia(mockname):\n",
    "\n",
    "    df = loads.npy2pandas(mockname)\n",
    "\n",
    "    # extract leaves. Boolean array output\n",
    "\n",
    "    # leaves = loads.extract_leaves(df, show=False)\n",
    "    leaves = np.ones(len(df), dtype=bool)\n",
    "    for i in ['x', 'y']:\n",
    "        leaves &= (df[i] > -1) & (df[i] < 1)\n",
    "\n",
    "    # extract trees. Dictionary with boolean arrays output\n",
    "    trees = segtree(df, leaves, show=False)\n",
    "\n",
    "\n",
    "    # load bestfit results\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        keep = (val) & (leaves)\n",
    "        print(sum(keep), len(keep))\n",
    "        points = df[['x', 'y', 'z']].to_numpy()[keep]\n",
    "    \n",
    "        bestfit_file = os.path.join(_data, mockname, 'lia', 'bestfit_%s.npy' %(key))\n",
    "        res = np.load(bestfit_file, allow_pickle=True)\n",
    "        res = res.tolist()\n",
    "\n",
    "        text = 'leaf area=%.2f \\n %s=%.4f \\n %s=%.4f \\n %s=%.4f ' %(res['leafsize'], 'voxel_size_w', res['voxel_size_w_bestfit'],'kd3_sr', res['kd3_sr_bestfit'],'max_nn', res['max_nn_bestfit'])\n",
    "        print(text)\n",
    "\n",
    "        chi2 = lia.leaf_angle(points, mockname, key, res['voxel_size_w_bestfit'], \n",
    "                                res['kd3_sr_bestfit'], res['max_nn_bestfit'], save=True,\n",
    "                                    savefig=True, text=text, voxel_size_h=0.1)\n",
    "\n",
    "        # save indexes from main df\n",
    "        # inds = np.where((val) & (leaves))\n",
    "        np.save(os.path.join(_data, mockname, 'lia', 'inds.npy'), keep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# Check we have a mesh\n",
    "meshfile = os.path.join(_data, mockname, 'mesh.ply')\n",
    "lad.see_mesh(meshfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 1\n",
      "voxel_size_w 0.0001 DONE...\n",
      "voxel_size_w 0.001 DONE...\n",
      "voxel_size_w 0.01 DONE...\n",
      "voxel_size_w 0.1 DONE...\n",
      "voxel_size_w 1 DONE...\n",
      "voxel_size_w BESTFIT:\t 1.0\n",
      "kd3_sr 0.001 DONE...\n",
      "kd3_sr 0.01 DONE...\n",
      "kd3_sr 0.1 DONE...\n",
      "kd3_sr 1.0 DONE...\n",
      "kd3_sr BESTFIT:\t 0.01\n",
      "max_nn 3 DONE...\n",
      "max_nn 5 DONE...\n",
      "max_nn 10 DONE...\n",
      "max_nn 20 DONE...\n",
      "max_nn 50 DONE...\n",
      "max_nn 100 DONE...\n",
      "max_nn BESTFIT:\t 3\n"
     ]
    }
   ],
   "source": [
    "best_fit_lia(mockname, Nleaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 1\n",
      "30223 160000\n",
      "leaf area=4.00 \n",
      " voxel_size_w=1.0000 \n",
      " kd3_sr=0.0100 \n",
      " max_nn=3.0000 \n"
     ]
    }
   ],
   "source": [
    "get_lia(mockname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runall(pointsPR, sensorsPR, inPR, voxel_size, tree, N, PRbounds, resdir, kbins=None):\n",
    "\n",
    "    # resdir = os.path.join(_data, mockname, 'lad_%s' %(str(voxel_size)))\n",
    "    inds_file = os.path.join(resdir, 'inds.npy')\n",
    "    inds0 = np.load(inds_file)\n",
    "\n",
    "    # resdir = os.path.join(_data, mockname, 'lad_%s' %(str(voxel_size)))\n",
    "\n",
    "    inds_lia = np.load(os.path.join(_data, mockname, 'lia', 'inds.npy'))\n",
    "\n",
    "    isfigures = os.path.join(resdir, 'figures')\n",
    "    if not os.path.exists(isfigures):\n",
    "        os.makedirs(isfigures)\n",
    "\n",
    "    attributes2_file = os.path.join(resdir, 'm3s_%s_%s.npy' %(tree, str(voxel_size)))\n",
    "    if os.path.isfile(attributes2_file):\n",
    "        m3b = np.load(attributes2_file)\n",
    "\n",
    "    print('voxel_size:', voxel_size)\n",
    "\n",
    "    # m3att = lad.compute_attributes(pointsPR, resdir, voxel_size, tree, PRbounds)\n",
    "\n",
    "    # _,_,_, m3scount = lad.density_counts(pointsPR, voxel_size)\n",
    "\n",
    "    # Load LIAs and its weights saved at `get_lia()`.\n",
    "    # Size of lias and ws arrays is the original size after leaf and tree extraction only.\n",
    "    lias, ws = loads.load_lias_ws(mockname, 'tree_0')\n",
    "\n",
    "    # Create  arrays of original size filled with -99\n",
    "    lias0 = np.full(N, -99)\n",
    "    ws0 = np.full(N, -99)\n",
    "\n",
    "    # fill arrays with lias and ws values where it correspond to.\n",
    "    lias0[np.where(inds_lia)[0]] = lias\n",
    "    ws0[np.where(inds_lia)[0]] = ws\n",
    "\n",
    "    # Finally, apply downsampling and second dowsampling to lias and ws.\n",
    "    lias = lias0[inds0[inPR]]\n",
    "    ws = ws0[inds0[inPR]]\n",
    "\n",
    "    try:\n",
    "        assert len(lias) == sum(inPR)\n",
    "    except Exception as e:\n",
    "        print('lias size does not match with Plant Region size.')\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        assert len(ws) == sum(inPR)\n",
    "    except Exception as e:\n",
    "        print('ws size does not match with Plant Region size.')\n",
    "        print(e)\n",
    "\n",
    "    voxk = lad.get_voxk(pointsPR, PRbounds, voxel_size)\n",
    "    bia = lad.get_bia(pointsPR, sensorsPR)\n",
    "    meshfile = lad.get_meshfile(mockname)\n",
    "\n",
    "    # print('----- DEBUG -----')\n",
    "    # print(len(lias), len(ws), len(voxk))\n",
    "\n",
    "    figext = '%s_%s' %(tree, str(voxel_size))\n",
    "    # figext = None\n",
    "    \n",
    "    alphas_k = lad.alpha_k(bia, voxk, lias, ws, resdir, meshfile, figext=figext, \n",
    "                            klia=False, use_true_lia=True)\n",
    "\n",
    "    kmax = m3b.shape[2]\n",
    "    \n",
    "    if kbins is None:\n",
    "        kbins = int(kmax/15)\n",
    "    print('kmax', kmax)\n",
    "    print('kbins', kbins)\n",
    "\n",
    "    # Attribute 2 counts per voxel\n",
    "    # outdir_count = os.path.join(resdir, 'm3count_%s_%s.npy' %(tree, str(voxel_size)))\n",
    "    \n",
    "    lads_mid_1, clai_1 = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6], PRbounds, tree, resdir, oldlad=True, C=1)\n",
    "    # lads_mid_05, clai_05 = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6], PRbounds, tree, resdir, oldlad=True, C=0.5)\n",
    "    lads_0, clai_0 = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6]*0+1, PRbounds, tree, resdir, oldlad=True, C=1)\n",
    "\n",
    "    # lads_mid_old, _ = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6], PRbounds, tree, resdir, oldlad=True)\n",
    "    # lads_mid_old = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,6], alpha2=1)\n",
    "    lads_mesh = lad.get_LADS_mesh(meshfile, voxel_size, kbins, kmax, PRbounds)\n",
    "\n",
    "    # lads = {'Truth':lads_mesh, 'Correction Mean':lads_mid, 'No Correction':lads_0, 'Correction Weights':lads_mid_w}#, 'Correction counts':lads_mid_counts}\n",
    "    # lads = {'Truth':lads_mesh, 'Correction Mean C=1':lads_mid_1, 'Correction Mean C=0.5':lads_mid_05,}\n",
    "    lads = {'Truth':lads_mesh, 'Correction Mean C=1':lads_mid_1, 'No Correction C=1':lads_0}\n",
    "    # clai = lad.get_clai(m3att, alphas_k)\n",
    "    attributes_file = os.path.join(resdir, 'm3s_%s_%s.npy' %(tree, str(voxel_size)))\n",
    "    if os.path.isfile(attributes_file):\n",
    "        RT = 'Y'\n",
    "    else:\n",
    "        RT = 'N'\n",
    "        \n",
    "    # text = {'tree':tree, 'VS':voxel_size, 'RT':RT, 'CLAI 1.0':np.round(clai_1, 3),  'CLAI 0.5':np.round(clai_05, 3)}\n",
    "    text = {'tree':tree, 'VS':voxel_size, 'RT':RT, 'CLAI 1.0':np.round(clai_1, 3),  'CLAI 1.0 -- NC':np.round(clai_0, 3)}\n",
    "    txt = []\n",
    "    for key, val in text.items():\n",
    "        txt.append('%s=%s \\n' %(key, str(val)))\n",
    "    text = (' ').join(txt)\n",
    "\n",
    "    savefig = os.path.join(resdir, 'figures','LAD_%s.png' %(figext))\n",
    "    figures.plot_lads(lads, text, savefig=savefig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  5.  1.]\n",
      " [ 1.  5.  1.]\n",
      " [-1.  5. -1.]\n",
      " [ 1.  5. -1.]\n",
      " [-1.  5.  1.]\n",
      " [ 1.  5.  1.]\n",
      " [-1.  5. -1.]\n",
      " [ 1.  5. -1.]\n",
      " [-1.  5.  1.]\n",
      " [ 1.  5.  1.]\n",
      " [-1.  5. -1.]\n",
      " [ 1.  5. -1.]\n",
      " [-1.  5.  1.]\n",
      " [ 1.  5.  1.]\n",
      " [-1.  5. -1.]\n",
      " [ 1.  5. -1.]\n",
      " [-1.  5.  1.]\n",
      " [ 1.  5.  1.]\n",
      " [-1.  5. -1.]\n",
      " [ 1.  5. -1.]\n",
      " [-1.  5.  1.]\n",
      " [ 1.  5.  1.]\n",
      " [-1.  5. -1.]\n",
      " [ 1.  5. -1.]\n",
      " [-1.  5.  1.]\n",
      " [ 1.  5.  1.]\n",
      " [-1.  5. -1.]\n",
      " [ 1.  5. -1.]\n",
      " [-1.  4.  1.]\n",
      " [ 1.  4.  1.]\n",
      " [-1.  4. -1.]\n",
      " [ 1.  4. -1.]\n",
      " [-1.  4.  1.]\n",
      " [ 1.  4.  1.]\n",
      " [-1.  4. -1.]\n",
      " [ 1.  4. -1.]\n",
      " [-1.  4.  1.]\n",
      " [ 1.  4.  1.]\n",
      " [-1.  4. -1.]\n",
      " [ 1.  4. -1.]\n",
      " [-1.  4.  1.]\n",
      " [ 1.  4.  1.]\n",
      " [-1.  4. -1.]\n",
      " [ 1.  4. -1.]\n",
      " [-1.  4.  1.]\n",
      " [ 1.  4.  1.]\n",
      " [-1.  4. -1.]\n",
      " [ 1.  4. -1.]\n",
      " [-1.  4.  1.]\n",
      " [ 1.  4.  1.]\n",
      " [-1.  4. -1.]\n",
      " [ 1.  4. -1.]\n",
      " [-1.  4.  1.]\n",
      " [ 1.  4.  1.]\n",
      " [-1.  4. -1.]\n",
      " [ 1.  4. -1.]\n",
      " [-1.  3.  1.]\n",
      " [ 1.  3.  1.]\n",
      " [-1.  3. -1.]\n",
      " [ 1.  3. -1.]\n",
      " [-1.  3.  1.]\n",
      " [ 1.  3.  1.]\n",
      " [-1.  3. -1.]\n",
      " [ 1.  3. -1.]\n",
      " [-1.  3.  1.]\n",
      " [ 1.  3.  1.]\n",
      " [-1.  3. -1.]\n",
      " [ 1.  3. -1.]\n",
      " [-1.  3.  1.]\n",
      " [ 1.  3.  1.]\n",
      " [-1.  3. -1.]\n",
      " [ 1.  3. -1.]\n",
      " [-1.  3.  1.]\n",
      " [ 1.  3.  1.]\n",
      " [-1.  3. -1.]\n",
      " [ 1.  3. -1.]\n",
      " [-1.  3.  1.]\n",
      " [ 1.  3.  1.]\n",
      " [-1.  3. -1.]\n",
      " [ 1.  3. -1.]\n",
      " [-1.  3.  1.]\n",
      " [ 1.  3.  1.]\n",
      " [-1.  3. -1.]\n",
      " [ 1.  3. -1.]\n",
      " [-1.  2.  1.]\n",
      " [ 1.  2.  1.]\n",
      " [-1.  2. -1.]\n",
      " [ 1.  2. -1.]\n",
      " [-1.  2.  1.]\n",
      " [ 1.  2.  1.]\n",
      " [-1.  2. -1.]\n",
      " [ 1.  2. -1.]\n",
      " [-1.  2.  1.]\n",
      " [ 1.  2.  1.]\n",
      " [-1.  2. -1.]\n",
      " [ 1.  2. -1.]\n",
      " [-1.  2.  1.]\n",
      " [ 1.  2.  1.]\n",
      " [-1.  2. -1.]\n",
      " [ 1.  2. -1.]\n",
      " [-1.  2.  1.]\n",
      " [ 1.  2.  1.]\n",
      " [-1.  2. -1.]\n",
      " [ 1.  2. -1.]\n",
      " [-1.  2.  1.]\n",
      " [ 1.  2.  1.]\n",
      " [-1.  2. -1.]\n",
      " [ 1.  2. -1.]\n",
      " [-1.  2.  1.]\n",
      " [ 1.  2.  1.]\n",
      " [-1.  2. -1.]\n",
      " [ 1.  2. -1.]]\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "meshfile = os.path.join(_data, mockname, 'mesh.ply')\n",
    "mesh = o3d.io.read_triangle_mesh(meshfile)\n",
    "vert = np.asarray(mesh.vertices)\n",
    "tri = np.asarray(mesh.triangles)\n",
    "\n",
    "print(np.array(mesh.vertices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voxel_size: 0.05\n",
      "kmax 62\n",
      "kbins 1\n",
      "======= K: 0 =======\n",
      "======= K: 1 =======\n",
      "======= K: 2 =======\n",
      "======= K: 3 =======\n",
      "======= K: 4 =======\n",
      "======= K: 5 =======\n",
      "======= K: 6 =======\n",
      "======= K: 7 =======\n",
      "======= K: 8 =======\n",
      "======= K: 9 =======\n",
      "======= K: 10 =======\n",
      "======= K: 11 =======\n",
      "======= K: 12 =======\n",
      "======= K: 13 =======\n",
      "======= K: 14 =======\n",
      "======= K: 15 =======\n",
      "======= K: 16 =======\n",
      "======= K: 17 =======\n",
      "======= K: 18 =======\n",
      "======= K: 19 =======\n",
      "======= K: 20 =======\n",
      "======= K: 21 =======\n",
      "======= K: 22 =======\n",
      "======= K: 23 =======\n",
      "======= K: 24 =======\n",
      "======= K: 25 =======\n",
      "======= K: 26 =======\n",
      "======= K: 27 =======\n",
      "======= K: 28 =======\n",
      "======= K: 29 =======\n",
      "======= K: 30 =======\n",
      "======= K: 31 =======\n",
      "======= K: 32 =======\n",
      "======= K: 33 =======\n",
      "======= K: 34 =======\n",
      "======= K: 35 =======\n",
      "======= K: 36 =======\n",
      "======= K: 37 =======\n",
      "======= K: 38 =======\n",
      "======= K: 39 =======\n",
      "======= K: 40 =======\n",
      "======= K: 41 =======\n",
      "======= K: 42 =======\n",
      "======= K: 43 =======\n",
      "======= K: 44 =======\n",
      "======= K: 45 =======\n",
      "======= K: 46 =======\n",
      "======= K: 47 =======\n",
      "======= K: 48 =======\n",
      "======= K: 49 =======\n",
      "======= K: 50 =======\n",
      "======= K: 51 =======\n",
      "======= K: 52 =======\n",
      "======= K: 53 =======\n",
      "======= K: 54 =======\n",
      "======= K: 55 =======\n",
      "======= K: 56 =======\n",
      "======= K: 57 =======\n",
      "======= K: 58 =======\n",
      "======= K: 59 =======\n",
      "======= K: 60 =======\n",
      "======= K: 61 =======\n",
      "======= K: 0 =======\n",
      "======= K: 1 =======\n",
      "======= K: 2 =======\n",
      "======= K: 3 =======\n",
      "======= K: 4 =======\n",
      "======= K: 5 =======\n",
      "======= K: 6 =======\n",
      "======= K: 7 =======\n",
      "======= K: 8 =======\n",
      "======= K: 9 =======\n",
      "======= K: 10 =======\n",
      "======= K: 11 =======\n",
      "======= K: 12 =======\n",
      "======= K: 13 =======\n",
      "======= K: 14 =======\n",
      "======= K: 15 =======\n",
      "======= K: 16 =======\n",
      "======= K: 17 =======\n",
      "======= K: 18 =======\n",
      "======= K: 19 =======\n",
      "======= K: 20 =======\n",
      "======= K: 21 =======\n",
      "======= K: 22 =======\n",
      "======= K: 23 =======\n",
      "======= K: 24 =======\n",
      "======= K: 25 =======\n",
      "======= K: 26 =======\n",
      "======= K: 27 =======\n",
      "======= K: 28 =======\n",
      "======= K: 29 =======\n",
      "======= K: 30 =======\n",
      "======= K: 31 =======\n",
      "======= K: 32 =======\n",
      "======= K: 33 =======\n",
      "======= K: 34 =======\n",
      "======= K: 35 =======\n",
      "======= K: 36 =======\n",
      "======= K: 37 =======\n",
      "======= K: 38 =======\n",
      "======= K: 39 =======\n",
      "======= K: 40 =======\n",
      "======= K: 41 =======\n",
      "======= K: 42 =======\n",
      "======= K: 43 =======\n",
      "======= K: 44 =======\n",
      "======= K: 45 =======\n",
      "======= K: 46 =======\n",
      "======= K: 47 =======\n",
      "======= K: 48 =======\n",
      "======= K: 49 =======\n",
      "======= K: 50 =======\n",
      "======= K: 51 =======\n",
      "======= K: 52 =======\n",
      "======= K: 53 =======\n",
      "======= K: 54 =======\n",
      "======= K: 55 =======\n",
      "======= K: 56 =======\n",
      "======= K: 57 =======\n",
      "======= K: 58 =======\n",
      "======= K: 59 =======\n",
      "======= K: 60 =======\n",
      "======= K: 61 =======\n",
      "isnegative []\n",
      "0.05 1 112.0 112.0\n"
     ]
    }
   ],
   "source": [
    "inPR = (leaves) & (trees['tree_0'])\n",
    "runall(POINTS[inPR], SENSORS[inPR], inPR, voxel_size, 'tree_0', N, (minpointPR, maxpointPR), resdir, kbins=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "760a6cd4159ac8b99590d0ad7ba9faed7c379184a996bf44e62e475912739812"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('plant-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
