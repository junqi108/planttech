{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyrr\n",
    "import itertools\n",
    "\n",
    "# basedir = os.path.dirname(os.getcwd())\n",
    "basedir = os.path.abspath(os.path.join(os.getcwd() ,\"../\"))\n",
    "_py = os.path.join(basedir, 'py')\n",
    "_data = os.path.join(basedir, 'data')\n",
    "\n",
    "sys.path.insert(1, _py)\n",
    "import loads\n",
    "import lia\n",
    "import ray as rayt\n",
    "import lad\n",
    "import figures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mockname = 'test_kiwi_2'\n",
    "voxel_size = 0.1\n",
    "downsample = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree and leaves segmentation\n",
    "\n",
    "Now we create the module to segmentate trees. This will be tuned acordingly for each data set, so below module only works for this particular data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segtree(df, leaves, show=False):\n",
    "\n",
    "    trees = {}\n",
    "\n",
    "    if show:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # centres\n",
    "    x, y = [0], [0]\n",
    "    num = 0\n",
    "    dx, dy = 2, 2\n",
    "    # dx, dy = 5, 5\n",
    "\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            \n",
    "            keep = np.ones(len(df['x']), dtype=bool)\n",
    "            keep &= (df['x'] < i+dx) & (df['x'] > i-dx)\n",
    "            keep &= (df['y'] < j+dy) & (df['y'] > j-dy)\n",
    "\n",
    "            trees['tree_%s' %(str(num))] = keep\n",
    "            \n",
    "            if show:\n",
    "                plt.scatter(df['x'][leaves & keep], df['y'][leaves & keep], s=0.5, label=num)\n",
    "                        \n",
    "            num += 1\n",
    "\n",
    "    if show:\n",
    "        plt.legend()\n",
    "    \n",
    "    return trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We segmentate the trees below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into a pandas data frame\n",
    "df = loads.npy2pandas(mockname)\n",
    "N = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def voxel_subsampling(voxel_size, POINTS):\n",
    "\n",
    "    nb_vox = np.ceil((np.max(POINTS, axis=0) - np.min(POINTS, axis=0))/voxel_size)\n",
    "    ni, nj, nk = nb_vox\n",
    "    print('min point:', np.min(POINTS, axis=0))\n",
    "    print('max point:', np.max(POINTS, axis=0))\n",
    "    print('Number of voxels: i:%d, j:%d, k:%d --> Total: %d' %(ni, nj, nk, np.product(nb_vox)))\n",
    "\n",
    "    non_empty_voxel_keys, inverse, nb_pts_per_voxel = np.unique(((POINTS - np.min(POINTS, axis=0)) // voxel_size).astype(int), axis=0, return_inverse=True, return_counts=True)\n",
    "    idx_pts_vox_sorted = np.argsort(inverse)\n",
    "    print('Number of non-empty voxels: %d' %(len(non_empty_voxel_keys)))\n",
    "\n",
    "    voxel_grid={}\n",
    "    voxel_grid_ptsidx = {}\n",
    "    grid_barycenter,grid_candidate_center = [], []\n",
    "    last_seen=0\n",
    "\n",
    "    for idx, vox in enumerate(non_empty_voxel_keys):\n",
    "\n",
    "        idxs_per_vox = idx_pts_vox_sorted[last_seen:last_seen+nb_pts_per_voxel[idx]]\n",
    "        voxel_grid[tuple(vox)] = POINTS[idxs_per_vox]\n",
    "        voxel_grid_ptsidx[tuple(vox)] = idxs_per_vox\n",
    "\n",
    "        # grid_barycenter.append(np.mean(voxel_grid[tuple(vox)],axis=0))\n",
    "\n",
    "        idx_grid_candidate_center = np.linalg.norm(voxel_grid[tuple(vox)] - np.mean(voxel_grid[tuple(vox)],axis=0),axis=1).argmin()\n",
    "        grid_candidate_center.append(voxel_grid_ptsidx[tuple(vox)][idx_grid_candidate_center])\n",
    "\n",
    "        last_seen+=nb_pts_per_voxel[idx]\n",
    "\n",
    "    # print('Downsampling percentage: %.1f %%' %(100 * len(grid_candidate_center) / len(POINTS)))\n",
    "    # minpoint = np.min(POINTS, axis=0)\n",
    "\n",
    "    return list(grid_candidate_center) #, minpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_downsample(N, downsample):\n",
    "\n",
    "    resdir = os.path.join(_data, mockname, 'random_%s' %(str(downsample)))\n",
    "    if not os.path.exists(resdir):\n",
    "        os.makedirs(resdir)\n",
    "\n",
    "    outdir = os.path.join(resdir, 'inds.npy')\n",
    "    if os.path.exists(outdir):\n",
    "        print('inds file already exists for donwnsample of %.3f at %s' %(downsample, outdir))\n",
    "\n",
    "        idx = np.load(outdir)\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('inds not been created yet for donwnsample of %.3f' %(downsample))\n",
    "        idx = np.random.randint(0, N, int(N * downsample))\n",
    "        # inds = np.zeros(N, dtype=bool)\n",
    "        # inds[idx] = True\n",
    "\n",
    "        np.save(outdir, idx)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement and keep Downsamplied points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inds not been created yet for donwnsample of 0.200\n",
      "Downsampling percentage: 20.0 %\n",
      "minpoint: [-5.00000238e+00 -5.00000095e+00 -1.43051147e-06]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if downsample is not None:\n",
    "    inds = random_downsample(N, downsample)\n",
    "else:\n",
    "    inds = voxel_subsampling(voxel_size, df[['x', 'y', 'z']].to_numpy())\n",
    "\n",
    "print('Downsampling percentage: %.1f %%' %(100 *  len(inds) / len(df['x'])))\n",
    "\n",
    "df = df.iloc[inds]\n",
    "POINTS = df[['x', 'y', 'z']].to_numpy()\n",
    "SENSORS = df[['sx', 'sy', 'sz']].to_numpy()\n",
    "\n",
    "# Compute lower point\n",
    "minpoint = np.min(POINTS, axis=0)\n",
    "print('minpoint:', minpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leave and tree segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract leaves. Boolean array output\n",
    "leaves = loads.extract_leaves(df, show=False)\n",
    "# extract trees. Dictionary with boolean arrays output\n",
    "trees = segtree(df, leaves, show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second downsampling: keep only points that colide with Plant Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inPR = (leaves) & (trees['tree_0'])\n",
    "minBB, maxBB = np.min(POINTS[inPR.values], axis=0), np.max(POINTS[inPR.values], axis=0)\n",
    "\n",
    "# Make sure Plant Region min & max points are multiples of voxel size\n",
    "# to match first voxelization where we implemented the downsampling\n",
    "minpointPR = minpoint + np.floor(np.abs(minpoint - minBB)/voxel_size) * voxel_size\n",
    "maxpointPR = minpoint + np.ceil(np.abs(minpoint - maxBB)/voxel_size) * voxel_size\n",
    "boxPR = pyrr.aabb.create_from_bounds(minpointPR, maxpointPR)\n",
    "\n",
    "lines = np.stack((POINTS, SENSORS), axis=1)\n",
    "f = lambda line: pyrr.geometric_tests.ray_intersect_aabb(pyrr.ray.create_from_line(line), boxPR) is not None\n",
    "res = np.array(list(map(f, lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "POINTS, SENSORS = POINTS[res], SENSORS[res]\n",
    "\n",
    "leaves = leaves[res]\n",
    "\n",
    "for key, val in trees.items():\n",
    "    trees[key] = val[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save indexes of voxel-based downsample\n",
    "\n",
    "idxs = np.array(inds)[res]\n",
    "\n",
    "if downsample is not None:\n",
    "    dirname = 'random_%s' %(str(downsample))\n",
    "    resdir = os.path.join(_data, mockname, dirname, 'lad_%s' %(str(voxel_size)))\n",
    "else:\n",
    "    dirname = 'voxel'\n",
    "    resdir = os.path.join(_data, mockname, dirname, 'lad_%s' %(str(voxel_size)))\n",
    "\n",
    "if not os.path.exists(resdir): os.makedirs(resdir)\n",
    "outdir = os.path.join(resdir, 'inds.npy')\n",
    "np.save(outdir, idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# iter... 63112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63112it [12:00, 87.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 11935\n",
      "voxels hitted: \t 7459\n",
      "Percentage of voxels hitted by beam: 0.62\n",
      "voxels hitted (OLD): \t 0\n",
      "Percentage of voxels hitted by beam (OLD): 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sample = None\n",
    "\n",
    "inPR = (leaves) & (trees['tree_0'])\n",
    "\n",
    "# resdir = os.path.join(_data, mockname, 'lad_%s' %(str(voxel_size)))\n",
    "# if not os.path.exists(resdir):\n",
    "    # os.makedirs(resdir)\n",
    "if sample is not None:\n",
    "    print('# iter...', len(POINTS[::sample]))\n",
    "    m3s = rayt.main2(POINTS[::sample], SENSORS[::sample], POINTS[inPR], voxel_size, resdir, 'tree_0', (minpointPR, maxpointPR), show=True)\n",
    "else:\n",
    "    print('# iter...', len(POINTS))\n",
    "    m3s = rayt.main2(POINTS, SENSORS, POINTS[inPR], voxel_size, resdir, 'tree_0', (minpointPR, maxpointPR), show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of voxels with points: 2437\n",
      "-----------------\n",
      "New attribute 1:\n",
      "\t from fraction of incidences with attribute 1: 2020.14\n",
      "\t from normal counts of voxels with attribute 1: 861.00\n",
      "New attribute 2\n",
      "\t from incidences with attribute 1: -444.14\n",
      "\t from normal counts of voxels with attribute 2: 7459.00\n"
     ]
    }
   ],
   "source": [
    "inPR = (leaves) & (trees['tree_0'])\n",
    "# resdir = os.path.join(_data, mockname, 'lad_%s' %(str(voxel_size)))\n",
    "NI, N0, NP0, NP = lad.get_attributes_per_k(POINTS[inPR], voxel_size, (minpointPR, maxpointPR), 'tree_0', kval=2, resdir=resdir, showall=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_fit_lia(mockname):\n",
    "\n",
    "    df = loads.npy2pandas(mockname)\n",
    "    # extract leaves. Boolean array output\n",
    "    leaves = loads.extract_leaves(df, show=False)\n",
    "    # extract trees. Dictionary with boolean arrays output\n",
    "    trees = segtree(df, leaves, show=False)\n",
    "\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        keep = (val) & (leaves) # take the LPC per tree\n",
    "        points = df[['x', 'y', 'z']].to_numpy()[keep]\n",
    "\n",
    "        res = lia.bestfit_pars_la(points, mockname, treename=key)\n",
    "        lia.best_fit_pars_plot(res, key, mockname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lia(mockname):\n",
    "\n",
    "    df = loads.npy2pandas(mockname)\n",
    "\n",
    "    # extract leaves. Boolean array output\n",
    "    leaves = loads.extract_leaves(df, show=False)\n",
    "    # extract trees. Dictionary with boolean arrays output\n",
    "    trees = segtree(df, leaves, show=False)\n",
    "\n",
    "\n",
    "    # load bestfit results\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        keep = (val) & (leaves)\n",
    "        points = df[['x', 'y', 'z']].to_numpy()[keep]\n",
    "    \n",
    "        bestfit_file = os.path.join(_data, mockname, 'lia', 'bestfit_%s.npy' %(key))\n",
    "        res = np.load(bestfit_file, allow_pickle=True)\n",
    "        res = res.tolist()\n",
    "\n",
    "        text = 'leaf area=%.2f \\n %s=%.4f \\n %s=%.4f \\n %s=%.4f ' %(res['leafsize'], 'voxel_size_w', res['voxel_size_w_bestfit'],'kd3_sr', res['kd3_sr_bestfit'],'max_nn', res['max_nn_bestfit'])\n",
    "        print(text)\n",
    "\n",
    "        chi2 = lia.leaf_angle(points, mockname, key, res['voxel_size_w_bestfit'], \n",
    "                                res['kd3_sr_bestfit'], res['max_nn_bestfit'], save=True,\n",
    "                                    savefig=True, text=text, voxel_size_h=0.1)\n",
    "\n",
    "        # save indexes from main df\n",
    "        inds = np.where((val) & (leaves))\n",
    "        np.save(os.path.join(_data, mockname, 'lia', 'inds.npy'), inds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voxel_size_w 0.0001 DONE...\n",
      "voxel_size_w 0.001 DONE...\n",
      "voxel_size_w 0.01 DONE...\n",
      "voxel_size_w 0.1 DONE...\n",
      "voxel_size_w 1 DONE...\n",
      "voxel_size_w BESTFIT:\t 0.01\n",
      "kd3_sr 0.001 DONE...\n",
      "kd3_sr 0.01 DONE...\n",
      "kd3_sr 0.1 DONE...\n",
      "kd3_sr 1.0 DONE...\n",
      "kd3_sr BESTFIT:\t 0.1\n",
      "max_nn 3 DONE...\n",
      "max_nn 5 DONE...\n",
      "max_nn 10 DONE...\n",
      "max_nn 20 DONE...\n",
      "max_nn 50 DONE...\n",
      "max_nn 100 DONE...\n",
      "max_nn BESTFIT:\t 5\n"
     ]
    }
   ],
   "source": [
    "best_fit_lia(mockname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf area=0.01 \n",
      " voxel_size_w=0.0100 \n",
      " kd3_sr=0.1000 \n",
      " max_nn=5.0000 \n"
     ]
    }
   ],
   "source": [
    "get_lia(mockname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 49026 141233 162125 ... 271647 121208 207455]\n"
     ]
    }
   ],
   "source": [
    "inds_file = os.path.join(resdir, 'inds.npy')\n",
    "inds = np.load(inds_file)\n",
    "print(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   105    106    137 ... 374846 374847 374848]\n"
     ]
    }
   ],
   "source": [
    "inds_lia = np.load(os.path.join(_data, mockname, 'lia', 'inds.npy'))\n",
    "print(inds_lia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runall(pointsPR, sensorsPR, voxel_size, tree, N, PRbounds, resdir, kbins=None):\n",
    "\n",
    "    # resdir = os.path.join(_data, mockname, 'lad_%s' %(str(voxel_size)))\n",
    "    inds_file = os.path.join(resdir, 'inds.npy')\n",
    "    inds = np.load(inds_file)\n",
    "    print(inds)\n",
    "\n",
    "    # resdir = os.path.join(_data, mockname, 'lad_%s' %(str(voxel_size)))\n",
    "\n",
    "    inds_lia = np.load(os.path.join(_data, mockname, 'lia', 'inds.npy'))\n",
    "\n",
    "    isfigures = os.path.join(resdir, 'figures')\n",
    "    if not os.path.exists(isfigures):\n",
    "        os.makedirs(isfigures)\n",
    "\n",
    "    attributes2_file = os.path.join(resdir, 'm3s_%s_%s.npy' %(tree, str(voxel_size)))\n",
    "    if os.path.isfile(attributes2_file):\n",
    "        m3b = np.load(attributes2_file)\n",
    "\n",
    "    print('voxel_size:', voxel_size)\n",
    "\n",
    "    m3att = lad.compute_attributes(pointsPR, resdir, voxel_size, tree, PRbounds)\n",
    "\n",
    "    # _,_,_, m3scount = lad.density_counts(pointsPR, voxel_size)\n",
    "\n",
    "    # get in down sample boolean array for LPC size\n",
    "    mask1 = np.zeros(N, bool)\n",
    "    mask2 = mask1.copy()\n",
    "\n",
    "    mask1[inds] = True\n",
    "    mask2[inds_lia] = True\n",
    "\n",
    "    lias, ws = lad.downsample_lia(mockname, tree, np.where(mask1[mask2])[0])\n",
    "    voxk = lad.get_voxk(pointsPR, PRbounds, voxel_size)\n",
    "    bia = lad.get_bia(pointsPR, sensorsPR)\n",
    "    meshfile = lad.get_meshfile(mockname)\n",
    "\n",
    "    print('DEBUG')\n",
    "    print(len(lias), len(ws), len(voxk))\n",
    "\n",
    "    figext = '%s_%s' %(tree, str(voxel_size))\n",
    "    # figext = None\n",
    "    \n",
    "    alphas_k = lad.alpha_k(bia, voxk, lias, ws, resdir, meshfile, figext=figext, \n",
    "                            klia=False, use_true_lia=True)\n",
    "\n",
    "    kmax = m3b.shape[2]\n",
    "    if kbins is None:\n",
    "        kbins = int(kmax/15)\n",
    "    print(kbins)\n",
    "\n",
    "    # Attribute 2 counts per voxel\n",
    "    # outdir_count = os.path.join(resdir, 'm3count_%s_%s.npy' %(tree, str(voxel_size)))\n",
    "    \n",
    "    lads_mid, clai = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6], PRbounds, tree, resdir)\n",
    "    lads_0, _ = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6]*0+1, PRbounds, tree, resdir)\n",
    "    # lads_mid_old, _ = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6], PRbounds, tree, resdir, oldlad=True)\n",
    "    # lads_mid_old = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,6], alpha2=1)\n",
    "    lads_mesh = lad.get_LADS_mesh(meshfile, voxel_size, kbins, kmax, PRbounds)\n",
    "\n",
    "    # lads = {'Truth':lads_mesh, 'Correction Mean':lads_mid, 'No Correction':lads_0, 'Correction Weights':lads_mid_w}#, 'Correction counts':lads_mid_counts}\n",
    "    lads = {'Truth':lads_mesh, 'Correction Mean':lads_mid, 'No Correction':lads_0}\n",
    "    # clai = lad.get_clai(m3att, alphas_k)\n",
    "    attributes_file = os.path.join(resdir, 'm3s_%s_%s.npy' %(tree, str(voxel_size)))\n",
    "    if os.path.isfile(attributes_file):\n",
    "        RT = 'Y'\n",
    "    else:\n",
    "        RT = 'N'\n",
    "        \n",
    "    text = {'tree':tree, 'VS':voxel_size, 'RT':RT, 'CLAI':np.round(clai, 3)}\n",
    "    txt = []\n",
    "    for key, val in text.items():\n",
    "        txt.append('%s=%s \\n' %(key, str(val)))\n",
    "    text = (' ').join(txt)\n",
    "\n",
    "    savefig = os.path.join(resdir, 'figures','LAD_%s.png' %(figext))\n",
    "    figures.plot_lads(lads, text, savefig=savefig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/omar/projects/planttech/data/test_kiwi_2/random_0.2/lad_0.1/inds.npy <class 'numpy.ndarray'>\n",
      "voxel_size: 0.1\n",
      "max --> [30, 34, 10]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (31, 35, 11)\n",
      "ray tracker voxel dimensions: \t (31, 35, 11)\n",
      "Number of voxels ocupied by points cloud: \t 2437\n",
      "Number of voxels ocupied by beam points cloud: \t 7459\n",
      "Total number of voxels in plant regions: \t 11935\n",
      "Number of voxels with attribute 1: \t 2437\n",
      "Number of voxels with attribute 2: \t 7459\n",
      "Number of voxels with attribute 3: \t 2039\n",
      "DEBUG\n",
      "30013 30013 33145\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 30013 but corresponding boolean dimension is 33145",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4l/bbjl67b151l_mb_20rk6glxh0000gn/T/ipykernel_19880/648449235.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minPR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tree_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrunall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPOINTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minPR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSENSORS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minPR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoxel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mminpointPR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxpointPR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/4l/bbjl67b151l_mb_20rk6glxh0000gn/T/ipykernel_19880/1466505394.py\u001b[0m in \u001b[0;36mrunall\u001b[0;34m(pointsPR, sensorsPR, voxel_size, tree, N, PRbounds, resdir, kbins)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# figext = None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     alphas_k = lad.alpha_k(bia, voxk, lias, ws, resdir, meshfile, figext=figext, \n\u001b[0m\u001b[1;32m     45\u001b[0m                             klia=False, use_true_lia=True)\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/planttech/py/lad.py\u001b[0m in \u001b[0;36malpha_k\u001b[0;34m(bia, voxk, lias, ws, resdir, meshfile, figext, klia, use_true_lia)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mmedian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mh_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mthetaLq_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0malpha_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradians\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mGtheta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetaLq_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 30013 but corresponding boolean dimension is 33145"
     ]
    }
   ],
   "source": [
    "inPR = (leaves) & (trees['tree_0'])\n",
    "runall(POINTS[inPR], SENSORS[inPR], voxel_size, 'tree_0', N, (minpointPR, maxpointPR), resdir, kbins=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "760a6cd4159ac8b99590d0ad7ba9faed7c379184a996bf44e62e475912739812"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('plant-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
