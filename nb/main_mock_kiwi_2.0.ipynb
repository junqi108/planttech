{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyrr\n",
    "import itertools\n",
    "\n",
    "# basedir = os.path.dirname(os.getcwd())\n",
    "basedir = os.path.abspath(os.path.join(os.getcwd() ,\"../\"))\n",
    "_py = os.path.join(basedir, 'py')\n",
    "_data = os.path.join(basedir, 'data')\n",
    "\n",
    "sys.path.insert(1, _py)\n",
    "import loads\n",
    "import lia\n",
    "import ray as rayt\n",
    "import lad\n",
    "import figures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `downsample` is not `None`, a random downsampling will be implemented. If `None`, the pipeline will use the voxel-based downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# mockname = 'test_kiwi_2'\n",
    "# mockname = 'test_simple_below'\n",
    "mockname = 'test_simple_below_inclined'\n",
    "voxel_size = 0.1\n",
    "downsample = None\n",
    "# downsample = 0.4\n",
    "\n",
    "Nleaves = 2\n",
    "# Nleaves = 4\n",
    "debug = True\n",
    "# minpointPR = np.array([-1.00000334, -1.0051055, 1.90000071])\n",
    "# maxpointPR = np.array([0.99999666, 1.0948945, 5.10000071])\n",
    "minpointPR = None\n",
    "maxpointPR = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree and leaves segmentation\n",
    "\n",
    "Now we create the module to segmentate trees. This will be tuned acordingly for each data set, so below module only works for this particular data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segtree(df, leaves, show=False):\n",
    "\n",
    "    trees = {}\n",
    "\n",
    "    if show:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # centres\n",
    "    x, y = [0], [0]\n",
    "    num = 0\n",
    "    dx, dy = 2, 2\n",
    "    # dx, dy = 5, 5\n",
    "\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            \n",
    "            keep = np.ones(len(df['x']), dtype=bool)\n",
    "            keep &= (df['x'] < i+dx) & (df['x'] > i-dx)\n",
    "            keep &= (df['y'] < j+dy) & (df['y'] > j-dy)\n",
    "\n",
    "            trees['tree_%s' %(str(num))] = keep\n",
    "            \n",
    "            if show:\n",
    "                plt.scatter(df['x'][leaves & keep], df['y'][leaves & keep], s=0.5, label=num)\n",
    "                        \n",
    "            num += 1\n",
    "\n",
    "    if show:\n",
    "        plt.legend()\n",
    "    \n",
    "    return trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We segmentate the trees below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0200000.numpy done --> Number of beams: 40000\n",
      "s0100000.numpy done --> Number of beams: 40000\n"
     ]
    }
   ],
   "source": [
    "# Conver `numpy` to `npy`\n",
    "loads.numpy2npy(mockname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 2\n",
      "80000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "x   -1.65773\n",
       "y    1.80441\n",
       "z    0.00000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data into a pandas data frame\n",
    "df = loads.npy2pandas(mockname)\n",
    "# round x, y, z to match voxel size significative figures\n",
    "df[['x', 'y', 'z']] = df[['x', 'y', 'z']].round(5)\n",
    "N = len(df)\n",
    "print(N)\n",
    "df[['x', 'y', 'z']].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply filter\n",
    "if False:\n",
    "    \n",
    "    leaves = np.ones(len(df), dtype=bool)\n",
    "    for i in ['x', 'y']:\n",
    "        leaves &= (df[i] > -1) & (df[i] < 1)\n",
    "    leaves &= (df['z'] > 1)\n",
    "\n",
    "    df = df[leaves]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 0 -- Non empty voxels --> 60\n",
      "K: 1 -- Non empty voxels --> 80\n",
      "K: 2 -- Non empty voxels --> 80\n",
      "K: 3 -- Non empty voxels --> 60\n",
      "K: 4 -- Non empty voxels --> 60\n",
      "K: 5 -- Non empty voxels --> 60\n",
      "K: 6 -- Non empty voxels --> 60\n",
      "K: 10 -- Non empty voxels --> 60\n",
      "K: 11 -- Non empty voxels --> 80\n",
      "K: 12 -- Non empty voxels --> 80\n",
      "K: 13 -- Non empty voxels --> 60\n",
      "K: 14 -- Non empty voxels --> 60\n",
      "K: 15 -- Non empty voxels --> 80\n",
      "K: 16 -- Non empty voxels --> 60\n",
      "K: 20 -- Non empty voxels --> 60\n",
      "K: 21 -- Non empty voxels --> 80\n",
      "K: 22 -- Non empty voxels --> 80\n",
      "K: 23 -- Non empty voxels --> 60\n",
      "K: 24 -- Non empty voxels --> 60\n",
      "K: 25 -- Non empty voxels --> 80\n",
      "K: 26 -- Non empty voxels --> 60\n",
      "K: 29 -- Non empty voxels --> 20\n",
      "K: 30 -- Non empty voxels --> 60\n",
      "K: 31 -- Non empty voxels --> 80\n",
      "K: 32 -- Non empty voxels --> 80\n",
      "K: 33 -- Non empty voxels --> 60\n",
      "K: 34 -- Non empty voxels --> 60\n",
      "K: 35 -- Non empty voxels --> 80\n",
      "K: 36 -- Non empty voxels --> 60\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def voxel_subsampling(voxel_size, POINTS):\n",
    "\n",
    "    nb_vox = np.ceil((np.max(POINTS, axis=0) - np.min(POINTS, axis=0))/voxel_size)\n",
    "    ni, nj, nk = nb_vox\n",
    "    print('min point:', np.min(POINTS, axis=0))\n",
    "    print('max point:', np.max(POINTS, axis=0))\n",
    "    print('Number of voxels: i:%d, j:%d, k:%d --> Total: %d' %(ni, nj, nk, np.product(nb_vox)))\n",
    "\n",
    "    non_empty_voxel_keys, inverse, nb_pts_per_voxel = np.unique(((POINTS - np.min(POINTS, axis=0)) // voxel_size).astype(int), axis=0, return_inverse=True, return_counts=True)\n",
    "    idx_pts_vox_sorted = np.argsort(inverse)\n",
    "    print('Number of non-empty voxels: %d' %(len(non_empty_voxel_keys)))\n",
    "\n",
    "    voxel_grid={}\n",
    "    voxel_grid_ptsidx = {}\n",
    "    grid_barycenter,grid_candidate_center = [], []\n",
    "    last_seen=0\n",
    "\n",
    "    for idx, vox in enumerate(non_empty_voxel_keys):\n",
    "\n",
    "        idxs_per_vox = idx_pts_vox_sorted[last_seen:last_seen+nb_pts_per_voxel[idx]]\n",
    "        voxel_grid[tuple(vox)] = POINTS[idxs_per_vox]\n",
    "        voxel_grid_ptsidx[tuple(vox)] = idxs_per_vox\n",
    "\n",
    "        # grid_barycenter.append(np.mean(voxel_grid[tuple(vox)],axis=0))\n",
    "\n",
    "        idx_grid_candidate_center = np.linalg.norm(voxel_grid[tuple(vox)] - np.mean(voxel_grid[tuple(vox)],axis=0),axis=1).argmin()\n",
    "        grid_candidate_center.append(voxel_grid_ptsidx[tuple(vox)][idx_grid_candidate_center])\n",
    "\n",
    "        last_seen+=nb_pts_per_voxel[idx]\n",
    "\n",
    "        # if idx < 5:\n",
    "        #     print('========')\n",
    "        #     print(voxel_grid_ptsidx[tuple(vox)][idx_grid_candidate_center])\n",
    "\n",
    "    # print('Downsampling percentage: %.1f %%' %(100 * len(grid_candidate_center) / len(POINTS)))\n",
    "    # minpoint = np.min(POINTS, axis=0)\n",
    "\n",
    "    # return list(grid_candidate_center) #, minpoint\n",
    "    return list(grid_candidate_center)\n",
    "\n",
    "# Sanity check\n",
    "leaves = np.ones(len(df), dtype=bool)\n",
    "for i in ['x', 'y']:\n",
    "    leaves &= (df[i] > -1) & (df[i] < 1)\n",
    "leaves &= (df['z'] > 1)\n",
    "\n",
    "_POINTS = df[['x', 'y', 'z']][leaves].to_numpy()\n",
    "vox, inverse, nb_pts_per_voxel = np.unique((np.round(_POINTS - np.min(_POINTS, axis=0), 10) // voxel_size).astype(int), axis=0, return_inverse=True, return_counts=True)\n",
    "\n",
    "for i in set(vox[:,2]):\n",
    "    print('K:',i, '-- Non empty voxels -->', np.sum(vox[:,2] == i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_downsample(N, downsample):\n",
    "\n",
    "    resdir = os.path.join(_data, mockname, 'random_%s' %(str(downsample)))\n",
    "    if not os.path.exists(resdir):\n",
    "        os.makedirs(resdir)\n",
    "\n",
    "    outdir = os.path.join(resdir, 'inds.npy')\n",
    "    if os.path.exists(outdir):\n",
    "        print('inds file already exists for donwnsample of %.3f at %s' %(downsample, outdir))\n",
    "\n",
    "        idx = np.load(outdir)\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('inds not been created yet for donwnsample of %.3f' %(downsample))\n",
    "        idx = np.random.randint(0, N, int(N * downsample))\n",
    "        # inds = np.zeros(N, dtype=bool)\n",
    "        # inds[idx] = True\n",
    "\n",
    "        np.save(outdir, idx)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement and keep Downsampled points\n",
    "\n",
    "Below code will implement a downsampling using either `random` or `voxel`. The donsampling is performed by saving the corresponding indexes list of the downsampled percentage from the original data size. If index list already exists we just take it to make the downsampling, if it does not exist yet, we created and save ir under its corresponding directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min point: [-11.00001  -5.        0.     ]\n",
      "max point: [11.00001  5.      24.94527]\n",
      "Number of voxels: i:221, j:100, k:250 --> Total: 5525000\n",
      "Number of non-empty voxels: 25052\n",
      "Voxel downsampling...\n",
      "Downsampling percentage: 31.3 %\n",
      "minpoint: [-11.00001  -5.        0.     ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if downsample is not None:\n",
    "    inds = random_downsample(N, downsample)\n",
    "    print('Random downsampling...')\n",
    "else:\n",
    "    inds = voxel_subsampling(voxel_size, df[['x', 'y', 'z']].to_numpy())\n",
    "    print('Voxel downsampling...')\n",
    "\n",
    "print('Downsampling percentage: %.1f %%' %(100 *  len(inds) / len(df['x'])))\n",
    "\n",
    "df = df.iloc[inds]\n",
    "POINTS = df[['x', 'y', 'z']].to_numpy()\n",
    "SENSORS = df[['sx', 'sy', 'sz']].to_numpy()\n",
    "\n",
    "# Compute lower point\n",
    "minpoint = np.min(POINTS, axis=0) # check this...\n",
    "print('minpoint:', minpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "leaves = np.ones(len(df), dtype=bool)\n",
    "for i in ['x', 'y']:\n",
    "    leaves &= (df[i] > -1) & (df[i] < 1)\n",
    "leaves &= (df['z'] > 1)\n",
    "\n",
    "# print(len(df), np.sum(leaves))\n",
    "loads.showPCfromDF(df[['x', 'y', 'z']][leaves])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leave and tree segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract leaves. Boolean array output\n",
    "# leaves = loads.extract_leaves(df, show=True)\n",
    "# extract trees. Dictionary with boolean arrays output\n",
    "trees = segtree(df, leaves, show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second downsampling: keep only points that colide with Plant Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.00001 -1.       1.6    ] [0.99999 1.      5.4    ]\n",
      "Error: min() arg is an empty sequence\n",
      "On line: 20956\n"
     ]
    }
   ],
   "source": [
    "inPR = (leaves) & (trees['tree_0'])\n",
    "minBB, maxBB = np.min(POINTS[inPR.values], axis=0), np.max(POINTS[inPR.values], axis=0)\n",
    "\n",
    "# if debug:\n",
    "#     minBB[2] = minBB[2] - 0*voxel_size\n",
    "#     maxBB[2] = maxBB[2] + 0*voxel_size\n",
    "\n",
    "# Make sure Plant Region min & max points are multiples of voxel size\n",
    "# to match first voxelization where we implemented the downsampling\n",
    "if minpointPR is None:\n",
    "    minpointPR = minpoint + np.floor(np.abs(minpoint - minBB)/voxel_size) * voxel_size\n",
    "if maxpointPR is None:\n",
    "    maxpointPR = minpoint + np.ceil(np.abs(minpoint - maxBB)/voxel_size) * voxel_size\n",
    "# else:\n",
    "#     minpointPR = minBB\n",
    "#     maxpointPR = maxBB\n",
    "\n",
    "print(minpointPR, maxpointPR)\n",
    "\n",
    "boxPR = pyrr.aabb.create_from_bounds(minpointPR, maxpointPR)\n",
    "\n",
    "lines = np.stack((POINTS, SENSORS), axis=1)\n",
    "f = lambda line: pyrr.geometric_tests.ray_intersect_aabb(pyrr.ray.create_from_line(line), boxPR) is not None\n",
    "# res = np.array(list(map(f, lines)))\n",
    "res = []\n",
    "\n",
    "for num, line in enumerate(lines):\n",
    "\n",
    "    try:\n",
    "        res.append(f(line))\n",
    "    except Exception as e:\n",
    "        res.append(False)\n",
    "        print('Error:', e)\n",
    "        print('On line:',num)\n",
    "\n",
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "POINTS, SENSORS = POINTS[res], SENSORS[res]\n",
    "\n",
    "leaves = leaves[res]\n",
    "\n",
    "for key, val in trees.items():\n",
    "    trees[key] = val[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save indexes of voxel-based downsample\n",
    "\n",
    "idxs = np.array(inds)[res]\n",
    "\n",
    "if downsample is not None:\n",
    "    dirname = 'random_%s' %(str(downsample))\n",
    "    resdir = os.path.join(_data, mockname, dirname, 'lad_%s' %(str(voxel_size)))\n",
    "else:\n",
    "    dirname = 'voxel'\n",
    "    resdir = os.path.join(_data, mockname, dirname, 'lad_%s' %(str(voxel_size)))\n",
    "\n",
    "if not os.path.exists(resdir): os.makedirs(resdir)\n",
    "outdir = os.path.join(resdir, 'inds.npy')\n",
    "np.save(outdir, idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# iter... 3015\n",
      "Results will be saved at /Users/omar/projects/planttech/data/test_simple_below_inclined/voxel/lad_0.1\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3015it [00:18, 162.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 15200\n",
      "voxels hitted: \t 7268\n",
      "Percentage of voxels hitted by beam: 0.48\n",
      "voxels hitted (OLD): \t 0\n",
      "Percentage of voxels hitted by beam (OLD): 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sample = None\n",
    "\n",
    "inPR = (leaves) & (trees['tree_0'])\n",
    "\n",
    "if sample is not None:\n",
    "    print('# iter...', len(POINTS[::sample]))\n",
    "    m3s = rayt.main2(POINTS[::sample], SENSORS[::sample], POINTS[inPR], voxel_size, resdir, 'tree_0', (minpointPR, maxpointPR), show=True)\n",
    "else:\n",
    "    print('# iter...', len(POINTS))\n",
    "    print('Results will be saved at %s' %(resdir))\n",
    "    print('-------------')\n",
    "    m3s = rayt.main2(POINTS, SENSORS, POINTS[inPR], voxel_size, resdir, 'tree_0', (minpointPR, maxpointPR), show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inPR = (leaves) & (trees['tree_0'])\n",
    "# resdir = os.path.join(_data, mockname, 'lad_%s' %(str(voxel_size)))\n",
    "NI, N0, NP0, NP = lad.get_attributes_per_k(POINTS[inPR], voxel_size, (minpointPR, maxpointPR), 'tree_0', kval=2, resdir=resdir, showall=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_fit_lia(mockname, Nleaves):\n",
    "\n",
    "    df = loads.npy2pandas(mockname)\n",
    "    # extract leaves. Boolean array output\n",
    "    \n",
    "    # leaves = loads.extract_leaves(df, show=False)\n",
    "    leaves = np.ones(len(df), dtype=bool)\n",
    "    for i in ['x', 'y']:\n",
    "        leaves &= (df[i] > -1) & (df[i] < 1)\n",
    "\n",
    "    # extract trees. Dictionary with boolean arrays output\n",
    "    trees = segtree(df, leaves, show=False)\n",
    "\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        keep = (val) & (leaves) # take the LPC per tree\n",
    "        points = df[['x', 'y', 'z']].to_numpy()[keep]\n",
    "\n",
    "        res = lia.bestfit_pars_la(points, mockname, Nleaves, treename=key)\n",
    "        lia.best_fit_pars_plot(res, key, mockname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lia(mockname):\n",
    "\n",
    "    df = loads.npy2pandas(mockname)\n",
    "\n",
    "    # extract leaves. Boolean array output\n",
    "\n",
    "    # leaves = loads.extract_leaves(df, show=False)\n",
    "    leaves = np.ones(len(df), dtype=bool)\n",
    "    for i in ['x', 'y']:\n",
    "        leaves &= (df[i] > -1) & (df[i] < 1)\n",
    "\n",
    "    # extract trees. Dictionary with boolean arrays output\n",
    "    trees = segtree(df, leaves, show=False)\n",
    "\n",
    "\n",
    "    # load bestfit results\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        keep = (val) & (leaves)\n",
    "        print(sum(keep), len(keep))\n",
    "        points = df[['x', 'y', 'z']].to_numpy()[keep]\n",
    "    \n",
    "        bestfit_file = os.path.join(_data, mockname, 'lia', 'bestfit_%s.npy' %(key))\n",
    "        res = np.load(bestfit_file, allow_pickle=True)\n",
    "        res = res.tolist()\n",
    "\n",
    "        text = 'leaf area=%.2f \\n %s=%.4f \\n %s=%.4f \\n %s=%.4f ' %(res['leafsize'], 'voxel_size_w', res['voxel_size_w_bestfit'],'kd3_sr', res['kd3_sr_bestfit'],'max_nn', res['max_nn_bestfit'])\n",
    "        print(text)\n",
    "\n",
    "        chi2 = lia.leaf_angle(points, mockname, key, res['voxel_size_w_bestfit'], \n",
    "                                res['kd3_sr_bestfit'], res['max_nn_bestfit'], save=True,\n",
    "                                    savefig=True, text=text, voxel_size_h=0.1)\n",
    "\n",
    "        # save indexes from main df\n",
    "        # inds = np.where((val) & (leaves))\n",
    "        np.save(os.path.join(_data, mockname, 'lia', 'inds.npy'), keep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <_NSViewBackingLayer: 0x7fb2f7fc8a30> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 2 doesn't match <_NSViewBackingLayer: 0x7fb2f7fc8a30> contents scale of 1 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 2 doesn't match <_NSViewBackingLayer: 0x7fb2f7fc8a30> contents scale of 1 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <_NSViewBackingLayer: 0x7fb2f7fc8a30> contents scale of 2 - updating layer to match.\n"
     ]
    }
   ],
   "source": [
    "# Check we have a mesh\n",
    "if True:\n",
    "    meshfile = os.path.join(_data, mockname, 'mesh.ply')\n",
    "    lad.see_mesh(meshfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 2\n",
      "voxel_size_w 0.0001 DONE...\n",
      "voxel_size_w 0.001 DONE...\n",
      "voxel_size_w 0.01 DONE...\n",
      "voxel_size_w 0.1 DONE...\n",
      "voxel_size_w 1 DONE...\n",
      "voxel_size_w BESTFIT:\t 0.0001\n",
      "kd3_sr 0.001 DONE...\n",
      "kd3_sr 0.01 DONE...\n",
      "kd3_sr 0.1 DONE...\n",
      "kd3_sr 1.0 DONE...\n",
      "kd3_sr BESTFIT:\t 0.1\n",
      "max_nn 3 DONE...\n",
      "max_nn 5 DONE...\n",
      "max_nn 10 DONE...\n",
      "max_nn 20 DONE...\n",
      "max_nn 50 DONE...\n",
      "max_nn 100 DONE...\n",
      "max_nn BESTFIT:\t 10\n"
     ]
    }
   ],
   "source": [
    "best_fit_lia(mockname, Nleaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 2\n",
      "25827 80000\n",
      "leaf area=4.00 \n",
      " voxel_size_w=0.0001 \n",
      " kd3_sr=0.1000 \n",
      " max_nn=10.0000 \n"
     ]
    }
   ],
   "source": [
    "get_lia(mockname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runall(pointsPR, sensorsPR, inPR, voxel_size, tree, N, PRbounds, resdir, kbins=None):\n",
    "\n",
    "    # resdir = os.path.join(_data, mockname, 'lad_%s' %(str(voxel_size)))\n",
    "    inds_file = os.path.join(resdir, 'inds.npy')\n",
    "    inds0 = np.load(inds_file)\n",
    "\n",
    "    # resdir = os.path.join(_data, mockname, 'lad_%s' %(str(voxel_size)))\n",
    "\n",
    "    inds_lia = np.load(os.path.join(_data, mockname, 'lia', 'inds.npy'))\n",
    "\n",
    "    isfigures = os.path.join(resdir, 'figures')\n",
    "    if not os.path.exists(isfigures):\n",
    "        os.makedirs(isfigures)\n",
    "\n",
    "    attributes2_file = os.path.join(resdir, 'm3s_%s_%s.npy' %(tree, str(voxel_size)))\n",
    "    if os.path.isfile(attributes2_file):\n",
    "        m3b = np.load(attributes2_file)\n",
    "\n",
    "    print('voxel_size:', voxel_size)\n",
    "\n",
    "    # m3att = lad.compute_attributes(pointsPR, resdir, voxel_size, tree, PRbounds)\n",
    "\n",
    "    # _,_,_, m3scount = lad.density_counts(pointsPR, voxel_size)\n",
    "\n",
    "    # Load LIAs and its weights saved at `get_lia()`.\n",
    "    # Size of lias and ws arrays is the original size after leaf and tree extraction only.\n",
    "    lias, ws = loads.load_lias_ws(mockname, 'tree_0')\n",
    "\n",
    "    # Create  arrays of original size filled with -99\n",
    "    lias0 = np.full(N, -99)\n",
    "    ws0 = np.full(N, -99)\n",
    "\n",
    "    # fill arrays with lias and ws values where it correspond to.\n",
    "    lias0[np.where(inds_lia)[0]] = lias\n",
    "    ws0[np.where(inds_lia)[0]] = ws\n",
    "\n",
    "    # Finally, apply downsampling and second dowsampling to lias and ws.\n",
    "    lias = lias0[inds0[inPR]]\n",
    "    ws = ws0[inds0[inPR]]\n",
    "\n",
    "    try:\n",
    "        assert len(lias) == sum(inPR)\n",
    "    except Exception as e:\n",
    "        print('lias size does not match with Plant Region size.')\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        assert len(ws) == sum(inPR)\n",
    "    except Exception as e:\n",
    "        print('ws size does not match with Plant Region size.')\n",
    "        print(e)\n",
    "\n",
    "    voxk = lad.get_voxk(pointsPR, PRbounds, voxel_size)\n",
    "    bia = lad.get_bia(pointsPR, sensorsPR)\n",
    "    meshfile = lad.get_meshfile(mockname)\n",
    "\n",
    "    # print('----- DEBUG -----')\n",
    "    # print(len(lias), len(ws), len(voxk))\n",
    "\n",
    "    figext = '%s_%s' %(tree, str(voxel_size))\n",
    "    # figext = None\n",
    "    \n",
    "    alphas_k = lad.alpha_k(bia, voxk, lias, ws, resdir, meshfile, figext=figext, \n",
    "                            klia=False, use_true_lia=True)\n",
    "\n",
    "    kmax = m3b.shape[2]\n",
    "    \n",
    "    if kbins is None:\n",
    "        kbins = int(kmax/15)\n",
    "    print('kmax', kmax)\n",
    "    print('kbins', kbins)\n",
    "\n",
    "    # Attribute 2 counts per voxel\n",
    "    # outdir_count = os.path.join(resdir, 'm3count_%s_%s.npy' %(tree, str(voxel_size)))\n",
    "\n",
    "    oldlad = True\n",
    "    \n",
    "    lads_mid_1, clai_1 = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6], PRbounds, tree, resdir, oldlad=oldlad, C=1)\n",
    "    # lads_mid_05, clai_05 = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6], PRbounds, tree, resdir, oldlad=True, C=0.5)\n",
    "    lads_0, clai_0 = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6]*0+1, PRbounds, tree, resdir, oldlad=oldlad, C=1)\n",
    "\n",
    "    # lads_mid_old, _ = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6], PRbounds, tree, resdir, oldlad=True)\n",
    "    # lads_mid_old = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,6], alpha2=1)\n",
    "    lads_mesh = lad.get_LADS_mesh(meshfile, voxel_size, kbins, kmax, PRbounds, inverted=True)\n",
    "\n",
    "    # lads = {'Truth':lads_mesh, 'Correction Mean':lads_mid, 'No Correction':lads_0, 'Correction Weights':lads_mid_w}#, 'Correction counts':lads_mid_counts}\n",
    "    # lads = {'Truth':lads_mesh, 'Correction Mean C=1':lads_mid_1, 'Correction Mean C=0.5':lads_mid_05,}\n",
    "    lads = {'Truth':lads_mesh, 'Correction Mean C=1':lads_mid_1, 'No Correction C=1':lads_0}\n",
    "    # clai = lad.get_clai(m3att, alphas_k)\n",
    "    attributes_file = os.path.join(resdir, 'm3s_%s_%s.npy' %(tree, str(voxel_size)))\n",
    "    if os.path.isfile(attributes_file):\n",
    "        RT = 'Y'\n",
    "    else:\n",
    "        RT = 'N'\n",
    "        \n",
    "    # text = {'tree':tree, 'VS':voxel_size, 'RT':RT, 'CLAI 1.0':np.round(clai_1, 3),  'CLAI 0.5':np.round(clai_05, 3)}\n",
    "    text = {'tree':tree, 'VS':voxel_size, 'RT':RT, 'CLAI 1.0':np.round(clai_1, 3),  'CLAI 1.0 -- NC':np.round(clai_0, 3)}\n",
    "    txt = []\n",
    "    for key, val in text.items():\n",
    "        txt.append('%s=%s \\n' %(key, str(val)))\n",
    "    text = (' ').join(txt)\n",
    "\n",
    "    savefig = os.path.join(resdir, 'figures','LAD_%s.png' %(figext))\n",
    "    figures.plot_lads(lads, text, savefig=savefig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voxel_size: 0.1\n",
      "kmax 38\n",
      "kbins 2\n",
      "==== Inverted normals =====\n",
      "==== Inverted vertices =====\n",
      "======\n",
      "surface area 16.00000492254976\n",
      "number of trinagles 968\n",
      "Area per triangle {0.016529}\n",
      "angles mesh {20.0}\n",
      "Number of vertices 576\n",
      " ---------- width, height, kbins * voxel_size 2.0 3.8000000000000003 0.2\n",
      "------- volume 1.5200000000000002\n",
      "======== kbin: [0, 1] ========\n",
      "number of triangles per bin 55\n",
      "total surface area per kbin 0.9090950000000001\n",
      "Area per kbin corrected: 0.8542698630933656\n",
      "labda: {20.0}\n",
      "======== kbin: [2, 3] ========\n",
      "number of triangles per bin 66\n",
      "total surface area per kbin 1.090914\n",
      "Area per kbin corrected: 1.0251238357120382\n",
      "labda: {20.0}\n",
      "======== kbin: [4, 5] ========\n",
      "number of triangles per bin 66\n",
      "total surface area per kbin 1.090914\n",
      "Area per kbin corrected: 1.0251238357120382\n",
      "labda: {20.0}\n",
      "======== kbin: [6, 7] ========\n",
      "number of triangles per bin 55\n",
      "total surface area per kbin 0.9090950000000001\n",
      "Area per kbin corrected: 0.8542698630933656\n",
      "labda: {20.0}\n",
      "======== kbin: [8, 9] ========\n",
      "number of triangles per bin 0\n",
      "total surface area per kbin 0.0\n",
      "Area per kbin corrected: 0.0\n",
      "labda: set()\n",
      "======== kbin: [10, 11] ========\n",
      "number of triangles per bin 55\n",
      "total surface area per kbin 0.9090950000000001\n",
      "Area per kbin corrected: 0.8542698630933656\n",
      "labda: {20.0}\n",
      "======== kbin: [12, 13] ========\n",
      "number of triangles per bin 66\n",
      "total surface area per kbin 1.090914\n",
      "Area per kbin corrected: 1.0251238357120382\n",
      "labda: {20.0}\n",
      "======== kbin: [14, 15] ========\n",
      "number of triangles per bin 66\n",
      "total surface area per kbin 1.090914\n",
      "Area per kbin corrected: 1.0251238357120382\n",
      "labda: {20.0}\n",
      "======== kbin: [16, 17] ========\n",
      "number of triangles per bin 55\n",
      "total surface area per kbin 0.9090950000000001\n",
      "Area per kbin corrected: 0.8542698630933656\n",
      "labda: {20.0}\n",
      "======== kbin: [18, 19] ========\n",
      "number of triangles per bin 0\n",
      "total surface area per kbin 0.0\n",
      "Area per kbin corrected: 0.0\n",
      "labda: set()\n",
      "======== kbin: [20, 21] ========\n",
      "number of triangles per bin 55\n",
      "total surface area per kbin 0.9090950000000001\n",
      "Area per kbin corrected: 0.8542698630933656\n",
      "labda: {20.0}\n",
      "======== kbin: [22, 23] ========\n",
      "number of triangles per bin 66\n",
      "total surface area per kbin 1.090914\n",
      "Area per kbin corrected: 1.0251238357120382\n",
      "labda: {20.0}\n",
      "======== kbin: [24, 25] ========\n",
      "number of triangles per bin 66\n",
      "total surface area per kbin 1.090914\n",
      "Area per kbin corrected: 1.0251238357120382\n",
      "labda: {20.0}\n",
      "======== kbin: [26, 27] ========\n",
      "number of triangles per bin 55\n",
      "total surface area per kbin 0.9090950000000001\n",
      "Area per kbin corrected: 0.8542698630933656\n",
      "labda: {20.0}\n",
      "======== kbin: [28, 29] ========\n",
      "number of triangles per bin 0\n",
      "total surface area per kbin 0.0\n",
      "Area per kbin corrected: 0.0\n",
      "labda: set()\n",
      "======== kbin: [30, 31] ========\n",
      "number of triangles per bin 55\n",
      "total surface area per kbin 0.9090950000000001\n",
      "Area per kbin corrected: 0.8542698630933656\n",
      "labda: {20.0}\n",
      "======== kbin: [32, 33] ========\n",
      "number of triangles per bin 66\n",
      "total surface area per kbin 1.090914\n",
      "Area per kbin corrected: 1.0251238357120382\n",
      "labda: {20.0}\n",
      "======== kbin: [34, 35] ========\n",
      "number of triangles per bin 66\n",
      "total surface area per kbin 1.090914\n",
      "Area per kbin corrected: 1.0251238357120382\n",
      "labda: {20.0}\n",
      "======== kbin: [36, 37] ========\n",
      "number of triangles per bin 55\n",
      "total surface area per kbin 0.9090950000000001\n",
      "Area per kbin corrected: 0.8542698630933656\n",
      "labda: {20.0}\n",
      "0.1 2 16.0 16.0\n",
      "------ A sum corrected 15.035149590443234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.backingstore: Back buffer dpr of 2 doesn't match <_NSViewBackingLayer: 0x7fb2f7fc8a30> contents scale of 1 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <_NSViewBackingLayer: 0x7fb2f7fc8a30> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <_NSViewBackingLayer: 0x7fb2f7fc8a30> contents scale of 2 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 2 doesn't match <_NSViewBackingLayer: 0x7fb2f7fc8a30> contents scale of 1 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 2 doesn't match <_NSViewBackingLayer: 0x7fb2f7fc8a30> contents scale of 1 - updating layer to match.\n",
      "qt.qpa.backingstore: Back buffer dpr of 1 doesn't match <_NSViewBackingLayer: 0x7fb2f7fc8a30> contents scale of 2 - updating layer to match.\n"
     ]
    }
   ],
   "source": [
    "inPR = (leaves) & (trees['tree_0'])\n",
    "runall(POINTS[inPR], SENSORS[inPR], inPR, voxel_size, 'tree_0', N, (minpointPR, maxpointPR), resdir, kbins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "[-0.34199212  0.93970282  0.        ]\n",
      "[-0.34199212  0.93970282  0.        ]\n",
      "[-0.34199212  0.93970282  0.        ]\n",
      "[-0.34199212  0.93970282  0.        ]\n",
      "[-0.34204245  0.9396845   0.        ]\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "meshfile = os.path.join(_data, mockname, 'mesh.ply')\n",
    "lad.see_mesh(meshfile)\n",
    "mesh = o3d.io.read_triangle_mesh(meshfile)\n",
    "vert = np.asarray(mesh.vertices)\n",
    "tri = np.asarray(mesh.triangles)\n",
    "\n",
    "# print(np.array(mesh.vertices))\n",
    "mesh.compute_triangle_normals()\n",
    "tnorm = np.asarray(mesh.triangle_normals)\n",
    "\n",
    "for vect in tnorm[:5]:\n",
    "    print(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "760a6cd4159ac8b99590d0ad7ba9faed7c379184a996bf44e62e475912739812"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('plant-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
