{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyrr\n",
    "import itertools\n",
    "\n",
    "# basedir = os.path.dirname(os.getcwd())\n",
    "basedir = os.path.abspath(os.path.join(os.getcwd() ,\"../\"))\n",
    "_py = os.path.join(basedir, 'py')\n",
    "_data = os.path.join(basedir, 'data')\n",
    "\n",
    "sys.path.insert(1, _py)\n",
    "import loads\n",
    "import lia\n",
    "import ray as rayt\n",
    "import lad\n",
    "import figures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `downsample` is not `None`, a random downsampling will be implemented. If `None`, the pipeline will use the voxel-based downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mockname = 'test_kiwi_2'\n",
    "voxel_size = 0.1\n",
    "downsample = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree and leaves segmentation\n",
    "\n",
    "Now we create the module to segmentate trees. This will be tuned acordingly for each data set, so below module only works for this particular data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segtree(df, leaves, show=False):\n",
    "\n",
    "    trees = {}\n",
    "\n",
    "    if show:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # centres\n",
    "    x, y = [0], [0]\n",
    "    num = 0\n",
    "    dx, dy = 2, 2\n",
    "    # dx, dy = 5, 5\n",
    "\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            \n",
    "            keep = np.ones(len(df['x']), dtype=bool)\n",
    "            keep &= (df['x'] < i+dx) & (df['x'] > i-dx)\n",
    "            keep &= (df['y'] < j+dy) & (df['y'] > j-dy)\n",
    "\n",
    "            trees['tree_%s' %(str(num))] = keep\n",
    "            \n",
    "            if show:\n",
    "                plt.scatter(df['x'][leaves & keep], df['y'][leaves & keep], s=0.5, label=num)\n",
    "                        \n",
    "            num += 1\n",
    "\n",
    "    if show:\n",
    "        plt.legend()\n",
    "    \n",
    "    return trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We segmentate the trees below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into a pandas data frame\n",
    "df = loads.npy2pandas(mockname)\n",
    "N = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375000\n"
     ]
    }
   ],
   "source": [
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def voxel_subsampling(voxel_size, POINTS):\n",
    "\n",
    "    nb_vox = np.ceil((np.max(POINTS, axis=0) - np.min(POINTS, axis=0))/voxel_size)\n",
    "    ni, nj, nk = nb_vox\n",
    "    print('min point:', np.min(POINTS, axis=0))\n",
    "    print('max point:', np.max(POINTS, axis=0))\n",
    "    print('Number of voxels: i:%d, j:%d, k:%d --> Total: %d' %(ni, nj, nk, np.product(nb_vox)))\n",
    "\n",
    "    non_empty_voxel_keys, inverse, nb_pts_per_voxel = np.unique(((POINTS - np.min(POINTS, axis=0)) // voxel_size).astype(int), axis=0, return_inverse=True, return_counts=True)\n",
    "    idx_pts_vox_sorted = np.argsort(inverse)\n",
    "    print('Number of non-empty voxels: %d' %(len(non_empty_voxel_keys)))\n",
    "\n",
    "    voxel_grid={}\n",
    "    voxel_grid_ptsidx = {}\n",
    "    grid_barycenter,grid_candidate_center = [], []\n",
    "    last_seen=0\n",
    "\n",
    "    for idx, vox in enumerate(non_empty_voxel_keys):\n",
    "\n",
    "        idxs_per_vox = idx_pts_vox_sorted[last_seen:last_seen+nb_pts_per_voxel[idx]]\n",
    "        voxel_grid[tuple(vox)] = POINTS[idxs_per_vox]\n",
    "        voxel_grid_ptsidx[tuple(vox)] = idxs_per_vox\n",
    "\n",
    "        # grid_barycenter.append(np.mean(voxel_grid[tuple(vox)],axis=0))\n",
    "\n",
    "        idx_grid_candidate_center = np.linalg.norm(voxel_grid[tuple(vox)] - np.mean(voxel_grid[tuple(vox)],axis=0),axis=1).argmin()\n",
    "        grid_candidate_center.append(voxel_grid_ptsidx[tuple(vox)][idx_grid_candidate_center])\n",
    "\n",
    "        last_seen+=nb_pts_per_voxel[idx]\n",
    "\n",
    "    # print('Downsampling percentage: %.1f %%' %(100 * len(grid_candidate_center) / len(POINTS)))\n",
    "    # minpoint = np.min(POINTS, axis=0)\n",
    "\n",
    "    return list(grid_candidate_center) #, minpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_downsample(N, downsample):\n",
    "\n",
    "    resdir = os.path.join(_data, mockname, 'random_%s' %(str(downsample)))\n",
    "    if not os.path.exists(resdir):\n",
    "        os.makedirs(resdir)\n",
    "\n",
    "    outdir = os.path.join(resdir, 'inds.npy')\n",
    "    if os.path.exists(outdir):\n",
    "        print('inds file already exists for donwnsample of %.3f at %s' %(downsample, outdir))\n",
    "\n",
    "        idx = np.load(outdir)\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('inds not been created yet for donwnsample of %.3f' %(downsample))\n",
    "        idx = np.random.randint(0, N, int(N * downsample))\n",
    "        # inds = np.zeros(N, dtype=bool)\n",
    "        # inds[idx] = True\n",
    "\n",
    "        np.save(outdir, idx)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement and keep Downsampled points\n",
    "\n",
    "Below code will implement a downsampling using either `random` or `voxel`. The donsampling is performed by saving the corresponding indexes list of the downsampled percentage from the original data size. If index list already exists we just take it to make the downsampling, if it does not exist yet, we created and save ir under its corresponding directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inds file already exists for donwnsample of 0.200 at /Users/omar/projects/planttech/data/test_kiwi_2/random_0.2/inds.npy\n",
      "Downsampling percentage: 20.0 %\n",
      "minpoint: [-5.00000238e+00 -5.00000095e+00 -1.43051147e-06]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if downsample is not None:\n",
    "    inds = random_downsample(N, downsample)\n",
    "else:\n",
    "    inds = voxel_subsampling(voxel_size, df[['x', 'y', 'z']].to_numpy())\n",
    "\n",
    "print('Downsampling percentage: %.1f %%' %(100 *  len(inds) / len(df['x'])))\n",
    "\n",
    "df = df.iloc[inds]\n",
    "POINTS = df[['x', 'y', 'z']].to_numpy()\n",
    "SENSORS = df[['sx', 'sy', 'sz']].to_numpy()\n",
    "\n",
    "# Compute lower point\n",
    "minpoint = np.min(POINTS, axis=0)\n",
    "print('minpoint:', minpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leave and tree segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract leaves. Boolean array output\n",
    "leaves = loads.extract_leaves(df, show=False)\n",
    "# extract trees. Dictionary with boolean arrays output\n",
    "trees = segtree(df, leaves, show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second downsampling: keep only points that colide with Plant Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inPR = (leaves) & (trees['tree_0'])\n",
    "minBB, maxBB = np.min(POINTS[inPR.values], axis=0), np.max(POINTS[inPR.values], axis=0)\n",
    "\n",
    "# Make sure Plant Region min & max points are multiples of voxel size\n",
    "# to match first voxelization where we implemented the downsampling\n",
    "minpointPR = minpoint + np.floor(np.abs(minpoint - minBB)/voxel_size) * voxel_size\n",
    "maxpointPR = minpoint + np.ceil(np.abs(minpoint - maxBB)/voxel_size) * voxel_size\n",
    "boxPR = pyrr.aabb.create_from_bounds(minpointPR, maxpointPR)\n",
    "\n",
    "lines = np.stack((POINTS, SENSORS), axis=1)\n",
    "f = lambda line: pyrr.geometric_tests.ray_intersect_aabb(pyrr.ray.create_from_line(line), boxPR) is not None\n",
    "res = np.array(list(map(f, lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "POINTS, SENSORS = POINTS[res], SENSORS[res]\n",
    "\n",
    "leaves = leaves[res]\n",
    "\n",
    "for key, val in trees.items():\n",
    "    trees[key] = val[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save indexes of voxel-based downsample\n",
    "\n",
    "idxs = np.array(inds)[res]\n",
    "\n",
    "if downsample is not None:\n",
    "    dirname = 'random_%s' %(str(downsample))\n",
    "    resdir = os.path.join(_data, mockname, dirname, 'lad_%s' %(str(voxel_size)))\n",
    "else:\n",
    "    dirname = 'voxel'\n",
    "    resdir = os.path.join(_data, mockname, dirname, 'lad_%s' %(str(voxel_size)))\n",
    "\n",
    "if not os.path.exists(resdir): os.makedirs(resdir)\n",
    "outdir = os.path.join(resdir, 'inds.npy')\n",
    "np.save(outdir, idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# iter... 63112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63112it [11:37, 90.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 11935\n",
      "voxels hitted: \t 7459\n",
      "Percentage of voxels hitted by beam: 0.62\n",
      "voxels hitted (OLD): \t 0\n",
      "Percentage of voxels hitted by beam (OLD): 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sample = None\n",
    "\n",
    "inPR = (leaves) & (trees['tree_0'])\n",
    "\n",
    "# resdir = os.path.join(_data, mockname, 'lad_%s' %(str(voxel_size)))\n",
    "# if not os.path.exists(resdir):\n",
    "    # os.makedirs(resdir)\n",
    "if sample is not None:\n",
    "    print('# iter...', len(POINTS[::sample]))\n",
    "    m3s = rayt.main2(POINTS[::sample], SENSORS[::sample], POINTS[inPR], voxel_size, resdir, 'tree_0', (minpointPR, maxpointPR), show=True)\n",
    "else:\n",
    "    print('# iter...', len(POINTS))\n",
    "    m3s = rayt.main2(POINTS, SENSORS, POINTS[inPR], voxel_size, resdir, 'tree_0', (minpointPR, maxpointPR), show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of voxels with points: 2437\n",
      "-----------------\n",
      "New attribute 1:\n",
      "\t from fraction of incidences with attribute 1: 490.57\n",
      "\t from normal counts of voxels with attribute 1: 861.00\n",
      "New attribute 2\n",
      "\t from incidences with attribute 1: 1085.43\n",
      "\t from normal counts of voxels with attribute 2: 7459.00\n"
     ]
    }
   ],
   "source": [
    "inPR = (leaves) & (trees['tree_0'])\n",
    "# resdir = os.path.join(_data, mockname, 'lad_%s' %(str(voxel_size)))\n",
    "NI, N0, NP0, NP = lad.get_attributes_per_k(POINTS[inPR], voxel_size, (minpointPR, maxpointPR), 'tree_0', kval=2, resdir=resdir, showall=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_fit_lia(mockname):\n",
    "\n",
    "    df = loads.npy2pandas(mockname)\n",
    "    # extract leaves. Boolean array output\n",
    "    leaves = loads.extract_leaves(df, show=False)\n",
    "    # extract trees. Dictionary with boolean arrays output\n",
    "    trees = segtree(df, leaves, show=False)\n",
    "\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        keep = (val) & (leaves) # take the LPC per tree\n",
    "        points = df[['x', 'y', 'z']].to_numpy()[keep]\n",
    "\n",
    "        res = lia.bestfit_pars_la(points, mockname, treename=key)\n",
    "        lia.best_fit_pars_plot(res, key, mockname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lia(mockname):\n",
    "\n",
    "    df = loads.npy2pandas(mockname)\n",
    "\n",
    "    # extract leaves. Boolean array output\n",
    "    leaves = loads.extract_leaves(df, show=False)\n",
    "    # extract trees. Dictionary with boolean arrays output\n",
    "    trees = segtree(df, leaves, show=False)\n",
    "\n",
    "\n",
    "    # load bestfit results\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        keep = (val) & (leaves)\n",
    "        print(sum(keep), len(keep))\n",
    "        points = df[['x', 'y', 'z']].to_numpy()[keep]\n",
    "    \n",
    "        bestfit_file = os.path.join(_data, mockname, 'lia', 'bestfit_%s.npy' %(key))\n",
    "        res = np.load(bestfit_file, allow_pickle=True)\n",
    "        res = res.tolist()\n",
    "\n",
    "        text = 'leaf area=%.2f \\n %s=%.4f \\n %s=%.4f \\n %s=%.4f ' %(res['leafsize'], 'voxel_size_w', res['voxel_size_w_bestfit'],'kd3_sr', res['kd3_sr_bestfit'],'max_nn', res['max_nn_bestfit'])\n",
    "        print(text)\n",
    "\n",
    "        chi2 = lia.leaf_angle(points, mockname, key, res['voxel_size_w_bestfit'], \n",
    "                                res['kd3_sr_bestfit'], res['max_nn_bestfit'], save=True,\n",
    "                                    savefig=True, text=text, voxel_size_h=0.1)\n",
    "\n",
    "        # save indexes from main df\n",
    "        # inds = np.where((val) & (leaves))\n",
    "        np.save(os.path.join(_data, mockname, 'lia', 'inds.npy'), keep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voxel_size_w 0.0001 DONE...\n",
      "voxel_size_w 0.001 DONE...\n",
      "voxel_size_w 0.01 DONE...\n",
      "voxel_size_w 0.1 DONE...\n",
      "voxel_size_w 1 DONE...\n",
      "voxel_size_w BESTFIT:\t 0.01\n",
      "kd3_sr 0.001 DONE...\n",
      "kd3_sr 0.01 DONE...\n",
      "kd3_sr 0.1 DONE...\n",
      "kd3_sr 1.0 DONE...\n",
      "kd3_sr BESTFIT:\t 0.1\n",
      "max_nn 3 DONE...\n",
      "max_nn 5 DONE...\n",
      "max_nn 10 DONE...\n",
      "max_nn 20 DONE...\n",
      "max_nn 50 DONE...\n",
      "max_nn 100 DONE...\n",
      "max_nn BESTFIT:\t 5\n"
     ]
    }
   ],
   "source": [
    "best_fit_lia(mockname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165062 375000\n",
      "leaf area=0.01 \n",
      " voxel_size_w=0.0100 \n",
      " kd3_sr=0.1000 \n",
      " max_nn=5.0000 \n"
     ]
    }
   ],
   "source": [
    "get_lia(mockname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 49026 141233 162125 ... 271647 121208 207455] 63112\n"
     ]
    }
   ],
   "source": [
    "inds_file = os.path.join(resdir, 'inds.npy')\n",
    "inds = np.load(inds_file)\n",
    "print(inds, len(inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   105    106    137 ... 374846 374847 374848] 165062\n"
     ]
    }
   ],
   "source": [
    "inds_lia = np.load(os.path.join(_data, mockname, 'lia', 'inds.npy'))\n",
    "print(inds_lia, len(inds_lia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runall(pointsPR, sensorsPR, inPR, voxel_size, tree, N, PRbounds, resdir, kbins=None):\n",
    "\n",
    "    # resdir = os.path.join(_data, mockname, 'lad_%s' %(str(voxel_size)))\n",
    "    inds_file = os.path.join(resdir, 'inds.npy')\n",
    "    inds0 = np.load(inds_file)\n",
    "\n",
    "    # resdir = os.path.join(_data, mockname, 'lad_%s' %(str(voxel_size)))\n",
    "\n",
    "    inds_lia = np.load(os.path.join(_data, mockname, 'lia', 'inds.npy'))\n",
    "\n",
    "    isfigures = os.path.join(resdir, 'figures')\n",
    "    if not os.path.exists(isfigures):\n",
    "        os.makedirs(isfigures)\n",
    "\n",
    "    attributes2_file = os.path.join(resdir, 'm3s_%s_%s.npy' %(tree, str(voxel_size)))\n",
    "    if os.path.isfile(attributes2_file):\n",
    "        m3b = np.load(attributes2_file)\n",
    "\n",
    "    print('voxel_size:', voxel_size)\n",
    "\n",
    "    m3att = lad.compute_attributes(pointsPR, resdir, voxel_size, tree, PRbounds)\n",
    "\n",
    "    # _,_,_, m3scount = lad.density_counts(pointsPR, voxel_size)\n",
    "\n",
    "    # get in down sample boolean array for LPC size\n",
    "    # mask1 = np.zeros(N, bool)\n",
    "    # mask2 = mask1.copy()\n",
    "\n",
    "    # mask1[inds] = True\n",
    "    # mask2[inds_lia] = True\n",
    "\n",
    "    # lias, ws = lad.downsample_lia(mockname, tree, np.where(mask1[mask2])[0])\n",
    "\n",
    "\n",
    "    # Load LIAs and its weights saved at `get_lia()`.\n",
    "    # Size of lias and ws arrays is the original size after leaf and tree extraction only.\n",
    "    lias, ws = loads.load_lias_ws(mockname, 'tree_0')\n",
    "\n",
    "    # Create  arrays of original size filled with -99\n",
    "    lias0 = np.full(N, -99)\n",
    "    ws0 = np.full(N, -99)\n",
    "\n",
    "    # fill arrays with lias and ws values where it correspond to.\n",
    "    lias0[np.where(inds_lia)[0]] = lias\n",
    "    ws0[np.where(inds_lia)[0]] = ws\n",
    "\n",
    "    # Finally, apply downsampling and second dowsampling to lias and ws.\n",
    "    lias = lias0[inds0[inPR]]\n",
    "    ws = ws0[inds0[inPR]]\n",
    "\n",
    "    try:\n",
    "        assert len(lias) == sum(inPR)\n",
    "    except Exception as e:\n",
    "        print('lias size does not match with Plant Region size.')\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        assert len(ws) == sum(inPR)\n",
    "    except Exception as e:\n",
    "        print('ws size does not match with Plant Region size.')\n",
    "        print(e)\n",
    "\n",
    "    voxk = lad.get_voxk(pointsPR, PRbounds, voxel_size)\n",
    "    bia = lad.get_bia(pointsPR, sensorsPR)\n",
    "    meshfile = lad.get_meshfile(mockname)\n",
    "\n",
    "    # print('----- DEBUG -----')\n",
    "    # print(len(lias), len(ws), len(voxk))\n",
    "\n",
    "    figext = '%s_%s' %(tree, str(voxel_size))\n",
    "    # figext = None\n",
    "    \n",
    "    alphas_k = lad.alpha_k(bia, voxk, lias, ws, resdir, meshfile, figext=figext, \n",
    "                            klia=False, use_true_lia=True)\n",
    "\n",
    "    kmax = m3b.shape[2]\n",
    "    if kbins is None:\n",
    "        kbins = int(kmax/15)\n",
    "    print(kbins)\n",
    "\n",
    "    # Attribute 2 counts per voxel\n",
    "    # outdir_count = os.path.join(resdir, 'm3count_%s_%s.npy' %(tree, str(voxel_size)))\n",
    "    \n",
    "    lads_mid, clai = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6], PRbounds, tree, resdir)\n",
    "    lads_0, _ = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6]*0+1, PRbounds, tree, resdir)\n",
    "    # lads_mid_old, _ = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6], PRbounds, tree, resdir, oldlad=True)\n",
    "    # lads_mid_old = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,6], alpha2=1)\n",
    "    lads_mesh = lad.get_LADS_mesh(meshfile, voxel_size, kbins, kmax, PRbounds)\n",
    "\n",
    "    # lads = {'Truth':lads_mesh, 'Correction Mean':lads_mid, 'No Correction':lads_0, 'Correction Weights':lads_mid_w}#, 'Correction counts':lads_mid_counts}\n",
    "    lads = {'Truth':lads_mesh, 'Correction Mean':lads_mid, 'No Correction':lads_0}\n",
    "    # clai = lad.get_clai(m3att, alphas_k)\n",
    "    attributes_file = os.path.join(resdir, 'm3s_%s_%s.npy' %(tree, str(voxel_size)))\n",
    "    if os.path.isfile(attributes_file):\n",
    "        RT = 'Y'\n",
    "    else:\n",
    "        RT = 'N'\n",
    "        \n",
    "    text = {'tree':tree, 'VS':voxel_size, 'RT':RT, 'CLAI':np.round(clai, 3)}\n",
    "    txt = []\n",
    "    for key, val in text.items():\n",
    "        txt.append('%s=%s \\n' %(key, str(val)))\n",
    "    text = (' ').join(txt)\n",
    "\n",
    "    savefig = os.path.join(resdir, 'figures','LAD_%s.png' %(figext))\n",
    "    figures.plot_lads(lads, text, savefig=savefig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voxel_size: 0.1\n",
      "max --> [30, 34, 10]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (31, 35, 11)\n",
      "ray tracker voxel dimensions: \t (31, 35, 11)\n",
      "Number of voxels ocupied by points cloud: \t 2437\n",
      "Number of voxels ocupied by beam points cloud: \t 7459\n",
      "Total number of voxels in plant regions: \t 11935\n",
      "Number of voxels with attribute 1: \t 2437\n",
      "Number of voxels with attribute 2: \t 7459\n",
      "Number of voxels with attribute 3: \t 2039\n",
      "----- DEBUG -----\n",
      "33145 33145 33145\n",
      "1\n",
      "======= K: 0 =======\n",
      "\t nI0: 2.00\n",
      "\t nI: 0.67\n",
      "\t nP0: 6.33\n",
      "\t nP: 916.00\n",
      "======= K: 1 =======\n",
      "\t nI0: 2.00\n",
      "\t nI: 5.40\n",
      "\t nP0: 27.60\n",
      "\t nP: 887.00\n",
      "======= K: 2 =======\n",
      "\t nI0: 5.00\n",
      "\t nI: 21.18\n",
      "\t nP0: 84.82\n",
      "\t nP: 802.00\n",
      "======= K: 3 =======\n",
      "\t nI0: 47.00\n",
      "\t nI: 83.31\n",
      "\t nP0: 198.69\n",
      "\t nP: 571.00\n",
      "======= K: 4 =======\n",
      "\t nI0: 280.00\n",
      "\t nI: 111.29\n",
      "\t nP0: 147.71\n",
      "\t nP: 342.00\n",
      "======= K: 5 =======\n",
      "\t nI0: 355.00\n",
      "\t nI: 92.71\n",
      "\t nP0: 140.29\n",
      "\t nP: 255.00\n",
      "======= K: 6 =======\n",
      "\t nI0: 170.00\n",
      "\t nI: 103.98\n",
      "\t nP0: 207.02\n",
      "\t nP: 396.00\n",
      "======= K: 7 =======\n",
      "\t nI0: 18.00\n",
      "\t nI: 60.88\n",
      "\t nP0: 189.12\n",
      "\t nP: 641.00\n",
      "======= K: 8 =======\n",
      "\t nI0: 0.00\n",
      "\t nI: 10.05\n",
      "\t nP0: 78.95\n",
      "\t nP: 820.00\n",
      "======= K: 9 =======\n",
      "\t nI0: 0.00\n",
      "\t nI: 0.88\n",
      "\t nP0: 3.12\n",
      "\t nP: 909.00\n",
      "======= K: 10 =======\n",
      "\t nI0: 0.00\n",
      "\t nI: 0.22\n",
      "\t nP0: 1.78\n",
      "\t nP: 920.00\n",
      "sums 2455.0 7459\n",
      "======= K: 0 =======\n",
      "\t nI0: 2.00\n",
      "\t nI: 0.67\n",
      "\t nP0: 6.33\n",
      "\t nP: 916.00\n",
      "======= K: 1 =======\n",
      "\t nI0: 2.00\n",
      "\t nI: 5.40\n",
      "\t nP0: 27.60\n",
      "\t nP: 887.00\n",
      "======= K: 2 =======\n",
      "\t nI0: 5.00\n",
      "\t nI: 21.18\n",
      "\t nP0: 84.82\n",
      "\t nP: 802.00\n",
      "======= K: 3 =======\n",
      "\t nI0: 47.00\n",
      "\t nI: 83.31\n",
      "\t nP0: 198.69\n",
      "\t nP: 571.00\n",
      "======= K: 4 =======\n",
      "\t nI0: 280.00\n",
      "\t nI: 111.29\n",
      "\t nP0: 147.71\n",
      "\t nP: 342.00\n",
      "======= K: 5 =======\n",
      "\t nI0: 355.00\n",
      "\t nI: 92.71\n",
      "\t nP0: 140.29\n",
      "\t nP: 255.00\n",
      "======= K: 6 =======\n",
      "\t nI0: 170.00\n",
      "\t nI: 103.98\n",
      "\t nP0: 207.02\n",
      "\t nP: 396.00\n",
      "======= K: 7 =======\n",
      "\t nI0: 18.00\n",
      "\t nI: 60.88\n",
      "\t nP0: 189.12\n",
      "\t nP: 641.00\n",
      "======= K: 8 =======\n",
      "\t nI0: 0.00\n",
      "\t nI: 10.05\n",
      "\t nP0: 78.95\n",
      "\t nP: 820.00\n",
      "======= K: 9 =======\n",
      "\t nI0: 0.00\n",
      "\t nI: 0.88\n",
      "\t nP0: 3.12\n",
      "\t nP: 909.00\n",
      "======= K: 10 =======\n",
      "\t nI0: 0.00\n",
      "\t nI: 0.22\n",
      "\t nP0: 1.78\n",
      "\t nP: 920.00\n",
      "sums 2455.0 7459\n",
      "0.1 1 16.1 16.1\n"
     ]
    }
   ],
   "source": [
    "inPR = (leaves) & (trees['tree_0'])\n",
    "runall(POINTS[inPR], SENSORS[inPR], inPR, voxel_size, 'tree_0', N, (minpointPR, maxpointPR), resdir, kbins=1)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "760a6cd4159ac8b99590d0ad7ba9faed7c379184a996bf44e62e475912739812"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('plant-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
