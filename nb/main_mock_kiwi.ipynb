{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# basedir = os.path.dirname(os.getcwd())\n",
    "basedir = os.path.abspath(os.path.join(os.getcwd() ,\"../\"))\n",
    "_py = os.path.join(basedir, 'py')\n",
    "_data = os.path.join(basedir, 'data')\n",
    "\n",
    "sys.path.insert(1, _py)\n",
    "import loads\n",
    "import lia\n",
    "import ray as rayt\n",
    "import lad\n",
    "import figures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Data structure\n",
    "\n",
    "```\n",
    "root\n",
    "│   requirements.yml\n",
    "│   readme.md  \n",
    "│\n",
    "└───data\n",
    "│   └───test\n",
    "│       │   s0100000.numpy\n",
    "│       │   s0200000.numpy\n",
    "│       │   ...\n",
    "│       │   mesh.ply\n",
    "│       │   scanner_pos.txt\n",
    "│   \n",
    "└───py\n",
    "    │   loads.py\n",
    "    │   lia.py\n",
    "    │   lad.py\n",
    "    │   ray.py\n",
    "    │   figures.py\n",
    "\n",
    "```\n",
    "\n",
    "## Blensor output transformation\n",
    "\n",
    "Most of the functions used in this chapter need:\n",
    "\n",
    "``` Python\n",
    "import loads\n",
    "```\n",
    "\n",
    "In order to get the `LIA` and hence the `LAD`, we need to segmentated the trees and the leaves.\n",
    "\n",
    "First, we define the name of the directory where the Blensor output data is, in this particular case we will look for directory `test`. Pipeline will look for this directory inside the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mockname = 'test_kiwi'\n",
    "# mockname = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next, we convert Blensor output `txt` files that have fake `numpy` extension to real `npy`. This is done trhough function `loads.numpy2npy()` as shown below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0500000.numpy done --> Number of beams: 62500\n",
      "s0200000.numpy done --> Number of beams: 62500\n",
      "s0400000.numpy done --> Number of beams: 62500\n",
      "s0100000.numpy done --> Number of beams: 62500\n",
      "s0600000.numpy done --> Number of beams: 62500\n",
      "s0300000.numpy done --> Number of beams: 62500\n"
     ]
    }
   ],
   "source": [
    "loads.numpy2npy(mockname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Transforming to `npy` reduce the size of files, besides is much faster to load than the Blensor `txt` output files.\n",
    "```\n",
    "\n",
    "The structure looks like,\n",
    "\n",
    "```\n",
    "root\n",
    "|\n",
    "└───data\n",
    "    └───test\n",
    "        │   s0100000.numpy\n",
    "        │   s0200000.numpy\n",
    "        │   ...\n",
    "        │   mesh.ply\n",
    "        │   scanner_pos.txt\n",
    "        │   s0100000.npy\n",
    "        │   s0200000.npy\n",
    "        │   ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree and leaves segmentation\n",
    "\n",
    "Now we create the module to segmentate trees. This will be tuned acordingly for each data set, so below module only works for this particular data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segtree(df, leaves, show=False):\n",
    "\n",
    "    trees = {}\n",
    "\n",
    "    if show:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # centres\n",
    "    x, y = [0], [0]\n",
    "    num = 0\n",
    "    dx, dy = 2, 2\n",
    "    # dx, dy = 5, 5\n",
    "\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            \n",
    "            keep = np.ones(len(df['x']), dtype=bool)\n",
    "            keep &= (df['x'] < i+dx) & (df['x'] > i-dx)\n",
    "            keep &= (df['y'] < j+dy) & (df['y'] > j-dy)\n",
    "\n",
    "            trees['tree_%s' %(str(num))] = keep\n",
    "            \n",
    "            if show:\n",
    "                plt.scatter(df['x'][leaves & keep], df['y'][leaves & keep], s=0.5, label=num)\n",
    "                        \n",
    "            num += 1\n",
    "\n",
    "    if show:\n",
    "        plt.legend()\n",
    "    \n",
    "    return trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We segmentate the trees below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# load data into a pandas data frame\n",
    "df = loads.npy2pandas(mockname)\n",
    "# extract leaves. Boolean array output\n",
    "leaves = loads.extract_leaves(df, show=True)\n",
    "# extract trees. Dictionary with boolean arrays output\n",
    "trees = segtree(df, leaves, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! So what we just did? First, with function `loads.npy2pandas()` we load all the `npy` files into a pandas DataFrame (`DF`) and we add three more columns with the $x$, $y$, and $z$ positions of the sensors that are stored in file `scanner_pos.txt`. Then, since this is a mockup dataset, we can easily separate the leaves from everythin else in the point cloud (`PC`). We do this with function `loads.extract_leaves()` that requires the pandas `DF` as input. Finally, we invoke the above module to segmentate trees that requires the pandas `DF` as well.\n",
    "\n",
    "outputs from this are:\n",
    "\n",
    "- `df`: Pandas DF with the entire PC\n",
    "- `leaves`: numpy boolean array of PC dimensions with True for Points concerning leaves only\n",
    "- `trees`: python dictionary where each entry contains one tree in the form of boolena array with PC dimensions\n",
    "\n",
    "Below piece of code shows an example of how to visualize the leaves points from one tree only, this will be know as the `Leaves Point Cloud` (LPC) and is shown in Fig. {numref}`lpc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below piece of code shows an example of how to visualize the leaves points from one tree only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# show the point cloud from leaves of firs tree only\n",
    "keep = (trees['tree_0']) & (leaves)\n",
    "loads.showPCfromDF(df[keep])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the subsequent chapters we will be comparing our estimations with the *True* values using the `mesh.ply` file located in the root directory `test`. The following piece of code shows how we can visualize this mesh that requires importing the library `lad`. Fig. {numref}`mesh` show this mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "import lad\n",
    "meshfile = lad.get_meshfile(mockname)\n",
    "lad.see_mesh(meshfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Leaf Inclination Angle` (LIA) estimation\n",
    "\n",
    "## Intro\n",
    "\n",
    "Most functions used in this chapter are in library:\n",
    "\n",
    "``` Python\n",
    "import lia\n",
    "```\n",
    "\n",
    "Outputs will be placed inside directory `lia`,\n",
    "\n",
    "```\n",
    "root\n",
    "└───data\n",
    "    └───test\n",
    "        │   s0100000.numpy\n",
    "        │   s0200000.numpy\n",
    "        │   ...\n",
    "        │   mesh.ply\n",
    "        │   scanner_pos.txt\n",
    "        │   s0100000.npy\n",
    "        │   s0200000.npy\n",
    "        │   ...\n",
    "        └───lia\n",
    "            │   angles_<treename>.npy\n",
    "            │   weights_<treename>.npy\n",
    "            │   leaf_angle_dist_<treename>.png\n",
    "            │   leaf_angle_dist_height_<treename>.png\n",
    "            │   bestfits_pars_treename>.png\n",
    "\n",
    "```\n",
    "\n",
    "## The method (`lia.leaf_angle()`)\n",
    "\n",
    "The main function that computes the LIA is `lia.leaf_angle()` which uses a KDtree approximation. The steps are as follow: \n",
    "\n",
    "1. `Compute normals`: This method fits a plane based on the nearesth neighbors for each point and gets the normal of this plane.\n",
    "    \n",
    "2. `Compute zenith angles`: Then, using the dot product with get the angle with respect to the zenith (i.e. agains vector (0, 0, 1)) \n",
    "    \n",
    "3. `Range correction`: The results angles run from $0 < \\theta < 180$, however we require these to be in the range $0 < \\theta < 90$ therefore we transfom those angles $> 90$ with relation:\n",
    "\n",
    "```{math}\n",
    ":label: angcorr\n",
    "\\theta_{L} = 180 - \\theta\n",
    "```\n",
    "\n",
    "4. `Weights correction`: The resulting LIA is biased to PC density and completeness. In order to reduce this biases, we compute weights via voxelization,\n",
    "\n",
    "```{math}\n",
    ":label:\n",
    "\\eta_{i} = n_{i}/L^{3} \\\\\n",
    "  \\bar{\\eta} = \\frac{1}{N}\\sum_{i=0}^{N} \\eta{i}\n",
    "```\n",
    "\n",
    "where $n_{i}$ is the number of points within voxel $i$, $L$ is the voxel size, and $N$ is the total number of voxels, then $\\eta_{i}$ is the volume density of voxel $i$, and $\\bar{\\eta}$ is the mean volume density.\n",
    "\n",
    "The function `lia.leaf_angle()` has to be ran per tree and requieres 6 input parameters:\n",
    "\n",
    "- `points`: $x$, $y$ and $z$ coordinates of the leaf point cloud (LPC).\n",
    "- `mockname`: name of directory where the data is.\n",
    "- `treename`: name/index of tree.\n",
    "- `voxel_size_w`: voxel size for `weights correction` i.e. $L$.\n",
    "- `kd3_sr`: KDtree searching radius for the nearest neighboors serch.\n",
    "- `max_nn`: Maximum number of nearest neightbors to be considered.\n",
    "\n",
    "This function returns a set of files inside directory `lia`:\n",
    "\n",
    "- `angles_<treename>.npy`: LIA for the LPC. One file per tree.\n",
    "- `weights_<treename>.npy`: LIA weights for the LPC. One file per tree.\n",
    "- `leaf_angle_dist_<treename>.png`: Figure of LIA ($\\theta_{L}$) distribution with `weights correction`. If `Truth` LIA available, this will be shown alongside. One figure per tree.\n",
    "- `leaf_angle_dist_height_<treename>.png`: Top - Figure of LPC distribution accross different heights in terms of voxels $k$. Bottom - If `Truth` LIA available, $\\theta_{L}^{truth} - \\theta_{L}$. The different curves show this for different heights ($k$). One figure per tree.\n",
    "\n",
    "## Look for best-fit `voxel_size_w`, `kd3_sr` and `max_nn` with `lia.bestfit_pars_la()`\n",
    "\n",
    "If truth LIA available i.e. there's a mesh file `mesh.ply` in the `test` directory, then we will be able to run function `lia.bestfit_pars_la()` which essentialy runs `lia.leaf_angle()` for a range of values in `voxel_size_w`, `kd3_sr` and `max_nn` and find the best-fit for these three based on the minimal $\\chi^{2}$ between the estimated LIA and the truth LIA.\n",
    "\n",
    "`lia.bestfit_pars_la()` is as well ran per tree and requires only `points`, `mockname` and `treename`. It returns `bestfit_<treename>.npy` file that contains the `voxel_size_w`, `kd3_sr` and `max_nn` best-fit values per tree. it also returns a dictionary with the $\\chi^{2}$ for each of these runs.\n",
    "\n",
    "Using output dictionary from `bestfit_pars_la` we can run `bestfit_pars_la` to create figure `bestfits_pars_treename>.png` that shows the $\\chi^{2}$ for all the ranges used in `voxel_size_w`, `kd3_sr` and `max_nn`.\n",
    "\n",
    "```{admonition} To-Do\n",
    ":class: important\n",
    "Current LIA implementation works without `Truth` LIA, however, we need it to estimate the best-fits `voxel_size_w`, `kd3_sr` and `max_nn` parameters. We need to find the relation between these three and LPC that could rely on the LPC density, leaf size, leaf area, etc.\n",
    "```\n",
    "\n",
    "The piece of code bellow runs `lia.bestfit_pars_la()` and `lia.best_fit_pars_plot()` for each tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voxel_size_w 0.0001 DONE...\n",
      "voxel_size_w 0.001 DONE...\n",
      "voxel_size_w 0.01 DONE...\n",
      "voxel_size_w 0.1 DONE...\n",
      "voxel_size_w 1 DONE...\n",
      "voxel_size_w BESTFIT:\t 0.01\n",
      "kd3_sr 0.001 DONE...\n",
      "kd3_sr 0.01 DONE...\n",
      "kd3_sr 0.1 DONE...\n",
      "kd3_sr 1.0 DONE...\n",
      "kd3_sr BESTFIT:\t 0.1\n",
      "max_nn 3 DONE...\n",
      "max_nn 5 DONE...\n",
      "max_nn 10 DONE...\n",
      "max_nn 20 DONE...\n",
      "max_nn 50 DONE...\n",
      "max_nn 100 DONE...\n",
      "max_nn BESTFIT:\t 5\n"
     ]
    }
   ],
   "source": [
    "for key, val in trees.items():\n",
    "\n",
    "    keep = (val) & (leaves) # take the LPC per tree\n",
    "    df_ = df[['x', 'y', 'z']][keep]\n",
    "    points = loads.DF2array(df_)\n",
    "    res = lia.bestfit_pars_la(points, mockname, treename=key)\n",
    "    lia.best_fit_pars_plot(res, key, mockname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once we find the best-fit parameters we get figure `bestfits_pars_treename>.png` that is shown in Fig. {numref}`bestfits_pars`. we use these best fits to run `lia.leaf_angle()` and get the LIA and corresponding weigths per tree. The code that does that is shown below and in Fig. {numref}`lia_dist` we show `leaf_angle_dist_<treename>.png` and in Fig. {numref}`lia_dist_h` `leaf_angle_dist_height_<treename>.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf area=0.01 \n",
      " voxel_size_w=0.0100 \n",
      " kd3_sr=0.1000 \n",
      " max_nn=5.0000 \n"
     ]
    }
   ],
   "source": [
    "# load bestfit results\n",
    "for key, val in trees.items():\n",
    "\n",
    "    keep = (val) & (leaves)\n",
    "    df_ = df[['x', 'y', 'z']][keep]\n",
    "    points = loads.DF2array(df_)\n",
    "\n",
    "    bestfit_file = os.path.join(_data, mockname, 'lia', 'bestfit_%s.npy' %(key))\n",
    "    res = np.load(bestfit_file, allow_pickle=True)\n",
    "    res = res.tolist()\n",
    "\n",
    "    text = 'leaf area=%.2f \\n %s=%.4f \\n %s=%.4f \\n %s=%.4f ' %(res['leafsize'], 'voxel_size_w', res['voxel_size_w_bestfit'],'kd3_sr', res['kd3_sr_bestfit'],'max_nn', res['max_nn_bestfit'])\n",
    "    print(text)\n",
    "\n",
    "    chi2 = lia.leaf_angle(points, mockname, key, res['voxel_size_w_bestfit'], \n",
    "                            res['kd3_sr_bestfit'], res['max_nn_bestfit'], save=True,\n",
    "                                savefig=True, text=text)\n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `\u001dLeaf Area Density` (LAD) estimation\n",
    "\n",
    "## Intro\n",
    "\n",
    "Most functions used in this chapter are in library:\n",
    "\n",
    "``` Python\n",
    "import lad\n",
    "```\n",
    "\n",
    "The LAD method implemented here uses the `Voxel 3D contact-bases frecuency` method first introduced by `HOSOI AND OMASA: VOXEL-BASED 3-D MODELING OF INDIVIDUAL TREES FOR ESTIMATING LAD`.\n",
    "\n",
    "The model looks like:\n",
    "\n",
    "```{math}\n",
    ":label:\n",
    "LAD(h, \\Delta H) = \\frac{1}{\\Delta H} \\sum_{k=m_{h}}^{m_{h}+\\Delta H} l(k),\n",
    "```\n",
    "\n",
    "where,\n",
    "\n",
    "```{math}\n",
    ":label:\n",
    "l(k) = \\alpha(\\theta)N(k) \\\\\n",
    "    = \\alpha(\\theta) \\cdot \\frac{n_{I}(k)}{n_{I}(k) + n_{P}(k)}.\n",
    "```\n",
    "\n",
    "$l(k)$ is the `Leaf Area Index` (LAI) of the kth horizontal layer of the voxel array within a plant region, $\\Delta H$ is the horizontal layer thickness, and $m_{h}$ and $m_{h}+\\Delta H$ are the voxel coordinates on the vertical axis equivalent to height $h$ and $h+\\Delta H$ in orthogonal coordinates ($h = \\Delta k \\times m_{h}$). The LAI of the kth horizontal layer $l(k)$ is the product of the contact frequency $N(k)$ of laser beams in the kth layer and the coefficient $\\alpha(\\theta)$, which corrects for leaf inclination at laser incident zenith angle $\\theta$.\n",
    "\n",
    "$n_{I}(k)$ is the number of voxels where the laser beams is intercepted by the kth layer, $n_{P}(k)$ is the number of voxels where the laser beams passed through the kth layer, and $n_{I}(k) + n_{P}(k)$ is the total number of voxels where the incident laser beams reach the kth layer.\n",
    "\n",
    "Despite the complexity of this method, it requieres only one parameter, the `voxel_size`. We will introduce a second parameter, the `downsample` whose importance will be explained later. The main steps towards LAD estimation are:\n",
    "\n",
    "1. Computing $n_{P}(k)$\n",
    "2. Computing $n_{I}(k)$\n",
    "3. Computing $\\alpha(\\theta)$\n",
    "4. Estimate LAD\n",
    "\n",
    "For this example, we will usea a `voxel_size` = 0.2 and `downsample` = 0.05 which means that we downsample our whole data to only $5\\%$. A reminder that as well as in for the LIA, the following process is per tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample = 0.1\n",
    "voxel_size = 0.2\n",
    "# to check everything looks fine\n",
    "show = True\n",
    "sample = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing $n_{P}(k)$\n",
    "\n",
    "Seeing where the beam pass through in the voxelize `Plant Region` (PR) is a tipycal ray tracing problem and it's reduced to see whether the ray hit or not an axis align bounding box (AABB).\n",
    "\n",
    "The below module grabs the requiered downsample percentge of the data with a random subsample and if it's the first time we ran this, it will create the directory `lad_<downsmple>`. All the subsequent results will be stored inside this directory. The first time a particular downsample is ran, it will store the file `inds.npy` containing a boolean array with size of the pandas DF where True being the selected random subsample requested. If we change the `voxel_size` but not the `downsample`, then the below module will look first for the `inds.npy` instead of searching for another random subsample, this to maintain uniformity between different voxels sizes approaches.\n",
    "\n",
    "The function `main` does the magic here, it has to be ran per tree and requires 6 input parameters:\n",
    "\n",
    "- `points`: $x$, $y$ and $z$ coordinates from the downsample data in the form of numpy array.\n",
    "- `sensors`: $x$, $y$ and $z$ coordinates of sensor responsible from each point in `points` parameter above.\n",
    "- `pointsPR`: `points` above filtered to the LPC.\n",
    "- `voxel_size`: Voxel Size.\n",
    "- `resdir`: Name of output directory for the specific `downsample`.\n",
    "- `treename`: Name/index of tree.\n",
    "\n",
    "```{note}\n",
    "`pointsPR` is require to get the same voxelization dimensions as in $n_{I}$.\n",
    "```\n",
    "This function returns two files:\n",
    "\n",
    "- `m3s_<treename>_<voxel_size>.npy`: numpy boolean 3D-array with number of voxels dimensions. True if a beam hit the voxel.\n",
    "- `m3count_<treename>_<voxel_size>.npy`: numpy 3D-array with number of voxels dimensions. Each entry contains the number of beams that passed trhough that voxel.\n",
    "\n",
    "```{admonition} To-Do\n",
    ":class: important\n",
    "Note that this is the slowest module of the entire pipeline, taking up to 5 minutes for a sample of 10,000 beams. This can be improved easlily if binding with a `C++` ray AABB module instead.\n",
    "```\n",
    "\n",
    "Below we show the piece of code that computes this,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "POINTS = loads.DF2array(df[['x', 'y', 'z']])\n",
    "SENSORS = loads.DF2array(df[['sx', 'sy', 'sz']])\n",
    "\n",
    "def get_rays(downsample, voxel_size, sample=None, show=False):\n",
    "\n",
    "    if downsample is not None:\n",
    "\n",
    "        resdir = os.path.join(_data, mockname, 'lad_%s' %(str(downsample)))\n",
    "        if not os.path.exists(resdir):\n",
    "            os.makedirs(resdir)\n",
    "\n",
    "        outdir = os.path.join(resdir, 'inds.npy')\n",
    "        if os.path.exists(outdir):\n",
    "            print('inds file already exists for donwnsample of %.3f at %s' %(downsample, outdir))\n",
    "\n",
    "            inds = np.load(outdir)\n",
    "\n",
    "            points = POINTS[inds]\n",
    "            sensors = SENSORS[inds]\n",
    "\n",
    "        else:\n",
    "\n",
    "            print('inds not been created yet for donwnsample of %.3f' %(downsample))\n",
    "            idx = np.random.randint(0, len(df), int(len(df) * downsample))\n",
    "            inds = np.zeros(len(df), dtype=bool)\n",
    "            inds[idx] = True\n",
    "\n",
    "            points = POINTS[inds]\n",
    "            sensors = SENSORS[inds]\n",
    "\n",
    "            np.save(outdir, inds)\n",
    "\n",
    "    else:\n",
    "\n",
    "        resdir = os.path.join(_data, mockname, 'lad')\n",
    "        if not os.path.exists(resdir):\n",
    "            os.makedirs(resdir)\n",
    "\n",
    "    if sample is not None:\n",
    "\n",
    "        idx = np.random.randint(0, len(df), int(sample))\n",
    "        points = POINTS[idx]\n",
    "        sensors = SENSORS[idx]\n",
    "\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        inPR = (val) & (leaves) & (inds)\n",
    "        pointsPR = POINTS[inPR]\n",
    "        m3s = rayt.main(points, sensors, pointsPR, voxel_size, resdir, key, show=show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing $n_{I}(k)$\n",
    "\n",
    "The $n_{I}$ per voxel is computed in function `lad.compute_attributes()`. It essentialy voxelize the LPC to get the PR dimensions (which have to be the same as in $n_{P}$). Then, for a numpy boolean 3D-array with voxelize PR dimensions, we fill it with True if there's a point in the voxel.\n",
    "\n",
    "This function looks for previous `m3s_<treename>_<voxel_size>.npy` result and get the attributes in the form of the same size numpy 3D-array (`m3att`). The attributes are:\n",
    "\n",
    "- 1 if any LPC in that voxel\n",
    "- 2 if any beam pass trhough that  voxel\n",
    "- 3 if none of previous\n",
    "\n",
    "It requires 4 input parameters `pointsPR`, `resdir`, `voxel_size`, `treename` which were defined in section {ref}`sec:np`. It returns the attributes numpy 3D-array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing $\\alpha(\\theta)$\n",
    "\n",
    "$\\alpha(\\theta)$ is expressed in terms of $G(\\theta)$, \n",
    "\n",
    "```{math}\n",
    ":label:\n",
    "\\alpha(\\theta) = \\frac{\\cos(\\theta)}{G(\\theta)},\n",
    "```\n",
    "\n",
    "where $G(\\theta)$ is the mean projection of a unit leaf area on a plane perpendicular to the direction of the laser beam. This quantity is determined with the assumption that leaves are positioned symmetrically with respect to the azimuth anc can be represented as:\n",
    "\n",
    "```{math}\n",
    ":label:\n",
    "G(\\theta) =  \\sum_{q=1}^{T_{q}} g(q) S(\\theta, \\theta_{L}(q))\n",
    "```\n",
    "\n",
    "where $S(\\theta, \\theta_{L}(q))$ is expresed in terms of the leaf inclination angle (LIA) $\\theta_{L}$ (the zenith angle of the normal to the leaf surface), and $\\theta$ is the laser-beam incident zenith angle:\n",
    "\n",
    "```{math}\n",
    ":label:\n",
    "S(\\theta, \\theta_{L}) = \\cos\\theta \\cos \\theta_{L}, \\hspace{.5cm} \\textrm{for } \\theta \\leq \\pi/2 - \\theta_{L}\n",
    "```\n",
    "\n",
    "```{math}\n",
    ":label:\n",
    "S(\\theta, \\theta_{L}) = \\cos\\theta \\cos \\theta_{L} \\left[ 1 + \\frac{2}{\\pi}(\\tan x - x) \\right], \\hspace{.5cm} \\textrm{for } \\theta \\gt \\pi/2 - \\theta_{L}\n",
    "```\n",
    "\n",
    "```{math}\n",
    ":label:\n",
    "x = \\cos^{-1}\\left( \\cot \\theta \\cot \\theta_{L} \\right).\n",
    "```\n",
    "\n",
    "Here $q$ is the leaf-inclination-angle class and Tq is the total number of leaf-inclination-angle classes. Thus, if there are $18$ leaf-inclination-angle classes from $0◦$ to $90◦$ ($Tq = 18$), then each class consists of a $5◦$ interval. For example, $q = 1$, $q = 9$, and $q = 16$ include the angles from $0◦$ to $4◦$, $40◦$ to $44◦$, and $75◦$ to $79◦$, respectively. $g(q)$ is the distribution of the leaf-inclination-angle class $q$, which is a ratio of the leaf area belonging to class $q$ to total leaf area; $θ_{L}(q)$ is the midpoint angle of class $q$, which is the leaf-inclination angle used to represent class $q$.\n",
    "\n",
    "This process is done trhough function `lad.Gtheta()`. In function `lad.alpha_k()` we compute $\\alpha(\\theta)$ for the median of $\\theta$, the Beam Inclination Angles (BIA) with respect to zenith, in the Kth layer. We made use of the files `angles_<treename>.npy` and `weights_<treename>.npy` we store previously in the directory `lia` to get $g(q)$. The function `lad.alpha_k()` create three figures inside the `figures` directory:\n",
    "\n",
    "- `alphas_<treename>_<voxel_size>.png`\n",
    "- `bia_<treename>_<voxel_size>.png`\n",
    "- `bia_per_k_<treename>_<voxel_size>.png`\n",
    "\n",
    "Examples of this three figures can be found in Figures {numref}`alphasplot`, {numref}`biaplot`, and {numref}`biakplot` for a `downsample` of $5 \\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate LAD\n",
    "\n",
    "Now that we have $\\alpha(\\theta)$ in the Kth layer (i.e. $\\alpha(\\theta, k)$), we can compute the LAI and therefore the LAD. We do this in function `lad.get_LADS()` which requires 4 input parameters:\n",
    "\n",
    "- `m3att`: The numpy 3D-array attributes we derive in section {ref}`sec:ni`\n",
    "- `voxel_size`: Voxel Size.\n",
    "- `kbins`: $\\Delta H$ in lengths if K.\n",
    "- `alphas_k`: `lad.alpha_k()` function output.\n",
    "\n",
    "This returns a numpy 2D-array with the height and LAD for the corresponding height with zero being the bottom of the PR.\n",
    "\n",
    "Finally, with function `figures.plot_lads()` we plot LAD as a function of height for:\n",
    "\n",
    "1. Using correction of $\\alpha(\\theta, K)$ taking the median of $\\theta$ in the Kth layer.\n",
    "2. Without $\\alpha(\\theta, K)$ correction\n",
    "3. Truth LAD from mesh file.\n",
    "\n",
    "The piece of code below we show all the above mentioned steps plus other minor steps. The output figure is saved in directory `figures` with name `LAD_<treename>_<voxel_size>.png` and shown in Fig. {numref}`ladplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runall(downsample, voxel_size, kbins=None):\n",
    "    \n",
    "    if downsample is not None:\n",
    "        resdir = os.path.join(_data, mockname, 'lad_%s' %(str(downsample)))\n",
    "        inds_file = os.path.join(resdir, 'inds.npy')\n",
    "        inds = np.load(inds_file)\n",
    "        print('downsample:', downsample)\n",
    "    else:\n",
    "        inds = np.ones(len(df), dtype=bool)\n",
    "        resdir = os.path.join(_data, mockname, 'lad')\n",
    "\n",
    "    isfigures = os.path.join(resdir, 'figures')\n",
    "    if not os.path.exists(isfigures):\n",
    "        os.makedirs(isfigures)\n",
    "\n",
    "    print('voxel_size:', voxel_size)\n",
    "\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        inPR = (val) & (leaves) & (inds)\n",
    "        pointsPR = POINTS[inPR]\n",
    "        sensorsPR = SENSORS[inPR]\n",
    "\n",
    "        m3att = lad.compute_attributes(pointsPR, resdir, voxel_size, key)\n",
    "\n",
    "        _,_,_, m3scount = lad.density_counts(pointsPR, voxel_size)\n",
    "\n",
    "        # get in down sample boolean array for LPC size\n",
    "        inds_ = inds[(val) & (leaves)]\n",
    "        lias, ws = lad.downsample_lia(mockname, key, inds_)\n",
    "        voxk = lad.get_voxk(pointsPR, voxel_size)\n",
    "        bia = lad.get_bia(pointsPR, sensorsPR)\n",
    "        meshfile = lad.get_meshfile(mockname)\n",
    "\n",
    "        figext = '%s_%s' %(key, str(voxel_size))\n",
    "        # figext = None\n",
    "        alphas_k = lad.alpha_k(bia, voxk, lias, ws, resdir, meshfile, figext=figext, \n",
    "                                klia=False, use_true_lia=True)\n",
    "\n",
    "        kmax = m3att.shape[2]\n",
    "        if kbins is None:\n",
    "            kbins = int(kmax/15)\n",
    "        print(kbins)\n",
    "\n",
    "        # Attribute 2 counts per voxel\n",
    "        outdir_count = os.path.join(resdir, 'm3count_%s_%s.npy' %(key, str(voxel_size)))\n",
    "        \n",
    "        # print('******* outdir_count', outdir_count)\n",
    "\n",
    "        \n",
    "        # lads_min = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,2], 1)\n",
    "        # lads_max = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,4], 1)\n",
    "        lads_mid = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,6], 1)\n",
    "\n",
    "        # try:\n",
    "        #     m3pcount = np.load(outdir_count)\n",
    "        #     lads_mid_w = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,6], 1, m3scount=m3scount, m3pcount=m3pcount)\n",
    "        #     lads_mid_counts = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,6], 1, m3scount=m3scount, usecounts=True, m3pcount=m3pcount)\n",
    "        # except:\n",
    "        #     print('no %s' %(outdir_count))\n",
    "\n",
    "        lads_0 = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,6]*0+1, 1.0)\n",
    "        lads_mesh = lad.get_LADS_mesh(meshfile, voxel_size, kbins, kmax)\n",
    "\n",
    "        # lads = {'Truth':lads_mesh, 'Correction Mean':lads_mid, 'No Correction':lads_0, 'Correction Weights':lads_mid_w}#, 'Correction counts':lads_mid_counts}\n",
    "        lads = {'Truth':lads_mesh, 'Correction Mean':lads_mid, 'No Correction':lads_0}\n",
    "        clai = lad.get_clai(m3att, alphas_k)\n",
    "        attributes_file = os.path.join(resdir, 'm3s_%s_%s.npy' %(key, str(voxel_size)))\n",
    "        if os.path.isfile(attributes_file):\n",
    "            RT = 'Y'\n",
    "        else:\n",
    "            RT = 'N'\n",
    "            \n",
    "        text = {'tree':key, 'VS':voxel_size, 'DS':downsample, 'RT':RT, 'CLAI':np.round(clai, 3)}\n",
    "        txt = []\n",
    "        for key, val in text.items():\n",
    "            txt.append('%s=%s \\n' %(key, str(val)))\n",
    "        text = (' ').join(txt)\n",
    "\n",
    "        savefig = os.path.join(resdir, 'figures','LAD_%s.png' %(figext))\n",
    "        figures.plot_lads(lads, text, savefig=savefig)\n",
    "\n",
    "    # return m3pcounts, m3scount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsample: 0.2\n",
      "voxel_size: 0.1\n",
      "max --> [30, 34, 10]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (31, 35, 11)\n",
      "ray tracker voxel dimensions: \t (31, 35, 11)\n",
      "Number of voxels ocupied by points cloud: \t 2418\n",
      "Number of voxels ocupied by beam points cloud: \t 7506\n",
      "Total number of voxels in plant regions: \t 11935\n",
      "Number of voxels with attribute 1: \t 2418\n",
      "Number of voxels with attribute 2: \t 7506\n",
      "Number of voxels with attribute 3: \t 2011\n",
      "max --> [30, 34, 10]\n",
      "min --> [0, 0, 0]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "downsample = 0.2\n",
    "voxel_size = 0.1\n",
    "\n",
    "runall(downsample, voxel_size, kbins=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 35, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3scount.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 35, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3pcounts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 74791\n"
     ]
    }
   ],
   "source": [
    "a = m3scount[:,:,1].sum()\n",
    "b = m3pcounts[:,:,1].sum()\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.00010954252303816187\n",
      "1 0.0028265536045224858\n",
      "2 0.009177660739427438\n",
      "3 0.03327934598179855\n",
      "4 0.08579118819726565\n",
      "5 0.10609558426248833\n",
      "6 0.07914677003187354\n",
      "7 0.03337338744416986\n",
      "8 0.01074671533674175\n",
      "9 0.0011161103554113913\n",
      "10 0.00017818324364776735\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for k in range(m3scount.shape[2]):\n",
    "\n",
    "    a = (m3scount[:,:,k] != 0).sum()\n",
    "    b = (m3pcounts[:,:,k] != 0).sum()\n",
    "    lai = a / (a + b)\n",
    "\n",
    "    a1 = m3scount[:,:,k].sum()\n",
    "    b1 = m3pcounts[:,:,k].sum()\n",
    "    lai1 = a1 / (a1 + b1)\n",
    "\n",
    "    print(k, lai1)\n",
    "\n",
    "    res.append([k, lai, lai1])\n",
    "\n",
    "res = np.array(res)\n",
    "res.T[1]\n",
    "\n",
    "plt.plot(res.T[0], res.T[1], marker='o', label='voxel count')\n",
    "plt.plot(res.T[0], res.T[2], marker='o', label='point count')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inds not been created yet for donwnsample of 0.500\n",
      "max --> [30, 34, 10]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1107it [00:12, 91.66it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4l/bbjl67b151l_mb_20rk6glxh0000gn/T/ipykernel_35412/3520044918.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mget_rays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoxel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/4l/bbjl67b151l_mb_20rk6glxh0000gn/T/ipykernel_35412/317020475.py\u001b[0m in \u001b[0;36mget_rays\u001b[0;34m(downsample, voxel_size, sample, show)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0minPR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mpointsPR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOINTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minPR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mm3s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrayt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpointsPR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoxel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/planttech/py/ray.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(points, sensors, pointsPR, voxel_size, resdir, treename, show)\u001b[0m\n\u001b[1;32m    538\u001b[0m                 \u001b[0midx_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0;31m# Does voxel where ray pass trhough is in a voxel occupied by point cloud?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m                 \u001b[0minm3p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoxp_idx_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36min1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/plant-env/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36min1d\u001b[0;34m(ar1, ar2, assume_unique, invert)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;31m# Ravel both arrays, behavior for the first array could be different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0mar1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m     \u001b[0mar2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;31m# Check if one of the arrays may contain arbitrary objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/plant-env/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "downsample = 0.5\n",
    "voxel_size = 0.1\n",
    "# to check everything looks fine\n",
    "show = False\n",
    "sample = None\n",
    "\n",
    "get_rays(downsample, voxel_size, sample, show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inds file already exists for donwnsample of 0.200 at /Users/omar/projects/planttech/data/test/lad_0.2/inds.npy\n",
      "max --> [188, 182, 116]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28463it [27:36, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 4046679\n",
      "voxels hitted: \t 1963773\n",
      "Percentage of voxels hitted by beam: 0.49\n",
      "voxels hitted (OLD): \t 2052638\n",
      "Percentage of voxels hitted by beam (OLD): 0.51\n",
      "inds file already exists for donwnsample of 0.200 at /Users/omar/projects/planttech/data/test/lad_0.2/inds.npy\n",
      "max --> [117, 113, 73]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28463it [15:20, 30.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 995448\n",
      "voxels hitted: \t 703584\n",
      "Percentage of voxels hitted by beam: 0.71\n",
      "voxels hitted (OLD): \t 763198\n",
      "Percentage of voxels hitted by beam (OLD): 0.77\n",
      "inds file already exists for donwnsample of 0.200 at /Users/omar/projects/planttech/data/test/lad_0.2/inds.npy\n",
      "max --> [94, 91, 58]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28463it [14:14, 33.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 515660\n",
      "voxels hitted: \t 394125\n",
      "Percentage of voxels hitted by beam: 0.76\n",
      "voxels hitted (OLD): \t 435077\n",
      "Percentage of voxels hitted by beam (OLD): 0.84\n",
      "inds not been created yet for donwnsample of 0.400\n",
      "max --> [189, 182, 119]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52020it [53:25, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 4172400\n",
      "voxels hitted: \t 2757125\n",
      "Percentage of voxels hitted by beam: 0.66\n",
      "voxels hitted (OLD): \t 2904096\n",
      "Percentage of voxels hitted by beam (OLD): 0.70\n",
      "inds file already exists for donwnsample of 0.400 at /Users/omar/projects/planttech/data/test/lad_0.4/inds.npy\n",
      "max --> [118, 114, 74]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52020it [30:06, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 1026375\n",
      "voxels hitted: \t 816348\n",
      "Percentage of voxels hitted by beam: 0.80\n",
      "voxels hitted (OLD): \t 888328\n",
      "Percentage of voxels hitted by beam (OLD): 0.87\n",
      "inds file already exists for donwnsample of 0.400 at /Users/omar/projects/planttech/data/test/lad_0.4/inds.npy\n",
      "max --> [94, 91, 59]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52020it [27:27, 31.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 524400\n",
      "voxels hitted: \t 427372\n",
      "Percentage of voxels hitted by beam: 0.81\n",
      "voxels hitted (OLD): \t 475459\n",
      "Percentage of voxels hitted by beam (OLD): 0.91\n",
      "inds not been created yet for donwnsample of 0.600\n",
      "max --> [188, 184, 119]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70990it [1:15:22, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 4195800\n",
      "voxels hitted: \t 3086910\n",
      "Percentage of voxels hitted by beam: 0.74\n",
      "voxels hitted (OLD): \t 3261074\n",
      "Percentage of voxels hitted by beam (OLD): 0.78\n",
      "inds file already exists for donwnsample of 0.600 at /Users/omar/projects/planttech/data/test/lad_0.6/inds.npy\n",
      "max --> [118, 115, 74]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70990it [42:27, 27.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 1035300\n",
      "voxels hitted: \t 850847\n",
      "Percentage of voxels hitted by beam: 0.82\n",
      "voxels hitted (OLD): \t 927935\n",
      "Percentage of voxels hitted by beam (OLD): 0.90\n",
      "inds file already exists for donwnsample of 0.600 at /Users/omar/projects/planttech/data/test/lad_0.6/inds.npy\n",
      "max --> [94, 92, 60]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70990it [38:50, 30.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 538935\n",
      "voxels hitted: \t 446752\n",
      "Percentage of voxels hitted by beam: 0.83\n",
      "voxels hitted (OLD): \t 498311\n",
      "Percentage of voxels hitted by beam (OLD): 0.92\n"
     ]
    }
   ],
   "source": [
    "for DS in [0.2, 0.4, 0.6]:\n",
    "    for VS in [0.05, 0.08, 0.1]:\n",
    "\n",
    "        get_rays(DS, VS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsample: 0.2\n",
      "voxel_size: 0.05\n",
      "max --> [60, 68, 20]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (61, 69, 21)\n",
      "ray tracker voxel dimensions: \t (61, 69, 21)\n",
      "Number of voxels ocupied by points cloud: \t 8115\n",
      "Number of voxels ocupied by beam points cloud: \t 63021\n",
      "Total number of voxels in plant regions: \t 88389\n",
      "Number of voxels with attribute 1: \t 8115\n",
      "Number of voxels with attribute 2: \t 63021\n",
      "Number of voxels with attribute 3: \t 17253\n",
      "max --> [60, 68, 20]\n",
      "min --> [0, 0, 0]\n",
      "8115 5979 2136\n",
      "Counts 29756\n",
      "Density overal= 2693.19\n",
      "Mean density= 27694.86\n",
      "Mean density considering all voxels= 2493.16\n",
      "Median density= 24000.00\n",
      "1\n",
      "downsample: 0.2\n",
      "voxel_size: 0.08\n",
      "max --> [38, 42, 12]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (39, 43, 13)\n",
      "ray tracker voxel dimensions: \t (39, 43, 13)\n",
      "Number of voxels ocupied by points cloud: \t 3708\n",
      "Number of voxels ocupied by beam points cloud: \t 14332\n",
      "Total number of voxels in plant regions: \t 21801\n",
      "Number of voxels with attribute 1: \t 3708\n",
      "Number of voxels with attribute 2: \t 14332\n",
      "Number of voxels with attribute 3: \t 3761\n",
      "max --> [38, 42, 12]\n",
      "min --> [0, 0, 0]\n",
      "3708 3227 481\n",
      "Counts 29756\n",
      "Density overal= 2665.80\n",
      "Mean density= 14667.33\n",
      "Mean density considering all voxels= 2434.13\n",
      "Median density= 11718.75\n",
      "1\n",
      "downsample: 0.2\n",
      "voxel_size: 0.1\n",
      "max --> [30, 34, 10]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (31, 35, 11)\n",
      "ray tracker voxel dimensions: \t (31, 35, 11)\n",
      "Number of voxels ocupied by points cloud: \t 2418\n",
      "Number of voxels ocupied by beam points cloud: \t 7506\n",
      "Total number of voxels in plant regions: \t 11935\n",
      "Number of voxels with attribute 1: \t 2418\n",
      "Number of voxels with attribute 2: \t 7506\n",
      "Number of voxels with attribute 3: \t 2011\n",
      "max --> [30, 34, 10]\n",
      "min --> [0, 0, 0]\n",
      "2418 2176 242\n",
      "Counts 29756\n",
      "Density overal= 2493.17\n",
      "Mean density= 11491.08\n",
      "Mean density considering all voxels= 2266.44\n",
      "Median density= 10000.00\n",
      "1\n",
      "downsample: 0.4\n",
      "voxel_size: 0.05\n",
      "max --> [60, 68, 20]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (61, 69, 21)\n",
      "ray tracker voxel dimensions: \t (61, 69, 21)\n",
      "Number of voxels ocupied by points cloud: \t 9173\n",
      "Number of voxels ocupied by beam points cloud: \t 62478\n",
      "Total number of voxels in plant regions: \t 88389\n",
      "Number of voxels with attribute 1: \t 9173\n",
      "Number of voxels with attribute 2: \t 62478\n",
      "Number of voxels with attribute 3: \t 16738\n",
      "max --> [60, 68, 20]\n",
      "min --> [0, 0, 0]\n",
      "9173 7626 1547\n",
      "Counts 54314\n",
      "Density overal= 4915.91\n",
      "Mean density= 43567.93\n",
      "Mean density considering all voxels= 4389.87\n",
      "Median density= 32000.00\n",
      "1\n",
      "downsample: 0.4\n",
      "voxel_size: 0.08\n",
      "max --> [38, 42, 12]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (39, 43, 13)\n",
      "ray tracker voxel dimensions: \t (39, 43, 13)\n",
      "Number of voxels ocupied by points cloud: \t 3938\n",
      "Number of voxels ocupied by beam points cloud: \t 14145\n",
      "Total number of voxels in plant regions: \t 21801\n",
      "Number of voxels with attribute 1: \t 3938\n",
      "Number of voxels with attribute 2: \t 14145\n",
      "Number of voxels with attribute 3: \t 3718\n",
      "max --> [38, 42, 12]\n",
      "min --> [0, 0, 0]\n",
      "3938 3615 323\n",
      "Counts 54314\n",
      "Density overal= 4865.93\n",
      "Mean density= 24887.78\n",
      "Mean density considering all voxels= 4363.15\n",
      "Median density= 19531.25\n",
      "1\n",
      "downsample: 0.4\n",
      "voxel_size: 0.1\n",
      "max --> [30, 34, 10]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (31, 35, 11)\n",
      "ray tracker voxel dimensions: \t (31, 35, 11)\n",
      "Number of voxels ocupied by points cloud: \t 2549\n",
      "Number of voxels ocupied by beam points cloud: \t 7423\n",
      "Total number of voxels in plant regions: \t 11935\n",
      "Number of voxels with attribute 1: \t 2549\n",
      "Number of voxels with attribute 2: \t 7423\n",
      "Number of voxels with attribute 3: \t 1963\n",
      "max --> [30, 34, 10]\n",
      "min --> [0, 0, 0]\n",
      "2549 2376 173\n",
      "Counts 54314\n",
      "Density overal= 4550.82\n",
      "Mean density= 19748.79\n",
      "Mean density considering all voxels= 4097.03\n",
      "Median density= 16000.00\n",
      "1\n",
      "downsample: 0.6\n",
      "voxel_size: 0.05\n",
      "max --> [60, 68, 20]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (61, 69, 21)\n",
      "ray tracker voxel dimensions: \t (61, 69, 21)\n",
      "Number of voxels ocupied by points cloud: \t 9685\n",
      "Number of voxels ocupied by beam points cloud: \t 62041\n",
      "Total number of voxels in plant regions: \t 88389\n",
      "Number of voxels with attribute 1: \t 9685\n",
      "Number of voxels with attribute 2: \t 62041\n",
      "Number of voxels with attribute 3: \t 16663\n",
      "max --> [60, 68, 20]\n",
      "min --> [0, 0, 0]\n",
      "9685 8351 1334\n",
      "Counts 74462\n",
      "Density overal= 6739.48\n",
      "Mean density= 56580.84\n",
      "Mean density considering all voxels= 6021.74\n",
      "Median density= 48000.00\n",
      "1\n",
      "downsample: 0.6\n",
      "voxel_size: 0.08\n",
      "max --> [38, 42, 12]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (39, 43, 13)\n",
      "ray tracker voxel dimensions: \t (39, 43, 13)\n",
      "Number of voxels ocupied by points cloud: \t 4054\n",
      "Number of voxels ocupied by beam points cloud: \t 14055\n",
      "Total number of voxels in plant regions: \t 21801\n",
      "Number of voxels with attribute 1: \t 4054\n",
      "Number of voxels with attribute 2: \t 14055\n",
      "Number of voxels with attribute 3: \t 3692\n",
      "max --> [38, 42, 12]\n",
      "min --> [0, 0, 0]\n",
      "4054 3774 280\n",
      "Counts 74462\n",
      "Density overal= 6670.96\n",
      "Mean density= 33026.83\n",
      "Mean density considering all voxels= 5958.19\n",
      "Median density= 27343.75\n",
      "1\n",
      "downsample: 0.6\n",
      "voxel_size: 0.1\n",
      "max --> [30, 34, 10]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (31, 35, 11)\n",
      "ray tracker voxel dimensions: \t (31, 35, 11)\n",
      "Number of voxels ocupied by points cloud: \t 2590\n",
      "Number of voxels ocupied by beam points cloud: \t 7395\n",
      "Total number of voxels in plant regions: \t 11935\n",
      "Number of voxels with attribute 1: \t 2590\n",
      "Number of voxels with attribute 2: \t 7395\n",
      "Number of voxels with attribute 3: \t 1950\n",
      "max --> [30, 34, 10]\n",
      "min --> [0, 0, 0]\n",
      "2590 2434 156\n",
      "Counts 74462\n",
      "Density overal= 6238.96\n",
      "Mean density= 26690.35\n",
      "Mean density considering all voxels= 5633.26\n",
      "Median density= 22000.00\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for DS in [0.2, 0.4, 0.6]:\n",
    "    for VS in [0.05, 0.08, 0.1]:\n",
    "\n",
    "        runall(downsample=DS, voxel_size=VS, kbins=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts within voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isinds(resdir, downsample):\n",
    "\n",
    "    outdir = os.path.join(resdir, 'inds.npy')\n",
    "    if os.path.exists(outdir):\n",
    "        print('inds file already exists for donwnsample of %.3f at %s' %(downsample, outdir))\n",
    "\n",
    "        inds = np.load(outdir)\n",
    "\n",
    "        points = POINTS[inds]\n",
    "        sensors = SENSORS[inds]\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('inds not been created yet for donwnsample of %.3f' %(downsample))\n",
    "        idx = np.random.randint(0, len(df), int(len(df) * downsample))\n",
    "        \n",
    "        inds = np.zeros(len(df), dtype=bool)\n",
    "        inds[idx] = True\n",
    "\n",
    "        points = POINTS[inds]\n",
    "        sensors = SENSORS[inds]\n",
    "\n",
    "        np.save(outdir, inds)\n",
    "\n",
    "    return inds\n",
    "\n",
    "def isinds_vs(resdir, voxel_size):\n",
    "\n",
    "    outdir = os.path.join(resdir, 'inds_vs.npy')\n",
    "    if os.path.exists(outdir):\n",
    "        print('inds file already exists for donwnsample of %.3f at %s' %(voxel_size, outdir))\n",
    "\n",
    "        inds = np.load(outdir)\n",
    "\n",
    "        points = POINTS[inds]\n",
    "        sensors = SENSORS[inds]\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('inds not been created yet for donwnsample of %.3f' %(voxel_size))\n",
    "        # idx = np.random.randint(0, len(df), int(len(df) * downsample))\n",
    "\n",
    "        pcd = loads.points2pcd(POINTS)\n",
    "        minb = pcd.get_min_bound()\n",
    "        maxb = pcd.get_max_bound()\n",
    "        voxel = o3d.geometry.PointCloud.voxel_down_sample_and_trace(pcd, voxel_size=voxel_size, min_bound=minb, max_bound=maxb)\n",
    "        idxDS = [i[0] for i in voxel[2]]\n",
    "        \n",
    "        inds = np.zeros(len(df), dtype=bool)\n",
    "        inds[idxDS] = True\n",
    "\n",
    "        points = POINTS[inds]\n",
    "        sensors = SENSORS[inds]\n",
    "\n",
    "        np.save(outdir, inds)\n",
    "\n",
    "    return inds\n",
    "\n",
    "def restmp(downsample, voxel_size, show=True, indsvs=False):\n",
    "\n",
    "    resdir = os.path.join(_data, mockname, 'lad_%s' %(str(downsample)))\n",
    "    if not os.path.exists(resdir):\n",
    "        os.makedirs(resdir)\n",
    "\n",
    "    if indsvs:\n",
    "        inds = isinds_vs(resdir, voxel_size)\n",
    "        print('Total:',len(df))\n",
    "        print('Downsampling:',np.sum(inds))\n",
    "    else:    \n",
    "        inds = isinds(resdir, downsample)\n",
    "\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        inPR = (val) & (leaves) & (inds)\n",
    "        pointsPR = POINTS[inPR]\n",
    "        sensorsPR = SENSORS[inPR]\n",
    "\n",
    "        density_overall, density, counts, m3scount = lad.density_counts(pointsPR, voxel_size)\n",
    "        \n",
    "        dens_ratio = density / density_overall\n",
    "        # print('Mean density ration: %.2f' %(np.mean(dens_ratio)))\n",
    "        # print('Median density ration: %.2f' %(np.median(dens_ratio)))\n",
    "\n",
    "        if show:\n",
    "\n",
    "            fig = plt.figure(figsize=(10,6))\n",
    "            plt.hist(counts, 25, align='left')\n",
    "            plt.axvline(np.mean(counts), color='k', label='Mean counts = %.2f' %(np.mean(counts)))\n",
    "            plt.xlabel(r'$n_{i}$', size=20)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "    return np.mean(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isinds(resdir, downsample):\n",
    "\n",
    "    outdir = os.path.join(resdir, 'inds.npy')\n",
    "    if os.path.exists(outdir):\n",
    "        print('inds file already exists for donwnsample of %.3f at %s' %(downsample, outdir))\n",
    "\n",
    "        inds = np.load(outdir)\n",
    "\n",
    "        points = POINTS[inds]\n",
    "        sensors = SENSORS[inds]\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('inds not been created yet for donwnsample of %.3f' %(downsample))\n",
    "        idx = np.random.randint(0, len(df), int(len(df) * downsample))\n",
    "        inds = np.zeros(len(df), dtype=bool)\n",
    "        inds[idx] = True\n",
    "\n",
    "        points = POINTS[inds]\n",
    "        sensors = SENSORS[inds]\n",
    "\n",
    "        np.save(outdir, inds)\n",
    "\n",
    "    return inds\n",
    "\n",
    "def restmp(downsample, voxel_size, show=True):\n",
    "\n",
    "    resdir = os.path.join(_data, mockname, 'lad_%s' %(str(downsample)))\n",
    "    if not os.path.exists(resdir):\n",
    "        os.makedirs(resdir)\n",
    "    inds = isinds(resdir, downsample)\n",
    "\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        inPR = (val) & (leaves) & (inds)\n",
    "        pointsPR = POINTS[inPR]\n",
    "        sensorsPR = SENSORS[inPR]\n",
    "\n",
    "        density_overall, density, counts, m3scount = lad.density_counts(pointsPR, voxel_size)\n",
    "        \n",
    "        # dens_ratio = density / density_overall\n",
    "        # print('Mean density ration: %.2f' %(np.mean(dens_ratio)))\n",
    "        # print('Median density ration: %.2f' %(np.median(dens_ratio)))\n",
    "\n",
    "        if show:\n",
    "\n",
    "            fig = plt.figure(figsize=(10,6))\n",
    "            plt.hist(counts, 25, align='left')\n",
    "            plt.axvline(np.mean(counts), color='k', label='Mean counts = %.2f' %(np.mean(counts)))\n",
    "            plt.xlabel(r'$n_{i}$', size=20)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "    return np.mean(counts)\n",
    "\n",
    "\n",
    "def ds2vs_first(DS, PCR):\n",
    "\n",
    "    N = np.cbrt(1/DS)\n",
    "    VS = N * PCR\n",
    "    \n",
    "    return VS\n",
    "\n",
    "def ds2vs(downsample, points, mean_counts=0, step=0.01, bounds=(1.25, 1.3)):\n",
    "\n",
    "    # nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(points)\n",
    "    # distances, indices = nbrs.kneighbors(points)\n",
    "\n",
    "    minb, maxb = bounds\n",
    "\n",
    "    # dist = distances[:, 1]\n",
    "    # dmin, dmax = np.percentile(dist, (0, 99.7))\n",
    "    # keep = (dist >= dmin) & (dist <= dmax)\n",
    "    # dist = dist[keep]\n",
    "    # PCR = np.round(np.mean(dist), 4)\n",
    "    # print('PCR first guess: %.3f' %(PCR))\n",
    "    PCR = 0.01\n",
    "\n",
    "    # first guess for voxel size\n",
    "    voxel_size = ds2vs_first(downsample, PCR)\n",
    "\n",
    "    resdir = os.path.join(_data, mockname, 'lad_%s' %(str(downsample)))\n",
    "    if not os.path.exists(resdir):\n",
    "        os.makedirs(resdir)\n",
    "    inds = isinds(resdir, downsample)\n",
    "\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        inPR = (val) & (leaves) & (inds)\n",
    "        pointsPR = POINTS[inPR]\n",
    "\n",
    "        j = 0\n",
    "\n",
    "        while (mean_counts < minb) or (mean_counts > maxb):\n",
    "\n",
    "            # mean_counts = restmp(downsample, voxel_size, show=False)\n",
    "            density_overall, density, counts, m3scount = lad.density_counts(pointsPR, voxel_size)\n",
    "            mean_counts = np.mean(counts)\n",
    "            \n",
    "            print(mean_counts, voxel_size, step)\n",
    "\n",
    "            if mean_counts < minb:\n",
    "                voxel_size += step\n",
    "\n",
    "            elif mean_counts > maxb:\n",
    "                voxel_size -= step\n",
    "\n",
    "            if np.abs(mean_counts - (maxb + minb)/2) < 0.1:\n",
    "                step /= 2\n",
    "\n",
    "    return voxel_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inds file already exists for donwnsample of 0.050 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.05/inds.npy\n",
      "max --> [109, 125, 36]\n",
      "min --> [0, 0, 0]\n",
      "1.2129175946547883 0.02714417616594907 0.01\n",
      "max --> [80, 91, 26]\n",
      "min --> [0, 0, 0]\n",
      "1.394741335154516 0.03714417616594907 0.005\n",
      "max --> [92, 105, 30]\n",
      "min --> [0, 0, 0]\n",
      "1.3082959641255605 0.03214417616594907 0.005\n",
      "max --> [109, 125, 36]\n",
      "min --> [0, 0, 0]\n",
      "1.2129175946547883 0.02714417616594907 0.0025\n",
      "max --> [100, 114, 33]\n",
      "min --> [0, 0, 0]\n",
      "1.2587057010785825 0.029644176165949068 0.00125\n",
      "inds file already exists for donwnsample of 0.100 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.1/inds.npy\n",
      "max --> [140, 156, 46]\n",
      "min --> [0, 0, 0]\n",
      "1.253128237825775 0.02154434690031884 0.01\n",
      "inds file already exists for donwnsample of 0.200 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.2/inds.npy\n",
      "max --> [176, 198, 58]\n",
      "min --> [0, 0, 0]\n",
      "1.30228894043503 0.01709975946676697 0.01\n"
     ]
    }
   ],
   "source": [
    "inPR = (trees['tree_0']) & (leaves)\n",
    "voxels = {}\n",
    "\n",
    "for DS in [0.05, 0.1, 0.2]:\n",
    "\n",
    "    VS = ds2vs(DS, POINTS[inPR], mean_counts=0, step=0.01, bounds=(1.25, 1.3))\n",
    "    VS = np.round(VS, 3)\n",
    "    voxels[DS] = VS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inds not been created yet for donwnsample of 0.100\n",
      "Total: 375000\n",
      "Downsampling: 35497\n",
      "max --> [30, 33, 10]\n",
      "min --> [0, 0, 0]\n",
      "1.5332926084300549\n"
     ]
    }
   ],
   "source": [
    "mean_counts = restmp(downsample=0.1, voxel_size=0.1, show=True, indsvs=True)\n",
    "print(mean_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ni and Np variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsample: 0.01\n",
      "voxel_size: 0.05\n",
      "max --> [60, 68, 18]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (61, 69, 19)\n",
      "ray tracker voxel dimensions: \t (61, 69, 19)\n",
      "Number of voxels ocupied by points cloud: \t 1475\n",
      "Number of voxels ocupied by beam points cloud: \t 40779\n",
      "Total number of voxels in plant regions: \t 79971\n",
      "Number of voxels with attribute 1: \t 1475\n",
      "Number of voxels with attribute 2: \t 40779\n",
      "Number of voxels with attribute 3: \t 37717\n",
      "downsample: 0.1\n",
      "voxel_size: 0.05\n",
      "max --> [60, 67, 20]\n",
      "min --> [0, 0, 0]\n",
      "No ray tracing for tree tree_0 and voxel size 0.050\n",
      "foliage voxel dimensions: \t (61, 68, 21)\n",
      "ray tracker voxel dimensions: \t (61, 68, 21)\n",
      "Number of voxels ocupied by points cloud: \t 6528\n",
      "Number of voxels ocupied by beam points cloud: \t 87108\n",
      "Total number of voxels in plant regions: \t 87108\n",
      "Number of voxels with attribute 1: \t 6528\n",
      "Number of voxels with attribute 2: \t 80580\n",
      "Number of voxels with attribute 3: \t 0\n",
      "downsample: 0.2\n",
      "voxel_size: 0.05\n",
      "max --> [60, 68, 20]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (61, 69, 21)\n",
      "ray tracker voxel dimensions: \t (61, 69, 21)\n",
      "Number of voxels ocupied by points cloud: \t 8115\n",
      "Number of voxels ocupied by beam points cloud: \t 63021\n",
      "Total number of voxels in plant regions: \t 88389\n",
      "Number of voxels with attribute 1: \t 8115\n",
      "Number of voxels with attribute 2: \t 63021\n",
      "Number of voxels with attribute 3: \t 17253\n",
      "downsample: 0.4\n",
      "voxel_size: 0.05\n",
      "max --> [60, 68, 20]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (61, 69, 21)\n",
      "ray tracker voxel dimensions: \t (61, 69, 21)\n",
      "Number of voxels ocupied by points cloud: \t 9173\n",
      "Number of voxels ocupied by beam points cloud: \t 62478\n",
      "Total number of voxels in plant regions: \t 88389\n",
      "Number of voxels with attribute 1: \t 9173\n",
      "Number of voxels with attribute 2: \t 62478\n",
      "Number of voxels with attribute 3: \t 16738\n",
      "downsample: 0.6\n",
      "voxel_size: 0.05\n",
      "max --> [60, 68, 20]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (61, 69, 21)\n",
      "ray tracker voxel dimensions: \t (61, 69, 21)\n",
      "Number of voxels ocupied by points cloud: \t 9685\n",
      "Number of voxels ocupied by beam points cloud: \t 62041\n",
      "Total number of voxels in plant regions: \t 88389\n",
      "Number of voxels with attribute 1: \t 9685\n",
      "Number of voxels with attribute 2: \t 62041\n",
      "Number of voxels with attribute 3: \t 16663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$n_{I}/(n_{I}+n_{P})$')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for downsample in [0.01, 0.1, 0.2, 0.4, 0.6]:\n",
    "    for voxel_size in [0.05]:\n",
    "\n",
    "        if downsample is not None:\n",
    "            resdir = os.path.join(_data, mockname, 'lad_%s' %(str(downsample)))\n",
    "            inds_file = os.path.join(resdir, 'inds.npy')\n",
    "            inds = np.load(inds_file)\n",
    "            print('downsample:', downsample)\n",
    "        else:\n",
    "            inds = np.ones(len(df), dtype=bool)\n",
    "            resdir = os.path.join(_data, mockname, 'lad')\n",
    "\n",
    "        isfigures = os.path.join(resdir, 'figures')\n",
    "        if not os.path.exists(isfigures):\n",
    "            os.makedirs(isfigures)\n",
    "\n",
    "        print('voxel_size:', voxel_size)\n",
    "\n",
    "        for key, val in trees.items():\n",
    "\n",
    "            inPR = (val) & (leaves) & (inds)\n",
    "            pointsPR = POINTS[inPR]\n",
    "            sensorsPR = SENSORS[inPR]\n",
    "\n",
    "            m3att = lad.compute_attributes(pointsPR, resdir, voxel_size, key)\n",
    "\n",
    "            results.append([downsample, voxel_size, (m3att == 1).sum(), (m3att == 2).sum(), (m3att == 3).sum()])\n",
    "\n",
    "results = np.array(results)\n",
    "\n",
    "total = np.array(np.sum(results[:,2:5], axis=1))\n",
    "nI0 = results[:,2] / total\n",
    "nP0 = results[:,3] / total\n",
    "n00 = results[:,4] / total\n",
    "\n",
    "nI = results[:,2]\n",
    "nP = results[:,3]\n",
    "n0 = results[:,4]\n",
    "\n",
    "\n",
    "fig, (a0, a1) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [2, 1]}, figsize=(10,22))\n",
    "colors = plt.cm.jet(np.linspace(0,1,5))\n",
    "\n",
    "for num, voxel_size in enumerate([0.05]):\n",
    "\n",
    "    keep = (results[:,1] == voxel_size)\n",
    "    downsample = results[:,0][keep]\n",
    "    a0.plot(downsample*100, nP0[keep], marker='*', color=colors[num], label='%s' %(voxel_size))\n",
    "    a0.plot(downsample*100, nI0[keep], marker='*', ls='--', color=colors[num])\n",
    "    a0.plot(downsample*100, n00[keep], marker='*', ls=':', color=colors[num])\n",
    "    \n",
    "    a1.plot(downsample*100, nI[keep]/(nI[keep]+nP[keep]), marker='*', ls='-', color=colors[num])\n",
    "\n",
    "text = '$n_{P}(k)$: Solid \\n $n_{I}(k)$: Dashed \\n $n_{0}(k)$: Dotted'\n",
    "props = dict(boxstyle='round', facecolor='green', alpha=0.3)\n",
    "a0.text(20, 0.5, text, fontsize=14, bbox=props)\n",
    "a0.legend(title='Voxel Size')\n",
    "a0.set_ylabel(r'$N$', size=20)\n",
    "\n",
    "# a1.axhline(0.035, ls='--', c='k', lw=2)\n",
    "a1.set_xlabel(r'Downsample (%)', size=20)\n",
    "a1.set_ylabel(r'$n_{I}/(n_{I}+n_{P})$', size=20)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165062, 3)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POINTS[leaves].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd = loads.points2pcd(POINTS[leaves])\n",
    "minb = pcd.get_min_bound()\n",
    "maxb = pcd.get_max_bound()\n",
    "voxel = o3d.geometry.PointCloud.voxel_down_sample_and_trace(pcd, voxel_size=0.5, min_bound=minb, max_bound=maxb)\n",
    "idxDS = [i[0] for i in voxel[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "pointslist = [POINTS[leaves], POINTS[leaves][idxDS]]\n",
    "colours = [[0,0,1], [1,0,0]]\n",
    "loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCR first guess: 0.006\n",
      "inds file already exists for donwnsample of 0.100 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.1/inds.npy\n",
      "max --> [250, 279, 82]\n",
      "min --> [0, 0, 0]\n",
      "1.068574147070817 0.012064834264178549 0.02\n",
      "inds file already exists for donwnsample of 0.100 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.1/inds.npy\n",
      "max --> [94, 105, 31]\n",
      "min --> [0, 0, 0]\n",
      "1.5718284514645606 0.03206483426417855 0.01\n",
      "inds file already exists for donwnsample of 0.100 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.1/inds.npy\n",
      "max --> [137, 153, 45]\n",
      "min --> [0, 0, 0]\n",
      "1.2706481331824795 0.022064834264178546 0.005\n",
      "0.022\n",
      "inds file already exists for donwnsample of 0.100 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.1/inds.npy\n",
      "max --> [137, 153, 45]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35680it [32:09, 18.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 977592\n",
      "voxels hitted: \t 657004\n",
      "Percentage of voxels hitted by beam: 0.67\n",
      "voxels hitted (OLD): \t 708817\n",
      "Percentage of voxels hitted by beam (OLD): 0.73\n"
     ]
    }
   ],
   "source": [
    "DS = 0.1\n",
    "VS = ds2vs(DS, POINTS[inPR], mean_counts=0, step=0.02)\n",
    "VS = np.round(VS, 3)\n",
    "print(VS)\n",
    "get_rays(DS, VS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsample: 0.1\n",
      "voxel_size: 0.022\n",
      "max --> [137, 153, 45]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (138, 154, 46)\n",
      "ray tracker voxel dimensions: \t (138, 154, 46)\n",
      "Number of voxels ocupied by points cloud: \t 12429\n",
      "Number of voxels ocupied by beam points cloud: \t 657004\n",
      "Total number of voxels in plant regions: \t 977592\n",
      "Number of voxels with attribute 1: \t 12429\n",
      "Number of voxels with attribute 2: \t 657004\n",
      "Number of voxels with attribute 3: \t 308159\n",
      "max --> [137, 153, 45]\n",
      "min --> [0, 0, 0]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "runall(downsample=0.1, voxel_size=0.022, kbins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# # keep = trees['tree_0']\n",
    "# # print(np.sum(keep))\n",
    "# downsample = 0.05\n",
    "\n",
    "# resdir = os.path.join(_data, mockname, 'lad_%s' %(str(downsample)))\n",
    "# inds_file = os.path.join(resdir, 'inds.npy')\n",
    "# inds = np.load(inds_file)\n",
    "\n",
    "# inPR = (trees['tree_0']) & (leaves) & (inds)\n",
    "# pointsPR = POINTS[inPR]\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(POINTS)\n",
    "distances, indices = nbrs.kneighbors(POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.09078427403044305\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "    \n",
    "dist = distances[:, 1]\n",
    "dmin, dmax = np.percentile(dist, (0, 99.7))\n",
    "keep = (dist >= dmin) & (dist <= dmax)\n",
    "dist = dist[keep]\n",
    "mean = np.round(np.mean(dist), 3)\n",
    "median = np.round(np.median(dist), 3)\n",
    "print(dmin, dmax)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "bins = np.linspace(dmin, dmax, 80)\n",
    "plt.hist(dist, bins, density=True)\n",
    "plt.axvline(mean, ls='--', c='k', label='Mean = %.3f' %(mean))\n",
    "plt.axvline(median, ls='--', c='g', label='Median = %.3f' %(median))\n",
    "plt.xlabel('voxel size', size=15)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds2vs_first(DS, PCR):\n",
    "\n",
    "    N = np.cbrt(1/DS)\n",
    "    VS = N * PCR\n",
    "    \n",
    "    return VS\n",
    "\n",
    "def ds2vs(downsample, points, mean_counts=0, step=0.01):\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(points)\n",
    "    distances, indices = nbrs.kneighbors(points)\n",
    "\n",
    "    minb, maxb = 1.25, 1.3\n",
    "\n",
    "    dist = distances[:, 1]\n",
    "    dmin, dmax = np.percentile(dist, (0, 99.7))\n",
    "    keep = (dist >= dmin) & (dist <= dmax)\n",
    "    dist = dist[keep]\n",
    "    PCR = np.round(np.mean(dist), 4)\n",
    "    print('PCR first guess: %.3f' %(PCR))\n",
    "\n",
    "    # first guess for voxel size\n",
    "    voxel_size = ds2vs_first(downsample, PCR)\n",
    "\n",
    "    while (mean_counts < minb) or (mean_counts > maxb):\n",
    "\n",
    "        mean_counts = restmp(downsample, voxel_size, show=False)\n",
    "        print(mean_counts, voxel_size, step)\n",
    "\n",
    "        if mean_counts < minb:\n",
    "            voxel_size += step\n",
    "            step /= 2\n",
    "\n",
    "        elif mean_counts > maxb:\n",
    "\n",
    "            voxel_size -= step\n",
    "            step /= 2\n",
    "\n",
    "    return voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCR first guess: 0.006\n",
      "inds file already exists for donwnsample of 0.050 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.05/inds.npy\n",
      "max --> [195, 222, 64]\n",
      "min --> [0, 0, 0]\n",
      "1.0599455040871935 0.015200738652931478 0.02\n",
      "inds file already exists for donwnsample of 0.050 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.05/inds.npy\n",
      "max --> [84, 96, 27]\n",
      "min --> [0, 0, 0]\n",
      "1.3651403743315509 0.03520073865293148 0.01\n",
      "inds file already exists for donwnsample of 0.050 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.05/inds.npy\n",
      "max --> [118, 134, 38]\n",
      "min --> [0, 0, 0]\n",
      "1.1859756097560976 0.02520073865293148 0.005\n",
      "inds file already exists for donwnsample of 0.050 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.05/inds.npy\n",
      "max --> [98, 112, 32]\n",
      "min --> [0, 0, 0]\n",
      "1.2643553629469122 0.03020073865293148 0.0025\n",
      "PCR first guess: 0.006\n",
      "inds file already exists for donwnsample of 0.100 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.1/inds.npy\n",
      "max --> [250, 279, 82]\n",
      "min --> [0, 0, 0]\n",
      "1.068574147070817 0.012064834264178549 0.02\n",
      "inds file already exists for donwnsample of 0.100 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.1/inds.npy\n",
      "max --> [94, 105, 31]\n",
      "min --> [0, 0, 0]\n",
      "1.5718284514645606 0.03206483426417855 0.01\n",
      "inds file already exists for donwnsample of 0.100 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.1/inds.npy\n",
      "max --> [137, 153, 45]\n",
      "min --> [0, 0, 0]\n",
      "1.2706481331824795 0.022064834264178546 0.005\n"
     ]
    }
   ],
   "source": [
    "inPR = (trees['tree_0']) & (leaves)\n",
    "voxels = {}\n",
    "\n",
    "for DS in [0.05, 0.1]:\n",
    "\n",
    "    VS = ds2vs(DS, POINTS[inPR], mean_counts=0, step=0.02)\n",
    "    VS = np.round(VS, 3)\n",
    "    voxels[DS] = VS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.03\n",
      "0.1 0.022\n"
     ]
    }
   ],
   "source": [
    "for key, val in voxels.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.0649822436705789\n",
      "0.05 0.038001846632328695\n",
      "0.1 0.030162085660446373\n",
      "0.2 0.02393966325347376\n",
      "0.4 0.019000923316164348\n",
      "0.6 0.016598835420953625\n"
     ]
    }
   ],
   "source": [
    "for DS in [0.01, 0.05, 0.1, 0.2, 0.4, 0.6]:\n",
    "\n",
    "    VS = ds2vs(DS, 0.014)\n",
    "    print(DS, VS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inds file already exists for donwnsample of 0.050 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.05/inds.npy\n",
      "max --> [99, 113, 32]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4l/bbjl67b151l_mb_20rk6glxh0000gn/T/ipykernel_40056/2140857438.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm3scount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoxel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    }
   ],
   "source": [
    "counts, m3scount = restmp(downsample=0.05, voxel_size=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.024\n",
      "inds file already exists for donwnsample of 0.200 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.2/inds.npy\n",
      "max --> [125, 141, 42]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "67879it [59:00, 19.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 769356\n",
      "voxels hitted: \t 588106\n",
      "Percentage of voxels hitted by beam: 0.76\n",
      "voxels hitted (OLD): \t 637916\n",
      "Percentage of voxels hitted by beam (OLD): 0.83\n"
     ]
    }
   ],
   "source": [
    "for DS in [0.2]:\n",
    "\n",
    "    VS = ds2vs(DS, 0.014)\n",
    "    VS = np.round(VS, 3)\n",
    "    print(DS, VS)\n",
    "\n",
    "    get_rays(DS, VS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.065\n",
      "inds not been created yet for donwnsample of 0.010\n",
      "max --> [46, 52, 14]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3732it [01:20, 46.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 37365\n",
      "voxels hitted: \t 22978\n",
      "Percentage of voxels hitted by beam: 0.61\n",
      "voxels hitted (OLD): \t 26462\n",
      "Percentage of voxels hitted by beam (OLD): 0.71\n",
      "0.05 0.038\n",
      "inds file already exists for donwnsample of 0.050 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.05/inds.npy\n",
      "max --> [78, 89, 25]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18298it [12:28, 24.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 184860\n",
      "voxels hitted: \t 130127\n",
      "Percentage of voxels hitted by beam: 0.70\n",
      "voxels hitted (OLD): \t 146928\n",
      "Percentage of voxels hitted by beam (OLD): 0.79\n",
      "0.1 0.03\n",
      "inds file already exists for donwnsample of 0.100 at /Users/omar/projects/planttech/data/test_kiwi/lad_0.1/inds.npy\n",
      "max --> [100, 112, 33]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35680it [32:34, 18.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot vox: \t 388042\n",
      "voxels hitted: \t 287106\n",
      "Percentage of voxels hitted by beam: 0.74\n",
      "voxels hitted (OLD): \t 316591\n",
      "Percentage of voxels hitted by beam (OLD): 0.82\n"
     ]
    }
   ],
   "source": [
    "for DS in [0.01, 0.05, 0.1]:\n",
    "\n",
    "    VS = ds2vs(DS, 0.014)\n",
    "    VS = np.round(VS, 3)\n",
    "    print(DS, VS)\n",
    "\n",
    "    get_rays(DS, VS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsample: 0.2\n",
      "voxel_size: 0.024\n",
      "max --> [125, 141, 42]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (126, 142, 43)\n",
      "ray tracker voxel dimensions: \t (126, 142, 43)\n",
      "Number of voxels ocupied by points cloud: \t 18343\n",
      "Number of voxels ocupied by beam points cloud: \t 588106\n",
      "Total number of voxels in plant regions: \t 769356\n",
      "Number of voxels with attribute 1: \t 18343\n",
      "Number of voxels with attribute 2: \t 588106\n",
      "Number of voxels with attribute 3: \t 162907\n",
      "max --> [125, 141, 42]\n",
      "min --> [0, 0, 0]\n",
      "18343 7345 10998\n",
      "Counts 29756\n",
      "Density overal= 2797.78\n",
      "Mean density= 112776.50\n",
      "Mean density considering all voxels= 2644.99\n",
      "Median density= 72337.96\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for DS in [0.2]:\n",
    "\n",
    "    VS = ds2vs(DS, 0.014)\n",
    "    VS = np.round(VS, 3)\n",
    "\n",
    "    runall(downsample=DS, voxel_size=VS, kbins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsample: 0.05\n",
      "voxel_size: 0.05\n",
      "max --> [59, 68, 19]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (60, 69, 20)\n",
      "ray tracker voxel dimensions: \t (60, 69, 20)\n",
      "Number of voxels ocupied by points cloud: \t 4791\n",
      "Number of voxels ocupied by beam points cloud: \t 58935\n",
      "Total number of voxels in plant regions: \t 82800\n",
      "Number of voxels with attribute 1: \t 4791\n",
      "Number of voxels with attribute 2: \t 58935\n",
      "Number of voxels with attribute 3: \t 19074\n",
      "max --> [59, 68, 19]\n",
      "min --> [0, 0, 0]\n",
      "4791 2055 2736\n",
      "Counts 8169\n",
      "Density overal= 789.28\n",
      "Mean density= 12833.26\n",
      "Mean density considering all voxels= 723.19\n",
      "Median density= 8000.00\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "downsample = 0.05\n",
    "voxel_size = 0.05\n",
    "\n",
    "runall(downsample, voxel_size, kbins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ks = []\n",
    "for v in vox:\n",
    "\n",
    "    i,j,k = v.split('_')\n",
    "    ks.append(int(k))\n",
    "\n",
    "ks = np.array(ks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[ks == 2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "760a6cd4159ac8b99590d0ad7ba9faed7c379184a996bf44e62e475912739812"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('plant-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
