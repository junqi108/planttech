{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import laspy as lp\n",
    "import pdal\n",
    "import pandas as pd\n",
    "import open3d as o3d\n",
    "from dbfread import DBF\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "# basedir = os.path.dirname(os.getcwd())\n",
    "basedir = os.path.abspath(os.path.join(os.getcwd() ,\"../\"))\n",
    "_py = os.path.join(basedir, 'py')\n",
    "_data = os.path.join(basedir, 'data')\n",
    "\n",
    "sys.path.insert(1, _py)\n",
    "import loads\n",
    "import lia\n",
    "import ray as rayt\n",
    "import lad\n",
    "import figures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib qt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'kiwifruit_interpine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'Z', 'intensity', 'return_number', 'number_of_returns', 'synthetic', 'key_point', 'withheld', 'overlap', 'scanner_channel', 'scan_direction_flag', 'edge_of_flight_line', 'classification', 'user_data', 'scan_angle', 'point_source_id', 'gps_time', 'red', 'green', 'blue']\n"
     ]
    }
   ],
   "source": [
    "# load files\n",
    "las = loads.loadlaz(name)\n",
    "\n",
    "# See LAS columns names\n",
    "point_format = las.point_format\n",
    "if True:\n",
    "    print(list(point_format.dimension_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# las to data frame\n",
    "columns = ['x', 'y', 'z', 'intensity', 'return_number', 'number_of_returns', 'gps_time', 'red', 'green', 'blue']\n",
    "las = pd.DataFrame(np.vstack((las.x, las.y, las.z, las.intensity, las.return_number, las.number_of_returns, las.gps_time, las.red, las.green, las.blue)).transpose(), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift x and y coordinates near zero\n",
    "for i in ['x', 'y']:\n",
    "    ismin = np.min(las[i])\n",
    "    las[i] = las[i] - ismin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define point cloud with RGB colours\n",
    "points = np.vstack((las.x, las.y, las.z)).transpose()\n",
    "colors = np.vstack((las.red, las.green, las.blue)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading trayectory file:\n",
      " could not find file '/Users/omar/projects/planttech/data/kiwifruit_interpine/trajectory.dbf'\n",
      "A mock trajectory will be used.\n"
     ]
    }
   ],
   "source": [
    "# trajectory file must be called `trajectory.dbf` anc must contain x, y, z and gpstime\n",
    "# if trajectory not given, bellow we mock this following x, y and gps_time values from point cloud \n",
    "try:\n",
    "    traj = loads.loaddbf(name)\n",
    "    traj = pd.DataFrame(iter(traj)) # to pandas\n",
    "except Exception as e:\n",
    "    print('Error loading trayectory file:\\n %s' %(e))\n",
    "    print('A mock trajectory will be used.')\n",
    "\n",
    "    xymin = np.amin(points[:,:2], axis=0)\n",
    "    xymax = np.amax(points[:,:2], axis=0)\n",
    "    xymock = np.linspace(xymin, xymax, 50)\n",
    "\n",
    "    zmock = np.full((len(xymock), 1), 40, dtype=int)\n",
    "\n",
    "    gpsmin = las.gps_time.min()\n",
    "    gpsmax = las.gps_time.max()\n",
    "    gpsmock = np.linspace(gpsmin, gpsmax, len(xymock)).reshape(len(xymock), 1)\n",
    "\n",
    "    traj = np.append(xymock, zmock, axis=1)\n",
    "    traj = np.append(traj, gpsmock, axis=1)\n",
    "\n",
    "    traj = pd.DataFrame(traj, columns=['x', 'y', 'z', 'gpstime'])\n",
    "\n",
    "points_t = np.vstack((traj.x, traj.y, traj.z)).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a region to run our pipeline as we know much of the point cloud is not relevant for the posterior analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PCsample(p):\n",
    "\n",
    "    PCsample = (p[:,1] > 2.8*p[:,0] - 120) & (p[:,1] < 2.8*p[:,0] -80)\n",
    "    PCsample &= (p[:,0] < -2.8*p[:,1] + 500) & (p[:,0] > -2.8*p[:,1] + 400)\n",
    "\n",
    "    return PCsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$y$')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "xymin = np.amin(points[:,:2][::n], axis=0)\n",
    "xymax = np.amax(points[:,:2][::n], axis=0)\n",
    "\n",
    "plt.scatter(points[:,0][::n], points[:,1][::n], s=0.5, c='gray', alpha=0.5)\n",
    "\n",
    "x = np.linspace(xymin[0], xymax[0], 3)\n",
    "y = np.linspace(xymin[1], xymax[1], 3)\n",
    "plt.plot(x, 2.8*x - 80, ls='--', lw=0.8, c='r')\n",
    "plt.plot(x, 2.8*x - 120, ls='--', lw=0.8, c='r')\n",
    "plt.plot(-2.8*y + 400, y, ls='--', lw=0.8, c='r')\n",
    "plt.plot(-2.8*y + 500, y, ls='--', lw=0.8, c='r')\n",
    "\n",
    "PCsample = get_PCsample(points[::n])\n",
    "print(PCsample.sum())\n",
    "plt.scatter(points[:,0][::n][PCsample], points[:,1][::n][PCsample], c='g', s=0.5)\n",
    "\n",
    "plt.xlim(0, 175)\n",
    "plt.ylim(0, 300)\n",
    "\n",
    "plt.xlabel(r'$x$', size=20)\n",
    "plt.ylabel(r'$y$', size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# plot the two point cloudsb\n",
    "if True:\n",
    "    pointslist = [points[::1000], points_t]\n",
    "    colours = [colors[::1000]/2**16, [1, 0, 0]]\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# define and plot a sample of the point cloud\n",
    "\n",
    "PCsample = get_PCsample(points)\n",
    "\n",
    "pointslist = [points[PCsample], points_t]\n",
    "colours = [colors[PCsample]/2**16, [1, 0, 0]]\n",
    "if True:\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate trajectory with gps time\n",
    "df = loads.coordsDF(las, traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>xs</th>\n",
       "      <th>ys</th>\n",
       "      <th>zs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.8851</td>\n",
       "      <td>52.6814</td>\n",
       "      <td>17.054934</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.1875</td>\n",
       "      <td>52.5695</td>\n",
       "      <td>17.030534</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58.8075</td>\n",
       "      <td>52.3344</td>\n",
       "      <td>17.004434</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.1026</td>\n",
       "      <td>52.2180</td>\n",
       "      <td>16.970034</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.9687</td>\n",
       "      <td>51.4525</td>\n",
       "      <td>16.780334</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x        y          z        xs        ys    zs\n",
       "0  57.8851  52.6814  17.054934  0.000090  0.000153  40.0\n",
       "1  58.1875  52.5695  17.030534  0.000099  0.000169  40.0\n",
       "2  58.8075  52.3344  17.004434  0.000117  0.000200  40.0\n",
       "3  59.1026  52.2180  16.970034  0.000126  0.000215  40.0\n",
       "4  60.9687  51.4525  16.780334  0.000180  0.000307  40.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sample of beams\n",
    "if False:\n",
    "    loads.showbeams(df[15000000:15000300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree and leaves segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$z$')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(-2.8*las['y'][PCsample] + 420, las['z'][PCsample], s=0.5, c='gray', alpha=0.5)\n",
    "plt.axhline(19.5, c='g')\n",
    "plt.axhline(21.5, c='g')\n",
    "\n",
    "plt.xlabel(r'$-2.8y + 420$', size=20)\n",
    "plt.ylabel(r'$z$', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$z$')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(2.8*las['x'][PCsample], las['z'][PCsample], s=0.5, c='gray', alpha=0.5)\n",
    "plt.axhline(19.5, c='g')\n",
    "plt.axhline(21.5, c='g')\n",
    "\n",
    "plt.xlabel(r'$-2.8y + 300$', size=20)\n",
    "plt.ylabel(r'$z$', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "zmin, zmax, zfar = 19.5, 21.5, 23\n",
    "\n",
    "keep = PCsample & (las.z > 20.8) & (las.z < zfar)\n",
    "Ntot = keep.sum()\n",
    "\n",
    "db = DBSCAN(eps=0.25).fit(points[keep])\n",
    "\n",
    "labels = {}\n",
    "\n",
    "for i in set(db.labels_):\n",
    "    mask = db.labels_ == i\n",
    "    perc = 100*mask.sum()/Ntot\n",
    "    if perc > 1:\n",
    "        # print(i, perc)\n",
    "        labels[i] = mask\n",
    "\n",
    "N = len(list(labels.keys()))\n",
    "\n",
    "# plot the two point clouds\n",
    "coltmp = plt.cm.jet(np.linspace(0,1,N))[:,0:3]\n",
    "\n",
    "if True:\n",
    "    pointslist = [points[keep][val] for val in labels.values()]\n",
    "    colours = [list(i) for i in coltmp]\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "above = np.zeros(len(points), dtype=bool)\n",
    "keep = PCsample & (las.z > 20.8) & (las.z < zfar)\n",
    "\n",
    "for val in labels.values():\n",
    "\n",
    "    above[keep] |= val\n",
    "\n",
    "keep = PCsample & ~above\n",
    "rej = PCsample & above\n",
    "\n",
    "if True:\n",
    "    pointslist = [points[keep], points[rej]]\n",
    "    colours = [colors[keep]/2**16, [1, 0, 0]]\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentiles masking\n",
    "\n",
    "In order to get rid of the stems of kiwifruit trees, first, we take a slide parallel to the stems arange. We have a total of two slides that folow equation:\n",
    "\n",
    "$$y = 0.34x - 0.5 \\\\\n",
    "y = 0.34x + 3.3, $$\n",
    "\n",
    "each one with width of $0.6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$y$')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep = PCsample & (las.z < 19.7) & (las.z > 18.2)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.scatter(np.array(las.x)[keep], np.array(las.y)[keep], c='k', s=0.01)\n",
    "\n",
    "x = np.linspace(70, 95, 20)\n",
    "\n",
    "plt.plot(x, 2.8*x - 93, c='r', lw=1, ls='--')\n",
    "plt.plot(x, 2.8*x - 105, c='r', lw=1, ls='--')\n",
    "plt.plot(x, 2.8*x - 118, c='r', lw=1, ls='--')\n",
    "\n",
    "for i in [2, -2]:\n",
    "\n",
    "    plt.plot(x, 2.8*x - 93 + i, c='g', lw=1, ls='-')\n",
    "    plt.plot(x, 2.8*x - 105 + i, c='g', lw=1, ls='-')\n",
    "    plt.plot(x, 2.8*x - 118 + i, c='g', lw=1, ls='-')\n",
    "\n",
    "plt.xlabel(r'$x$', size=20)\n",
    "plt.ylabel(r'$y$', size=20)\n",
    "\n",
    "# plt.xlim(-20, -10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "slides = {}\n",
    "\n",
    "for num,i in enumerate([-93, -105]):\n",
    "    slides['slide%s' %(str(num))] = (np.array(las.y) > 2.8*np.array(las.x) +i - 2) & (np.array(las.y) < 2.8*np.array(las.x) +i + 2)\n",
    "\n",
    "below = np.zeros(len(points), dtype=bool)\n",
    "\n",
    "for key, val in slides.items():\n",
    "\n",
    "    keep = PCsample & i & (las.z > 19.5) & (las.z < 21.5) & ~above\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.scatter(-2.8*las['y'][PCsample & ~above & val][::1] + 420, las['z'][PCsample & ~above & val][::1], s=0.04, c='k')\n",
    "    plt.axhline(19.5, lw=1, c='k')\n",
    "    plt.axhline(21.5, lw=1, c='k')\n",
    "\n",
    "    res, bcmask = loads.remove_outliers(-2.8*las['y'][keep] + 420, las['z'][keep], nbins=100, bounds=(2, 98.0))\n",
    "    below[keep] |= ~bcmask\n",
    "\n",
    "    # plt.ylim(-1,4)\n",
    "\n",
    "    plt.xlabel(r'$y$', size=20)\n",
    "    plt.ylabel(r'$z$', size=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# sanity check: check that red dots corresponds to the regions we want to mask out\n",
    "if True:\n",
    "    keep = PCsample & ~above & ~below\n",
    "    rej = PCsample & (above | below)\n",
    "    pointslist = [points[keep], points[rej]]\n",
    "    colours = [colors[keep]/2**16, [1, 0, 0]]\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# foliage\n",
    "\n",
    "foliage = ~above & ~below & (las.z > 19.5) & (las.z < 21.5)\n",
    "keep = PCsample & foliage\n",
    "# rej = PCsample & ~foliage\n",
    "if True:\n",
    "    pointslist = [points[keep]]\n",
    "    colours = [colors[keep]/2**16]\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # points in sample: 2015758\n",
      "total # points within foliage: 1857143, \t 92.13 %\n"
     ]
    }
   ],
   "source": [
    "N = PCsample.sum()\n",
    "samp = PCsample & foliage\n",
    "\n",
    "print('total # points in sample: %i' %(N))\n",
    "print('total # points within foliage: %i, \\t %.2f %%' %(samp.sum(), 100*samp.sum()/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segtree(df, leaves, show=False):\n",
    "\n",
    "    trees = {}\n",
    "    centres = []\n",
    "    # keepS = PCsample[::100]\n",
    "    # PCsample = (points[:,1] > 0.34*points[:,0] - 3.0) & (points[:,1] < 0.34*points[:,0] + 5)\n",
    "    # PCsample &= (points[:,0] < -0.35*points[:,1] - 10) & (points[:,0] > -0.35*points[:,1] - 20)\n",
    "    # bins = np.arange(10, 20, 1)\n",
    "    wi = 10\n",
    "    wj = 10\n",
    "    squares = list(itertools.product(np.arange(400, 500, wi), np.arange(-120, -80, wj)))\n",
    "\n",
    "    if show:\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "\n",
    "    for num, (i,j) in enumerate(squares):\n",
    "\n",
    "        keep = np.ones(len(df['x']), dtype=bool)\n",
    "        keep &= (df['y'] > 2.8*df['x'] + j) & (df['y'] < 2.8*df['x'] + (j+wj))\n",
    "        keep &= (df['x'] > -2.8*df['y'] + i) & (df['x'] < -2.8*df['y'] + (i+wi))\n",
    "\n",
    "        # PCsample = (p[:,1] > 2.8*p[:,0] - 120) & (p[:,1] < 2.8*p[:,0] -80)\n",
    "        # PCsample &= (p[:,0] < -2.8*p[:,1] + 500) & (p[:,0] > -2.8*p[:,1] + 400)\n",
    "        # print(np.sum(keep))\n",
    "\n",
    "        trees['tree_%s' %(str(num))] = keep\n",
    "            \n",
    "        if show:\n",
    "            plt.scatter(df['x'][leaves & keep], df['y'][leaves & keep], s=0.5, label=i)\n",
    "            p = ((i+0.5) - 0.35 * (j+0.5)) / (1 + (0.35 * 0.34))\n",
    "            ya = 0.34*(p) + (j+0.5)\n",
    "            centres.append([num, p, ya])\n",
    "            # plt.scatter(p,ya, s=20, c='k')\n",
    "\n",
    "            box = dict(facecolor='green', edgecolor='black', boxstyle='round,pad=0.5', alpha=0.8)\n",
    "            text = 'tree_%s' %(str(num))\n",
    "\n",
    "            # x = np.linspace(-18, -12, 5)\n",
    "            # plt.plot(x, 0.34*x + j + 0.5, c='r', lw=1, ls='--')\n",
    "            # plt.plot(x, (x - (i + 0.5))/(-0.35), c='r', lw=1, ls='--')\n",
    "\n",
    "            plt.text(p, ya, text, size=10, bbox=box)\n",
    "\n",
    "    if show:\n",
    "        # plt.scatter(df['x'][leaves], df['y'][leaves], s=0.1, c='k')\n",
    "        plt.xlabel(r'$x$', size=20)\n",
    "        plt.ylabel(r'$y$', size=20)\n",
    "        # plt.show()\n",
    "        \n",
    "    return trees, centres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves = PCsample & foliage\n",
    "trees, centres = segtree(df, leaves, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save centre coordinates of patches\n",
    "resdir = os.path.join(_data, name, 'lia')\n",
    "if not os.path.exists(resdir):\n",
    "    os.makedirs(resdir)\n",
    "    \n",
    "df_centres = pd.DataFrame(centres, columns=['tree_id', 'x', 'y'])\n",
    "df_centres.to_csv(os.path.join(resdir, 'centres.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# show the point cloud from leaves of firs tree only\n",
    "keep = (trees['tree_0']) & (leaves)\n",
    "# loads.showPCfromDF(df[keep])\n",
    "\n",
    "if True:\n",
    "    pointslist = [points[keep]]\n",
    "    colours = [colors[keep]/2**16]\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intensity vs MLS beam trajectory distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 81.56263993,  81.71232847,  82.01202894, ..., 212.46993869,\n",
       "       213.60740158, 212.40959348])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors = np.vstack((df['xs'].values, df['ys'].values, df['zs'].values)).transpose()\n",
    "\n",
    "# get the distances between the PC and the sensor\n",
    "ab = sensors - points\n",
    "dist = np.sqrt(np.sum((ab) ** 2, axis=1))\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-10.1 0\n",
      "20-20.1 831\n",
      "30-30.1 2837\n",
      "40-40.1 1300\n",
      "50-50.1 1225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Intensity')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep = PCsample\n",
    "\n",
    "f = plt.figure(figsize=(10,6))\n",
    "plt.hist(dist[keep], 50, density=True)\n",
    "plt.title('Distance between the PC and sensor', size=15)\n",
    "\n",
    "distbins = {}\n",
    "\n",
    "for i in [10, 20, 30, 40, 50]:\n",
    "\n",
    "    distbins['%s-%s.1' %(str(i), str(i))] = np.logical_and(dist[keep] > i, dist[keep] < i+0.1)\n",
    "    plt.axvline(i, ls='--', color='k')\n",
    "\n",
    "\n",
    "intensity = np.array(las.intensity[keep])\n",
    "\n",
    "f = plt.figure(figsize=(10,6))\n",
    "\n",
    "for key, val in distbins.items():\n",
    "\n",
    "    print(key, val.sum())\n",
    "\n",
    "    bins = np.linspace(intensity.min(), intensity.max(), 50)\n",
    "    plt.hist(intensity[val], bins=bins, histtype='step', lw=2, density=True, label=key)\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Intensity', size=15)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Leaf Inclination Angle` (LIA) estimation\n",
    "\n",
    "On the contrary to the mock example, here we can not use function `lia.bestfit_pars_la` to get the best-fit parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_lia(trees, name, voxel_size_w, kd3_sr, max_nn, voxel_size_h=0.1, savefig=True, savefig_extra=False):\n",
    "\n",
    "    # load bestfit results      \n",
    "    for num, (key, val) in enumerate(trees.items()):\n",
    "\n",
    "        # if num == 0: # for debug\n",
    "        if True:\n",
    "\n",
    "            print('********* %s *********' %(key))\n",
    "\n",
    "            keep = (val) & (leaves)\n",
    "            points = df[['x', 'y', 'z']].to_numpy()[keep]\n",
    "\n",
    "            text = '%s=%.4f \\n %s=%.4f \\n %s=%.4f ' %(\n",
    "                                    'voxel_size_w', voxel_size_w,\n",
    "                                    'kd3_sr', kd3_sr,\n",
    "                                    'max_nn', max_nn)\n",
    "\n",
    "            lia.leaf_angle(points, name, key, voxel_size_w, kd3_sr, max_nn, save=True,\n",
    "                                        savefig=savefig, text=text, voxel_size_h=voxel_size_h, ismock=False,\n",
    "                                        ylim=0.03, ylimh=0.45, savefig_extra=savefig_extra)\n",
    "\n",
    "            # save indexes from main df\n",
    "            # inds = np.where((val) & (leaves))\n",
    "            np.save(os.path.join(_data, name, 'lia', 'inds_%s.npy' %(key)), keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* tree_0 *********\n",
      "********* tree_1 *********\n",
      "********* tree_2 *********\n",
      "********* tree_3 *********\n",
      "********* tree_4 *********\n",
      "********* tree_5 *********\n",
      "********* tree_6 *********\n",
      "********* tree_7 *********\n",
      "********* tree_8 *********\n",
      "********* tree_9 *********\n",
      "********* tree_10 *********\n",
      "********* tree_11 *********\n",
      "********* tree_12 *********\n",
      "********* tree_13 *********\n",
      "********* tree_14 *********\n",
      "********* tree_15 *********\n",
      "********* tree_16 *********\n",
      "********* tree_17 *********\n",
      "********* tree_18 *********\n",
      "********* tree_19 *********\n",
      "********* tree_20 *********\n",
      "********* tree_21 *********\n",
      "********* tree_22 *********\n",
      "********* tree_23 *********\n",
      "********* tree_24 *********\n",
      "********* tree_25 *********\n",
      "********* tree_26 *********\n",
      "********* tree_27 *********\n",
      "********* tree_28 *********\n",
      "********* tree_29 *********\n",
      "********* tree_30 *********\n",
      "********* tree_31 *********\n",
      "********* tree_32 *********\n",
      "********* tree_33 *********\n",
      "********* tree_34 *********\n",
      "********* tree_35 *********\n",
      "********* tree_36 *********\n",
      "********* tree_37 *********\n",
      "********* tree_38 *********\n",
      "********* tree_39 *********\n"
     ]
    }
   ],
   "source": [
    "run_lia(trees, name, voxel_size_w=0.01, kd3_sr=0.15, max_nn=300, \n",
    "voxel_size_h=0.05, savefig=True, savefig_extra=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files for Junqi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code takes `results_per_height_tree_<ID>.csv` file adds the `LAD` column and break the `values` array to asign a value to a column. Result is stored in Junqi directory with same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "for file in glob.glob(os.path.join(_data, name, 'lia', 'results_per_*.csv')):\n",
    "    # print(file)\n",
    "    df_ = pd.read_csv(file)\n",
    "    outfile = os.path.join(_data, name, 'lia', 'junqi', file.split('/')[-1])\n",
    "    a = df_['values'].str[1:-1]\n",
    "    keep = [len(i) > 0 for i in a]\n",
    "    a = a.str.split(expand=True)\n",
    "    df_['lad'] = np.arange(0, len(a))\n",
    "    pd.concat([df_['zmin'][keep], df_['lad'][keep], a[keep]], axis=1).to_csv(outfile, index=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `\u001dLeaf Area Density` (LAD) estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_0 54237\n",
      "tree_1 58546\n",
      "tree_2 35130\n",
      "tree_3 55879\n",
      "tree_4 52307\n",
      "tree_5 57671\n",
      "tree_6 35096\n",
      "tree_7 56137\n",
      "tree_8 51493\n",
      "tree_9 57432\n",
      "tree_10 35975\n",
      "tree_11 56780\n",
      "tree_12 51606\n",
      "tree_13 57698\n",
      "tree_14 35461\n",
      "tree_15 56736\n",
      "tree_16 50674\n",
      "tree_17 58809\n",
      "tree_18 36302\n",
      "tree_19 56532\n",
      "tree_20 49828\n",
      "tree_21 57757\n",
      "tree_22 35447\n",
      "tree_23 57236\n",
      "tree_24 51740\n",
      "tree_25 58728\n",
      "tree_26 35960\n",
      "tree_27 56752\n",
      "tree_28 49937\n",
      "tree_29 57077\n",
      "tree_30 37127\n",
      "tree_31 56474\n",
      "tree_32 49037\n",
      "tree_33 56287\n",
      "tree_34 37248\n",
      "tree_35 56586\n",
      "tree_36 48797\n",
      "tree_37 57296\n",
      "tree_38 36470\n",
      "tree_39 59473\n"
     ]
    }
   ],
   "source": [
    "for key, val in trees.items():\n",
    "\n",
    "    keep = (val)\n",
    "    print(key, np.sum(keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsampling is always implemented\n",
    "voxel_size = 0.1\n",
    "\n",
    "# set to a value to use Random-base downsampling instead of voxel-based downsampling\n",
    "downsample = None\n",
    "# to check everything looks fine\n",
    "show = False\n",
    "sample = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement and keep Downsampled points\n",
    "\n",
    "Below code will implement a downsampling using either `random` or `voxel`. The donsampling is performed by saving the corresponding indexes list of the downsampled percentage from the original data size. If index list already exists we just take it to make the downsampling, if it does not exist yet, we created and save ir under its corresponding directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minpoint: [ 0.          0.         14.63463378]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if downsample is not None:\n",
    "    inds = lad.random_downsample(N, downsample, name)\n",
    "    print('Random downsampling...')\n",
    "else:\n",
    "    inds = lad.voxel_subsampling(voxel_size, df[['x', 'y', 'z']].to_numpy())\n",
    "    print('Voxel downsampling...')\n",
    "\n",
    "print('Downsampling percentage: %.1f %%' %(100 *  len(inds) / len(df['x'])))\n",
    "\n",
    "df = df.iloc[inds]\n",
    "POINTS = df[['x', 'y', 'z']].to_numpy()\n",
    "SENSORS = df[['xs', 'ys', 'zs']].to_numpy()\n",
    "COLORS = colors[inds]\n",
    "\n",
    "# Compute lower point\n",
    "minpoint = np.min(POINTS, axis=0) # check this...\n",
    "print('minpoint:', minpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save indexes of voxel-based downsample\n",
    "if downsample is not None:\n",
    "    dirname = 'random_%s' %(str(downsample))\n",
    "    resdir = os.path.join(_data, name, dirname, 'lad_%s' %(str(voxel_size)))\n",
    "else:\n",
    "    dirname = 'voxel'\n",
    "    resdir = os.path.join(_data, name, dirname, 'lad_%s' %(str(voxel_size)))\n",
    "\n",
    "if not os.path.exists(resdir): os.makedirs(resdir)\n",
    "outdir = os.path.join(resdir, 'inds.npy')\n",
    "np.save(outdir, np.array(inds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leave and tree segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves = leaves[inds]\n",
    "\n",
    "for key, val in trees.items():\n",
    "    trees[key] = val[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    pointslist = [POINTS[leaves]]\n",
    "    colours = [COLORS[leaves]/2**16]\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== tree_0 ==============\n",
      "# iter... 7466610\n",
      "Results will be saved at /Users/omar/projects/planttech/data/kiwifruit_interpine/voxel/lad_0.1\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1872556it [01:08, 26580.61it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "for key, val in trees.items():\n",
    "\n",
    "    # if key == 'tree_0': #for debug\n",
    "    if True:\n",
    "        print('============== %s ==============' %(key))\n",
    "        inPR = (leaves) & (val)\n",
    "        minBB, maxBB = np.min(POINTS[inPR.values], axis=0), np.max(POINTS[inPR.values], axis=0)\n",
    "\n",
    "        minpointPR = minpoint + np.floor(np.abs(minpoint - minBB)/voxel_size) * voxel_size\n",
    "        maxpointPR = minpoint + np.ceil(np.abs(minpoint - maxBB)/voxel_size) * voxel_size\n",
    "\n",
    "        if sample is not None:\n",
    "            print('# iter...', len(POINTS[::sample]))\n",
    "            m3s = rayt.main2(POINTS[::sample], SENSORS[::sample], POINTS[inPR], voxel_size, resdir, key, (minpointPR, maxpointPR), show=True)\n",
    "        else:\n",
    "            print('# iter...', len(POINTS))\n",
    "            print('Results will be saved at %s' %(resdir))\n",
    "            print('-------------')\n",
    "            m3s = rayt.main2(POINTS, SENSORS, POINTS[inPR], voxel_size, resdir, key, (minpointPR, maxpointPR), show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runall(name, pointsPR, sensorsPR, inPR, voxel_size, tree, N, PRbounds, resdir, kbins=None, inverted=False):\n",
    "\n",
    "    inds_file = os.path.join(resdir, 'inds.npy')\n",
    "    inds0 = np.load(inds_file)\n",
    "    inds_lia = np.load(os.path.join(_data, name, 'lia', 'inds_%s.npy' %(tree)))\n",
    "\n",
    "    isfigures = os.path.join(resdir, 'figures')\n",
    "    if not os.path.exists(isfigures):\n",
    "        os.makedirs(isfigures)\n",
    "\n",
    "    attributes2_file = os.path.join(resdir, 'm3s_%s_%s.npy' %(tree, str(voxel_size)))\n",
    "    if os.path.isfile(attributes2_file):\n",
    "        m3b = np.load(attributes2_file)\n",
    "\n",
    "    print('voxel_size:', voxel_size)\n",
    "\n",
    "    # Load LIAs and its weights saved at `get_lia()`.\n",
    "    # Size of lias and ws arrays is the original size after leaf and tree extraction only.\n",
    "    lias, ws = loads.load_lias_ws(name, tree)\n",
    "\n",
    "    # Create  arrays of original size filled with -99\n",
    "    lias0 = np.full(N, -99)\n",
    "    ws0 = np.full(N, -99)\n",
    "\n",
    "    # fill arrays with lias and ws values where it correspond to.\n",
    "    lias0[np.where(inds_lia)[0]] = lias\n",
    "    ws0[np.where(inds_lia)[0]] = ws\n",
    "\n",
    "    # Finally, apply downsampling and second dowsampling to lias and ws.\n",
    "    lias = lias0[inds0[inPR]]\n",
    "    ws = ws0[inds0[inPR]]\n",
    "\n",
    "    try:\n",
    "        assert len(lias) == sum(inPR)\n",
    "    except Exception as e:\n",
    "        print('lias size does not match with Plant Region size.')\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        assert len(ws) == sum(inPR)\n",
    "    except Exception as e:\n",
    "        print('ws size does not match with Plant Region size.')\n",
    "        print(e)\n",
    "\n",
    "    voxk = lad.get_voxk(pointsPR, PRbounds, voxel_size)\n",
    "    bia = lad.get_bia(pointsPR, sensorsPR)\n",
    "    meshfile = None\n",
    "\n",
    "    figext = '%s_%s' %(tree, str(voxel_size))\n",
    "    \n",
    "    alphas_k = lad.alpha_k(bia, voxk, lias, ws, resdir, meshfile, figext=figext, \n",
    "                            klia=False, use_true_lia=False)\n",
    "\n",
    "    kmax = m3b.shape[2]\n",
    "    \n",
    "    if kbins is None:\n",
    "        kbins = int(kmax/15)\n",
    "    print('kmax', kmax)\n",
    "    print('kbins', kbins)\n",
    "\n",
    "    oldlad = True\n",
    "    \n",
    "    lads_mid_1, clai_1 = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6], PRbounds, tree, resdir, oldlad=oldlad, C=1)\n",
    "    lads_0, clai_0 = lad.get_LADS2(pointsPR, kmax, voxel_size, kbins, alphas_k[:,6]*0+1, PRbounds, tree, resdir, oldlad=oldlad, C=1)\n",
    "\n",
    "    lads = {'Correction Mean C=1':lads_mid_1, 'No Correction C=1':lads_0}\n",
    "    attributes_file = os.path.join(resdir, 'm3s_%s_%s.npy' %(tree, str(voxel_size)))\n",
    "    if os.path.isfile(attributes_file):\n",
    "        RT = 'Y'\n",
    "    else:\n",
    "        RT = 'N'\n",
    "        \n",
    "    text = {'tree':tree, 'VS':voxel_size, 'Ray Tracing':RT, 'CLAI 1.0':np.round(clai_1, 3),  'CLAI 1.0 -- NC':np.round(clai_0, 3)}\n",
    "    txt = []\n",
    "    for key, val in text.items():\n",
    "        txt.append('%s=%s \\n' %(key, str(val)))\n",
    "    text = (' ').join(txt)\n",
    "\n",
    "    savefig = os.path.join(resdir, 'figures','LAD_%s.png' %(figext))\n",
    "    figures.plot_lads(lads, text, savefig=savefig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voxel_size: 0.1\n",
      "kmax 9\n",
      "kbins 1\n"
     ]
    }
   ],
   "source": [
    "inPR = (leaves) & (trees['tree_0'])\n",
    "runall(name, POINTS[inPR], SENSORS[inPR], inPR, voxel_size, 'tree_0', len(points), (minpointPR, maxpointPR), resdir, kbins=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POINTS = loads.DF2array(df[['x', 'y', 'z']])\n",
    "# SENSORS = loads.DF2array(df[['xs', 'ys', 'zs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = PCsample & (las.z < 0.8)\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.scatter(np.array(las.x)[keep][::1], np.array(las.z)[keep][::1], s=0.04, c='k')\n",
    "plt.axhline(0.2, lw=1, c='k')\n",
    "\n",
    "# res, bcmask = loads.remove_outliers(np.array(las.y)[keep], np.array(las.z)[keep], nbins=100, bounds=(0, 90))\n",
    "# below[keep] |= ~bcmask\n",
    "\n",
    "# plt.ylim(-1,4)\n",
    "\n",
    "plt.xlabel(r'$x$', size=20)\n",
    "plt.ylabel(r'$z$', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = PCsample & (las.z < 0)\n",
    "Ntot = keep.sum()\n",
    "\n",
    "db = DBSCAN(eps=0.3).fit(points[keep])\n",
    "# db = KMeans(n_clusters = 8, init='k-means++').fit(points[keep])\n",
    "\n",
    "labels = {}\n",
    "\n",
    "for i in set(db.labels_):\n",
    "    mask = db.labels_ == i\n",
    "    perc = 100*mask.sum()/Ntot\n",
    "    if perc > 0:\n",
    "        print(i, perc)\n",
    "        labels[i] = mask\n",
    "\n",
    "N = len(list(labels.keys()))\n",
    "\n",
    "# plot the two point clouds\n",
    "coltmp = plt.cm.jet(np.linspace(0,1,N))[:,0:3]\n",
    "\n",
    "pointslist = [points[keep][val] for val in labels.values()]\n",
    "colours = [list(i) for i in coltmp]\n",
    "loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8\n",
    "keep = PCsample & (las.z < 0)\n",
    "pcd = loads.points2pcd(POINTS[keep], colors=[1,0,0])\n",
    "downpcd = pcd.voxel_down_sample(voxel_size=0.05)\n",
    "print(f\"alpha={alpha:.3f}\")\n",
    "mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(downpcd, alpha)\n",
    "mesh.compute_vertex_normals()\n",
    "# pcd = loads.points2pcd(POINTS[keep], colors=[1,0,0])\n",
    "# downpcd = pcd.voxel_down_sample(voxel_size=0.05)\n",
    "o3d.visualization.draw_geometries([downpcd, mesh.paint_uniform_color([0.5, 0.3, 0.1])], mesh_show_back_face=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('filter with average with 1 iteration')\n",
    "mesh_out = mesh.filter_smooth_simple(number_of_iterations=2)\n",
    "mesh_out.compute_vertex_normals()\n",
    "print(mesh)\n",
    "vertices = np.asarray(mesh_out.vertices)\n",
    "pcd = loads.points2pcd(vertices, colors=[1,0,0])\n",
    "mesh_name = os.path.join(_data, name, 'dtm_mesh.obj')\n",
    "o3d.io.write_triangle_mesh(mesh_name, mesh_out)\n",
    "o3d.visualization.draw_geometries([pcd, mesh_out], mesh_show_back_face=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(_data,'DTM_vertices.csv'), vertices, fmt=\"%.8f\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-Do\n",
    "\n",
    "1) Fix algorithm to find `voxel size` from `downsampling`. It currently seems to work for the toy kiwifruit tree it isn't for the real data. Try:\n",
    "   * Check that the algorithm realy work by computing several `LAD`s for different `downsampling` values using the toy model.\n",
    "   * Remove outliers of foliage point cloud `FPC` as these might be adding noise to the mean of points per voxel. Try cliping or with a built-in `Open3D` function.\n",
    "2) Improve `ray tracing` algorithm:\n",
    "   * find a way to reduce the main sample i.e. `POINTS` and `SENSORS` to keep only the rays that pass trhough the plant region `PR`. It might be not that easy as many other process are involved.\n",
    "3) Once `LAD` algorithm works. Usea the leaf inclination angles (`LIA`) and the leaf area index (`LAI`) as input parameters to built a realistic model of the kiwifruit trees. One way to do this is using `Blensor` software. Here, we can create a Python script to create the kiwifruit trees with the option of change some of the tree features such as the leaf sizes and leaf angles. Then, in a recursive algorithm, modify these values until we get the same `LIA` and `LAI` distributions from the real LiDAR."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "760a6cd4159ac8b99590d0ad7ba9faed7c379184a996bf44e62e475912739812"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('plant-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
