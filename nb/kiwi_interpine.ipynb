{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import laspy as lp\n",
    "import pdal\n",
    "import pandas as pd\n",
    "import open3d as o3d\n",
    "from dbfread import DBF\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "# basedir = os.path.dirname(os.getcwd())\n",
    "basedir = os.path.abspath(os.path.join(os.getcwd() ,\"../\"))\n",
    "_py = os.path.join(basedir, 'py')\n",
    "_data = os.path.join(basedir, 'data')\n",
    "\n",
    "sys.path.insert(1, _py)\n",
    "import loads\n",
    "import lia\n",
    "import ray as rayt\n",
    "import lad\n",
    "import figures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib qt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'kiwifruit_interpine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'Z', 'intensity', 'return_number', 'number_of_returns', 'synthetic', 'key_point', 'withheld', 'overlap', 'scanner_channel', 'scan_direction_flag', 'edge_of_flight_line', 'classification', 'user_data', 'scan_angle', 'point_source_id', 'gps_time', 'red', 'green', 'blue']\n"
     ]
    }
   ],
   "source": [
    "# load files\n",
    "las = loads.loadlaz(name)\n",
    "\n",
    "# See LAS columns names\n",
    "point_format = las.point_format\n",
    "if True:\n",
    "    print(list(point_format.dimension_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# las to data frame\n",
    "columns = ['x', 'y', 'z', 'intensity', 'return_number', 'number_of_returns', 'gps_time', 'red', 'green', 'blue']\n",
    "las = pd.DataFrame(np.vstack((las.x, las.y, las.z, las.intensity, las.return_number, las.number_of_returns, las.gps_time, las.red, las.green, las.blue)).transpose(), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift x and y coordinates near zero\n",
    "for i in ['x', 'y']:\n",
    "    ismin = np.min(las[i])\n",
    "    las[i] = las[i] - ismin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define point cloud with RGB colours\n",
    "points = np.vstack((las.x, las.y, las.z)).transpose()\n",
    "colors = np.vstack((las.red, las.green, las.blue)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading trayectory file:\n",
      " could not find file '/Users/omar/projects/planttech/data/kiwifruit_interpine/trajectory.dbf'\n",
      "A mock trajectory will be used.\n"
     ]
    }
   ],
   "source": [
    "# trajectory file must be called `trajectory.dbf` anc must contain x, y, z and gpstime\n",
    "# if trajectory not given, bellow we mock this following x, y and gps_time values from point cloud \n",
    "try:\n",
    "    traj = loads.loaddbf(name)\n",
    "    traj = pd.DataFrame(iter(traj)) # to pandas\n",
    "except Exception as e:\n",
    "    print('Error loading trayectory file:\\n %s' %(e))\n",
    "    print('A mock trajectory will be used.')\n",
    "\n",
    "    xymin = np.amin(points[:,:2], axis=0)\n",
    "    xymax = np.amax(points[:,:2], axis=0)\n",
    "    xymock = np.linspace(xymin, xymax, 50)\n",
    "\n",
    "    zmock = np.full((len(xymock), 1), 40, dtype=int)\n",
    "\n",
    "    gpsmin = las.gps_time.min()\n",
    "    gpsmax = las.gps_time.max()\n",
    "    gpsmock = np.linspace(gpsmin, gpsmax, len(xymock)).reshape(len(xymock), 1)\n",
    "\n",
    "    traj = np.append(xymock, zmock, axis=1)\n",
    "    traj = np.append(traj, gpsmock, axis=1)\n",
    "\n",
    "    traj = pd.DataFrame(traj, columns=['x', 'y', 'z', 'gpstime'])\n",
    "\n",
    "points_t = np.vstack((traj.x, traj.y, traj.z)).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a region to run our pipeline as we know much of the point cloud is not relevant for the posterior analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PCsample(p):\n",
    "\n",
    "    PCsample = (p[:,1] > 2.8*p[:,0] - 120) & (p[:,1] < 2.8*p[:,0] -80)\n",
    "    PCsample &= (p[:,0] < -2.8*p[:,1] + 500) & (p[:,0] > -2.8*p[:,1] + 400)\n",
    "\n",
    "    return PCsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$y$')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "xymin = np.amin(points[:,:2][::n], axis=0)\n",
    "xymax = np.amax(points[:,:2][::n], axis=0)\n",
    "\n",
    "plt.scatter(points[:,0][::n], points[:,1][::n], s=0.5, c='gray', alpha=0.5)\n",
    "\n",
    "x = np.linspace(xymin[0], xymax[0], 3)\n",
    "y = np.linspace(xymin[1], xymax[1], 3)\n",
    "plt.plot(x, 2.8*x - 80, ls='--', lw=0.8, c='r')\n",
    "plt.plot(x, 2.8*x - 120, ls='--', lw=0.8, c='r')\n",
    "plt.plot(-2.8*y + 400, y, ls='--', lw=0.8, c='r')\n",
    "plt.plot(-2.8*y + 500, y, ls='--', lw=0.8, c='r')\n",
    "\n",
    "PCsample = get_PCsample(points[::n])\n",
    "print(PCsample.sum())\n",
    "plt.scatter(points[:,0][::n][PCsample], points[:,1][::n][PCsample], c='g', s=0.5)\n",
    "\n",
    "plt.xlim(0, 175)\n",
    "plt.ylim(0, 300)\n",
    "\n",
    "plt.xlabel(r'$x$', size=20)\n",
    "plt.ylabel(r'$y$', size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# plot the two point cloudsb\n",
    "if True:\n",
    "    pointslist = [points[::1000], points_t]\n",
    "    colours = [colors[::1000]/2**16, [1, 0, 0]]\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# define and plot a sample of the point cloud\n",
    "\n",
    "PCsample = get_PCsample(points)\n",
    "\n",
    "pointslist = [points[PCsample], points_t]\n",
    "colours = [colors[PCsample]/2**16, [1, 0, 0]]\n",
    "if True:\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# las_df = pd.DataFrame(np.append(points, las.gps_time.reshape(len(las.gps_time), 1), axis=1), columns=['x', 'y', 'z', 'gps_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate trajectory with gps time\n",
    "\n",
    "df = loads.coordsDF(las, traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>xs</th>\n",
       "      <th>ys</th>\n",
       "      <th>zs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.8851</td>\n",
       "      <td>52.6814</td>\n",
       "      <td>17.054934</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.1875</td>\n",
       "      <td>52.5695</td>\n",
       "      <td>17.030534</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58.8075</td>\n",
       "      <td>52.3344</td>\n",
       "      <td>17.004434</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.1026</td>\n",
       "      <td>52.2180</td>\n",
       "      <td>16.970034</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.9687</td>\n",
       "      <td>51.4525</td>\n",
       "      <td>16.780334</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x        y          z        xs        ys    zs\n",
       "0  57.8851  52.6814  17.054934  0.000090  0.000153  40.0\n",
       "1  58.1875  52.5695  17.030534  0.000099  0.000169  40.0\n",
       "2  58.8075  52.3344  17.004434  0.000117  0.000200  40.0\n",
       "3  59.1026  52.2180  16.970034  0.000126  0.000215  40.0\n",
       "4  60.9687  51.4525  16.780334  0.000180  0.000307  40.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sample of beams\n",
    "if False:\n",
    "    loads.showbeams(df[15000000:15000300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree and leaves segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(-2.8*las['y'][PCsample] + 400, las['z'][PCsample], s=0.5, c='gray', alpha=0.5)\n",
    "plt.axhline(19.5, c='g')\n",
    "plt.axhline(21.5, c='g')\n",
    "\n",
    "x = np.linspace(xymin[0], xymax[0], 3)\n",
    "y = np.linspace(xymin[1], xymax[1], 3)\n",
    "# plt.plot(x, 2.8*x - 80, ls='--', lw=0.8, c='r')\n",
    "# plt.plot(x, 2.8*x - 120, ls='--', lw=0.8, c='r')\n",
    "# plt.plot(-2.8*y + 400, y, ls='--', lw=0.8, c='r')\n",
    "# plt.plot(-2.8*y + 500, y, ls='--', lw=0.8, c='r')\n",
    "\n",
    "plt.xlabel(r'$-2.8y + 300$', size=20)\n",
    "plt.ylabel(r'$z$', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(2.8*las['x'][PCsample] + 300, las['z'][PCsample], s=0.5, c='gray', alpha=0.5)\n",
    "plt.axhline(19.5, c='g')\n",
    "plt.axhline(21.5, c='g')\n",
    "\n",
    "plt.xlabel(r'$-2.8y + 300$', size=20)\n",
    "plt.ylabel(r'$z$', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "zmin, zmax, zfar = 19.5, 21.5, 23\n",
    "\n",
    "keep = PCsample & (las.z > 20.8) & (las.z < zfar)\n",
    "Ntot = keep.sum()\n",
    "\n",
    "db = DBSCAN(eps=0.25).fit(points[keep])\n",
    "\n",
    "labels = {}\n",
    "\n",
    "for i in set(db.labels_):\n",
    "    mask = db.labels_ == i\n",
    "    perc = 100*mask.sum()/Ntot\n",
    "    if perc > 1:\n",
    "        # print(i, perc)\n",
    "        labels[i] = mask\n",
    "\n",
    "N = len(list(labels.keys()))\n",
    "\n",
    "# plot the two point clouds\n",
    "coltmp = plt.cm.jet(np.linspace(0,1,N))[:,0:3]\n",
    "\n",
    "if True:\n",
    "    pointslist = [points[keep][val] for val in labels.values()]\n",
    "    colours = [list(i) for i in coltmp]\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "above = np.zeros(len(points), dtype=bool)\n",
    "keep = PCsample & (las.z > 20.8) & (las.z < zfar)\n",
    "\n",
    "for val in labels.values():\n",
    "\n",
    "    above[keep] |= val\n",
    "\n",
    "keep = PCsample & ~above\n",
    "rej = PCsample & above\n",
    "\n",
    "if True:\n",
    "    pointslist = [points[keep], points[rej]]\n",
    "    colours = [colors[keep]/2**16, [1, 0, 0]]\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentiles masking\n",
    "\n",
    "In order to get rid of the stems of kiwifruit trees, first, we take a slide parallel to the stems arange. We have a total of two slides that folow equation:\n",
    "\n",
    "$$y = 0.34x - 0.5 \\\\\n",
    "y = 0.34x + 3.3, $$\n",
    "\n",
    "each one with width of $0.6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = PCsample & (las.z < 1.3) & (las.z > 0.4)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.scatter(np.array(las.x)[keep], np.array(las.y)[keep], c='k', s=0.01)\n",
    "\n",
    "x = np.linspace(-30, -10, 20)\n",
    "\n",
    "plt.plot(x, 0.34*x - 0.5, c='r', lw=1, ls='--')\n",
    "plt.plot(x, 0.34*x + 3.3, c='r', lw=1, ls='--')\n",
    "\n",
    "for i in [0.3, -0.3]:\n",
    "\n",
    "    plt.plot(x, 0.34*x - 0.5 + i, c='g', lw=1, ls='-')\n",
    "    plt.plot(x, 0.34*x + 3.3 + i, c='g', lw=1, ls='-')\n",
    "\n",
    "plt.xlabel(r'$x$', size=20)\n",
    "plt.ylabel(r'$y$', size=20)\n",
    "\n",
    "plt.xlim(-20, -10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide1 = (np.array(las.y) > 0.34*np.array(las.x) - 0.5 - 0.3) & (np.array(las.y) < 0.34*np.array(las.x) - 0.5 + 0.3)\n",
    "slide2 = (np.array(las.y) > 0.34*np.array(las.x) + 3.3 - 0.3) & (np.array(las.y) < 0.34*np.array(las.x) + 3.3 + 0.3)\n",
    "\n",
    "below = np.zeros(len(points), dtype=bool)\n",
    "\n",
    "for i in [slide1, slide2]:\n",
    "\n",
    "    keep = PCsample & i & (las.z > 1.5) & (las.z < 2.7) & ~above\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.scatter(np.array(las.x)[PCsample & ~above & i][::1], np.array(las.z)[PCsample & ~above & i][::1], s=0.04, c='k')\n",
    "    plt.axhline(1.5, lw=1, c='k')\n",
    "    plt.axhline(2.7, lw=1, c='k')\n",
    "\n",
    "    res, bcmask = loads.remove_outliers(np.array(las.x)[keep], np.array(las.z)[keep], nbins=100, bounds=(2, 98.0))\n",
    "    below[keep] |= ~bcmask\n",
    "\n",
    "    plt.ylim(-1,4)\n",
    "\n",
    "    plt.xlabel(r'$x$', size=20)\n",
    "    plt.ylabel(r'$z$', size=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: check that red dots corresponds to the regions we want to mask out\n",
    "if False:\n",
    "    keep = PCsample & ~above & ~below\n",
    "    rej = PCsample & (above | below)\n",
    "    pointslist = [points[keep], points[rej]]\n",
    "    colours = [colors[keep]/2**16, [1, 0, 0]]\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foliage\n",
    "\n",
    "foliage = ~above & ~below & (las.z > 1.5) & (las.z < 2.7)\n",
    "keep = PCsample & foliage\n",
    "# rej = PCsample & ~foliage\n",
    "if False:\n",
    "    pointslist = [points[keep]]\n",
    "    colours = [colors[keep]/2**16]\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = PCsample.sum()\n",
    "samp = PCsample & foliage\n",
    "\n",
    "print('total # points in sample: %i' %(N))\n",
    "print('total # points within foliage: %i, \\t %.2f %%' %(samp.sum(), 100*samp.sum()/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segtree(df, leaves, show=False):\n",
    "\n",
    "    trees = {}\n",
    "    centres = []\n",
    "    # keepS = PCsample[::100]\n",
    "    # PCsample = (points[:,1] > 0.34*points[:,0] - 3.0) & (points[:,1] < 0.34*points[:,0] + 5)\n",
    "    # PCsample &= (points[:,0] < -0.35*points[:,1] - 10) & (points[:,0] > -0.35*points[:,1] - 20)\n",
    "    # bins = np.arange(10, 20, 1)\n",
    "    squares = list(itertools.product(np.arange(-20, -10, 1), np.arange(-3, 5, 1)))\n",
    "\n",
    "    if show:\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "\n",
    "    for num, (i,j) in enumerate(squares):\n",
    "        # print(i,j)\n",
    "        keep = np.ones(len(df['x']), dtype=bool)\n",
    "        keep &= (df['y'] > 0.34*df['x'] + j) & (df['y'] < 0.34*df['x'] + (j+1))\n",
    "        keep &= (df['x'] > -0.35*df['y'] + i) & (df['x'] < -0.35*df['y'] + (i+1))\n",
    "        # print(np.sum(keep))\n",
    "\n",
    "        trees['tree_%s' %(str(num))] = keep\n",
    "            \n",
    "        if show:\n",
    "            plt.scatter(df['x'][leaves & keep], df['y'][leaves & keep], s=0.5, label=i)\n",
    "            p = ((i+0.5) - 0.35 * (j+0.5)) / (1 + (0.35 * 0.34))\n",
    "            ya = 0.34*(p) + (j+0.5)\n",
    "            centres.append([num, p, ya])\n",
    "            # plt.scatter(p,ya, s=20, c='k')\n",
    "\n",
    "            box = dict(facecolor='green', edgecolor='black', boxstyle='round,pad=0.5', alpha=0.8)\n",
    "            text = 'tree_%s' %(str(num))\n",
    "\n",
    "            # x = np.linspace(-18, -12, 5)\n",
    "            # plt.plot(x, 0.34*x + j + 0.5, c='r', lw=1, ls='--')\n",
    "            # plt.plot(x, (x - (i + 0.5))/(-0.35), c='r', lw=1, ls='--')\n",
    "\n",
    "            plt.text(p, ya, text, size=10, bbox=box)\n",
    "\n",
    "    if show:\n",
    "        # plt.scatter(df['x'][leaves], df['y'][leaves], s=0.1, c='k')\n",
    "        plt.xlabel(r'$x$', size=20)\n",
    "        plt.ylabel(r'$y$', size=20)\n",
    "        # plt.show()\n",
    "        \n",
    "    return trees, centres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves = PCsample & foliage\n",
    "trees, centres = segtree(df, leaves, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save centre coordinates of patches\n",
    "resdir = os.path.join(_data, name, 'lia')\n",
    "if not os.path.exists(resdir):\n",
    "    os.makedirs(resdir)\n",
    "    \n",
    "df_centres = pd.DataFrame(centres, columns=['tree_id', 'x', 'y'])\n",
    "df_centres.to_csv(os.path.join(resdir, 'centres.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the point cloud from leaves of firs tree only\n",
    "keep = (trees['tree_0']) & (leaves)\n",
    "# loads.showPCfromDF(df[keep])\n",
    "\n",
    "if False:\n",
    "    pointslist = [points[keep]]\n",
    "    colours = [colors[keep]/2**16]\n",
    "    loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intensity vs MLS beam trajectory distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = np.vstack((df['xs'].values, df['ys'].values, df['zs'].values)).transpose()\n",
    "\n",
    "# get the distances between the PC and the sensor\n",
    "ab = sensors - points\n",
    "dist = np.sqrt(np.sum((ab) ** 2, axis=1))\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = PCsample\n",
    "\n",
    "f = plt.figure(figsize=(10,6))\n",
    "plt.hist(dist[keep], 50, density=True)\n",
    "plt.title('Distance between the PC and sensor', size=15)\n",
    "\n",
    "distbins = {}\n",
    "\n",
    "for i in [10, 20, 30, 40, 50]:\n",
    "\n",
    "    distbins['%s-%s.1' %(str(i), str(i))] = np.logical_and(dist[keep] > i, dist[keep] < i+0.1)\n",
    "    plt.axvline(i, ls='--', color='k')\n",
    "\n",
    "\n",
    "intensity = np.array(las.intensity[keep])\n",
    "\n",
    "f = plt.figure(figsize=(10,6))\n",
    "\n",
    "for key, val in distbins.items():\n",
    "\n",
    "    print(key, val.sum())\n",
    "\n",
    "    bins = np.linspace(intensity.min(), intensity.max(), 50)\n",
    "    plt.hist(intensity[val], bins=bins, histtype='step', lw=2, density=True, label=key)\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Intensity', size=15)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Leaf Inclination Angle` (LIA) estimation\n",
    "\n",
    "On the contrary to the mock example, here we can not use function `lia.bestfit_pars_la` to get the best-fit parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_lia(trees, voxel_size_w, kd3_sr, max_nn, voxel_size_h=0.1, savefig=True, savefig_extra=False):\n",
    "\n",
    "    # load bestfit results      \n",
    "    for num, (key, val) in enumerate(trees.items()):\n",
    "\n",
    "        # if num == 0: # for debug\n",
    "        if True:\n",
    "\n",
    "            print('********* %s *********' %(key))\n",
    "\n",
    "            keep = (val) & (leaves)\n",
    "            df_ = df[['x', 'y', 'z']][keep]\n",
    "            points = loads.DF2array(df_)\n",
    "            # print(points[:,2].min())\n",
    "\n",
    "            # voxel_size_w = 0.01\n",
    "            # kd3_sr = 0.15\n",
    "            # max_nn = 40\n",
    "\n",
    "            text = '%s=%.4f \\n %s=%.4f \\n %s=%.4f ' %(\n",
    "                                    'voxel_size_w', voxel_size_w,\n",
    "                                    'kd3_sr', kd3_sr,\n",
    "                                    'max_nn', max_nn)\n",
    "            # print(text)\n",
    "\n",
    "            lia.leaf_angle(points, name, key, voxel_size_w, kd3_sr, max_nn, save=True,\n",
    "                                        savefig=savefig, text=text, voxel_size_h=voxel_size_h, ismock=False,\n",
    "                                        ylim=0.03, ylimh=0.45, savefig_extra=savefig_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_lia(trees, voxel_size_w=0.01, kd3_sr=0.15, max_nn=300, \n",
    "voxel_size_h=0.05, savefig=False, savefig_extra=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files for Junqi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code takes `results_per_height_tree_<ID>.csv` file adds the `LAD` column and break the `values` array to asign a value to a column. Result is stored in Junqi directory with same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "for file in glob.glob(os.path.join(_data, name, 'lia', 'results_per_*.csv')):\n",
    "    # print(file)\n",
    "    df_ = pd.read_csv(file)\n",
    "    outfile = os.path.join(_data, name, 'lia', 'junqi', file.split('/')[-1])\n",
    "    a = df_['values'].str[1:-1]\n",
    "    keep = [len(i) > 0 for i in a]\n",
    "    a = a.str.split(expand=True)\n",
    "    df_['lad'] = np.arange(0, len(a))\n",
    "    pd.concat([df_['zmin'][keep], df_['lad'][keep], a[keep]], axis=1).to_csv(outfile, index=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code is deprecated now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    \n",
    "    import glob\n",
    "\n",
    "    files = glob.glob(os.path.join(_data, name, 'lia', 'angles*.npy'))\n",
    "    for file in files:\n",
    "        outfile = os.path.join(_data, name, 'lia', 'junqi', file.split('/')[-1].split('.')[0]+'.csv')\n",
    "        pd.DataFrame(np.load(file)).to_csv(outfile, index=False)\n",
    "        \n",
    "    for num, (key, val) in enumerate(trees.items()):\n",
    "        if True:\n",
    "            keep = (val) & (leaves)\n",
    "            outfile = os.path.join(_data, name, 'lia', 'junqi', 'heighta_%s.csv' %(key))\n",
    "            df[['z']][keep].to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `\u001dLeaf Area Density` (LAD) estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in trees.items():\n",
    "\n",
    "    keep = (val)\n",
    "    print(key, np.sum(keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample = 0.005\n",
    "voxel_size = 0.15\n",
    "# to check everything looks fine\n",
    "show = False\n",
    "sample = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "POINTS = loads.DF2array(df[['x', 'y', 'z']])\n",
    "SENSORS = loads.DF2array(df[['xs', 'ys', 'zs']])\n",
    "\n",
    "def get_rays(downsample, voxel_size, sample=None, show=False):\n",
    "\n",
    "    if downsample is not None:\n",
    "\n",
    "        resdir = os.path.join(_data, name, 'lad_%s' %(str(downsample)))\n",
    "        if not os.path.exists(resdir):\n",
    "            os.makedirs(resdir)\n",
    "\n",
    "        outdir = os.path.join(resdir, 'inds.npy')\n",
    "        if os.path.exists(outdir):\n",
    "            print('inds file already exists for donwnsample of %.3f at %s' %(downsample, outdir))\n",
    "\n",
    "            inds = np.load(outdir)\n",
    "\n",
    "            points = POINTS[inds]\n",
    "            sensors = SENSORS[inds]\n",
    "\n",
    "        else:\n",
    "\n",
    "            print('inds not been created yet for donwnsample of %.3f' %(downsample))\n",
    "            idx = np.random.randint(0, len(df), int(len(df) * downsample))\n",
    "            inds = np.zeros(len(df), dtype=bool)\n",
    "            inds[idx] = True\n",
    "\n",
    "            points = POINTS[inds]\n",
    "            sensors = SENSORS[inds]\n",
    "\n",
    "            np.save(outdir, inds)\n",
    "\n",
    "    else:\n",
    "\n",
    "        resdir = os.path.join(_data, name, 'lad')\n",
    "        if not os.path.exists(resdir):\n",
    "            os.makedirs(resdir)\n",
    "\n",
    "    if sample is not None:\n",
    "\n",
    "        idx = np.random.randint(0, len(df), int(sample))\n",
    "        points = POINTS[idx]\n",
    "        sensors = SENSORS[idx]\n",
    "\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        inPR = (val) & (leaves) & (inds)\n",
    "        pointsPR = POINTS[inPR]\n",
    "        m3s = rayt.main(points, sensors, pointsPR, voxel_size, resdir, key, show=show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runall(downsample, voxel_size, kbins=None):\n",
    "    \n",
    "    if downsample is not None:\n",
    "        resdir = os.path.join(_data, name, 'lad_%s' %(str(downsample)))\n",
    "        inds_file = os.path.join(resdir, 'inds.npy')\n",
    "        inds = np.load(inds_file)\n",
    "        print('downsample:', downsample)\n",
    "    else:\n",
    "        inds = np.ones(len(df), dtype=bool)\n",
    "        resdir = os.path.join(_data, name, 'lad')\n",
    "\n",
    "    isfigures = os.path.join(resdir, 'figures')\n",
    "    if not os.path.exists(isfigures):\n",
    "        os.makedirs(isfigures)\n",
    "\n",
    "    print('voxel_size:', voxel_size)\n",
    "\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        inPR = (val) & (leaves) & (inds)\n",
    "        pointsPR = POINTS[inPR]\n",
    "        sensorsPR = SENSORS[inPR]\n",
    "\n",
    "        m3att = lad.compute_attributes(pointsPR, resdir, voxel_size, key)\n",
    "\n",
    "        # _,_,_, m3scount = lad.density_counts(pointsPR, voxel_size)\n",
    "\n",
    "        # get in down sample boolean array for LPC size\n",
    "        inds_ = inds[(val) & (leaves)]\n",
    "        lias, ws = lad.downsample_lia(name, key, inds_)\n",
    "        voxk = lad.get_voxk(pointsPR, voxel_size)\n",
    "        bia = lad.get_bia(pointsPR, sensorsPR)\n",
    "        # meshfile = lad.get_meshfile(name)\n",
    "\n",
    "        figext = '%s_%s' %(key, str(voxel_size))\n",
    "        # figext = None\n",
    "        alphas_k = lad.alpha_k(bia, voxk, lias, ws, resdir, meshfile=None, figext=figext, \n",
    "                                klia=False, use_true_lia=False)\n",
    "\n",
    "        kmax = m3att.shape[2]\n",
    "        if kbins is None:\n",
    "            kbins = int(kmax/15)\n",
    "        print(kbins)\n",
    "\n",
    "        # Attribute 2 counts per voxel\n",
    "        # outdir_count = os.path.join(resdir, 'm3count_%s_%s.npy' %(key, str(voxel_size)))\n",
    "        # m3pcount = np.load(outdir_count)\n",
    "        # print('******* outdir_count', outdir_count)\n",
    "\n",
    "        \n",
    "        # lads_min = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,2], 1)\n",
    "        # lads_max = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,4], 1)\n",
    "        lads_mid = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,6], alpha2=1)\n",
    "        # lads_mid_w = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,6], 1, m3scount=m3scount, m3pcount=m3pcount)\n",
    "        # lads_mid_counts = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,6], 1, m3scount=m3scount, usecounts=True, m3pcount=m3pcount)\n",
    "\n",
    "        lads_0 = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,6]*0+1, alpha2=1)\n",
    "        # lads_mesh = lad.get_LADS_mesh(meshfile, voxel_size, kbins, kmax)\n",
    "\n",
    "        lads = {'Correction Mean':lads_mid, 'No Correction':lads_0} #, 'Correction counts':lads_mid_counts}\n",
    "        # lads = {'Truth':lads_mesh, 'Correction Mean':lads_mid, 'No Correction':lads_0}\n",
    "        clai = lad.get_clai(m3att, alphas_k)\n",
    "        attributes_file = os.path.join(resdir, 'm3s_%s_%s.npy' %(key, str(voxel_size)))\n",
    "        if os.path.isfile(attributes_file):\n",
    "            RT = 'Y'\n",
    "        else:\n",
    "            RT = 'N'\n",
    "            \n",
    "        text = {'tree':key, 'VS':voxel_size, 'DS':downsample, 'RT':RT, 'CLAI':np.round(clai, 3)}\n",
    "        txt = []\n",
    "        for key, val in text.items():\n",
    "            txt.append('%s=%s \\n' %(key, str(val)))\n",
    "        text = (' ').join(txt)\n",
    "\n",
    "        savefig = os.path.join(resdir, 'figures','LAD_%s.png' %(figext))\n",
    "        figures.plot_lads(lads, text, savefig=savefig)\n",
    "\n",
    "    # return m3pcounts, m3scount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample = 0.01\n",
    "voxel_size = 0.1\n",
    "# to check everything looks fine\n",
    "show = False\n",
    "sample = None\n",
    "\n",
    "get_rays(downsample, voxel_size, sample, show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for DS in [0.005, 0.01, 0.05, 0.1, 0.2]:\n",
    "\n",
    "    get_rays(downsample=DS, voxel_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for downsample in [0.005, 0.01, 0.05, 0.1, 0.2]:\n",
    "    for voxel_size in [0.1]:\n",
    "\n",
    "        if downsample is not None:\n",
    "            resdir = os.path.join(_data, name, 'lad_%s' %(str(downsample)))\n",
    "            inds_file = os.path.join(resdir, 'inds.npy')\n",
    "            inds = np.load(inds_file)\n",
    "            print('downsample:', downsample)\n",
    "        else:\n",
    "            inds = np.ones(len(df), dtype=bool)\n",
    "            resdir = os.path.join(_data, name, 'lad')\n",
    "\n",
    "        isfigures = os.path.join(resdir, 'figures')\n",
    "        if not os.path.exists(isfigures):\n",
    "            os.makedirs(isfigures)\n",
    "\n",
    "        print('voxel_size:', voxel_size)\n",
    "\n",
    "        for key, val in trees.items():\n",
    "\n",
    "            inPR = (val) & (leaves) & (inds)\n",
    "            pointsPR = POINTS[inPR]\n",
    "            sensorsPR = SENSORS[inPR]\n",
    "\n",
    "            m3att = lad.compute_attributes(pointsPR, resdir, voxel_size, key)\n",
    "\n",
    "            results.append([downsample, voxel_size, (m3att == 1).sum(), (m3att == 2).sum(), (m3att == 3).sum()])\n",
    "\n",
    "results = np.array(results)\n",
    "\n",
    "total = np.array(np.sum(results[:,2:5], axis=1))\n",
    "nI0 = results[:,2] / total\n",
    "nP0 = results[:,3] / total\n",
    "n00 = results[:,4] / total\n",
    "\n",
    "nI = results[:,2]\n",
    "nP = results[:,3]\n",
    "n0 = results[:,4]\n",
    "\n",
    "\n",
    "fig, (a0, a1) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [2, 1]}, figsize=(10,22))\n",
    "colors = plt.cm.jet(np.linspace(0,1,5))\n",
    "\n",
    "for num, voxel_size in enumerate([0.1]):\n",
    "\n",
    "    keep = (results[:,1] == voxel_size)\n",
    "    downsample = results[:,0][keep]\n",
    "    a0.plot(downsample*100, nP0[keep], marker='*', color=colors[num], label='%s' %(voxel_size))\n",
    "    a0.plot(downsample*100, nI0[keep], marker='*', ls='--', color=colors[num])\n",
    "    a0.plot(downsample*100, n00[keep], marker='*', ls=':', color=colors[num])\n",
    "    \n",
    "    a1.plot(downsample*100, nI[keep]/(nI[keep]+nP[keep]), marker='*', ls='-', color=colors[num])\n",
    "\n",
    "text = '$n_{P}(k)$: Solid \\n $n_{I}(k)$: Dashed \\n $n_{0}(k)$: Dotted'\n",
    "props = dict(boxstyle='round', facecolor='green', alpha=0.3)\n",
    "a0.text(20, 0.5, text, fontsize=14, bbox=props)\n",
    "a0.legend(title='Voxel Size')\n",
    "a0.set_ylabel(r'$N$', size=20)\n",
    "\n",
    "# a1.axhline(0.035, ls='--', c='k', lw=2)\n",
    "a1.set_xlabel(r'Downsample (%)', size=20)\n",
    "a1.set_ylabel(r'$n_{I}/(n_{I}+n_{P})$', size=20)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Cloud Resolution (PCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(POINTS[PCsample])\n",
    "distances, indices = nbrs.kneighbors(POINTS[PCsample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = distances[:, 1]\n",
    "dmin, dmax = np.percentile(dist, (0, 99.7))\n",
    "keep = (dist >= dmin) & (dist <= dmax)\n",
    "dist = dist[keep]\n",
    "mean = np.round(np.mean(dist), 3)\n",
    "median = np.round(np.median(dist), 3)\n",
    "print(dmin, dmax)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "bins = np.linspace(dmin, dmax, 80)\n",
    "plt.hist(dist, bins, density=True)\n",
    "plt.axvline(mean, ls='--', c='k', label='Mean = %.3f' %(mean))\n",
    "plt.axvline(median, ls='--', c='g', label='Median = %.3f' %(median))\n",
    "plt.xlabel('Distance (m)', size=15)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the correct voxel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isinds(resdir, downsample):\n",
    "\n",
    "    outdir = os.path.join(resdir, 'inds.npy')\n",
    "    if os.path.exists(outdir):\n",
    "        print('inds file already exists for donwnsample of %.3f at %s' %(downsample, outdir))\n",
    "\n",
    "        inds = np.load(outdir)\n",
    "\n",
    "        points = POINTS[inds]\n",
    "        sensors = SENSORS[inds]\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('inds not been created yet for donwnsample of %.3f' %(downsample))\n",
    "        idx = np.random.randint(0, len(df), int(len(df) * downsample))\n",
    "        inds = np.zeros(len(df), dtype=bool)\n",
    "        inds[idx] = True\n",
    "\n",
    "        points = POINTS[inds]\n",
    "        sensors = SENSORS[inds]\n",
    "\n",
    "        np.save(outdir, inds)\n",
    "\n",
    "    return inds\n",
    "\n",
    "def restmp(downsample, voxel_size, show=True):\n",
    "\n",
    "    resdir = os.path.join(_data, name, 'lad_%s' %(str(downsample)))\n",
    "    if not os.path.exists(resdir):\n",
    "        os.makedirs(resdir)\n",
    "    inds = isinds(resdir, downsample)\n",
    "\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        inPR = (val) & (leaves) & (inds)\n",
    "        pointsPR = POINTS[inPR]\n",
    "        sensorsPR = SENSORS[inPR]\n",
    "\n",
    "        density_overall, density, counts, m3scount = lad.density_counts(pointsPR, voxel_size)\n",
    "        \n",
    "        # dens_ratio = density / density_overall\n",
    "        # print('Mean density ration: %.2f' %(np.mean(dens_ratio)))\n",
    "        # print('Median density ration: %.2f' %(np.median(dens_ratio)))\n",
    "\n",
    "        if show:\n",
    "\n",
    "            fig = plt.figure(figsize=(10,6))\n",
    "            plt.hist(counts, 25, align='left')\n",
    "            plt.axvline(np.mean(counts), color='k', label='Mean counts = %.2f' %(np.mean(counts)))\n",
    "            plt.xlabel(r'$n_{i}$', size=20)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "    return np.mean(counts)\n",
    "\n",
    "\n",
    "def ds2vs_first(DS, PCR):\n",
    "\n",
    "    N = np.cbrt(1/DS)\n",
    "    VS = N * PCR\n",
    "    \n",
    "    return VS\n",
    "\n",
    "def ds2vs(downsample, points, mean_counts=0, step=0.01, bounds=(1.25, 1.3)):\n",
    "\n",
    "    # nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(points)\n",
    "    # distances, indices = nbrs.kneighbors(points)\n",
    "\n",
    "    minb, maxb = bounds\n",
    "\n",
    "    # dist = distances[:, 1]\n",
    "    # dmin, dmax = np.percentile(dist, (0, 99.7))\n",
    "    # keep = (dist >= dmin) & (dist <= dmax)\n",
    "    # dist = dist[keep]\n",
    "    # PCR = np.round(np.mean(dist), 4)\n",
    "    # print('PCR first guess: %.3f' %(PCR))\n",
    "    PCR = 0.01\n",
    "\n",
    "    # first guess for voxel size\n",
    "    voxel_size = ds2vs_first(downsample, PCR)\n",
    "\n",
    "    resdir = os.path.join(_data, name, 'lad_%s' %(str(downsample)))\n",
    "    if not os.path.exists(resdir):\n",
    "        os.makedirs(resdir)\n",
    "    inds = isinds(resdir, downsample)\n",
    "\n",
    "    for key, val in trees.items():\n",
    "\n",
    "        inPR = (val) & (leaves) & (inds)\n",
    "        pointsPR = POINTS[inPR]\n",
    "\n",
    "        j = 0\n",
    "\n",
    "        while (mean_counts < minb) or (mean_counts > maxb):\n",
    "\n",
    "            # mean_counts = restmp(downsample, voxel_size, show=False)\n",
    "            density_overall, density, counts, m3scount = lad.density_counts(pointsPR, voxel_size)\n",
    "            mean_counts = np.mean(counts)\n",
    "            \n",
    "            print(mean_counts, voxel_size, step)\n",
    "\n",
    "            if mean_counts < minb:\n",
    "                voxel_size += step\n",
    "\n",
    "            elif mean_counts > maxb:\n",
    "                voxel_size -= step\n",
    "\n",
    "            if np.abs(mean_counts - (maxb + minb)/2) < 0.1:\n",
    "                step /= 2\n",
    "\n",
    "    return voxel_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inPR = (trees['tree_0']) & (leaves)\n",
    "voxels = {}\n",
    "\n",
    "for DS in [0.01, 0.1]:\n",
    "\n",
    "    VS = ds2vs(DS, POINTS[inPR], mean_counts=0, step=0.02, bounds=(1.4, 1.45))\n",
    "    VS = np.round(VS, 3)\n",
    "    voxels[DS] = VS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(100*np.array(list(voxels.keys())), np.array(list(voxels.values())), marker='o')\n",
    "plt.xlabel('Downsampling (%)', size=18)\n",
    "plt.ylabel('Voxel Size', size=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for DS in [0.01, 0.1]:\n",
    "\n",
    "    VS = voxels[DS]\n",
    "    print(DS, VS)\n",
    "\n",
    "    runall(downsample=DS, voxel_size=VS, kbins=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute LAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restmp(downsample=0.05, voxel_size=0.051, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for DS in [0.03, 0.05, 0.1]:\n",
    "\n",
    "    VS = voxels[DS]\n",
    "    print(DS, VS)\n",
    "    get_rays(DS, VS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for DS in [0.01, 0.05]:\n",
    "\n",
    "    VS = voxels[DS]\n",
    "    print(DS, VS)\n",
    "\n",
    "    runall(downsample=DS, voxel_size=VS, kbins=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POINTS = loads.DF2array(df[['x', 'y', 'z']])\n",
    "# SENSORS = loads.DF2array(df[['xs', 'ys', 'zs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = PCsample & (las.z < 0.8)\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.scatter(np.array(las.x)[keep][::1], np.array(las.z)[keep][::1], s=0.04, c='k')\n",
    "plt.axhline(0.2, lw=1, c='k')\n",
    "\n",
    "# res, bcmask = loads.remove_outliers(np.array(las.y)[keep], np.array(las.z)[keep], nbins=100, bounds=(0, 90))\n",
    "# below[keep] |= ~bcmask\n",
    "\n",
    "# plt.ylim(-1,4)\n",
    "\n",
    "plt.xlabel(r'$x$', size=20)\n",
    "plt.ylabel(r'$z$', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = PCsample & (las.z < 0)\n",
    "Ntot = keep.sum()\n",
    "\n",
    "db = DBSCAN(eps=0.3).fit(points[keep])\n",
    "# db = KMeans(n_clusters = 8, init='k-means++').fit(points[keep])\n",
    "\n",
    "labels = {}\n",
    "\n",
    "for i in set(db.labels_):\n",
    "    mask = db.labels_ == i\n",
    "    perc = 100*mask.sum()/Ntot\n",
    "    if perc > 0:\n",
    "        print(i, perc)\n",
    "        labels[i] = mask\n",
    "\n",
    "N = len(list(labels.keys()))\n",
    "\n",
    "# plot the two point clouds\n",
    "coltmp = plt.cm.jet(np.linspace(0,1,N))[:,0:3]\n",
    "\n",
    "pointslist = [points[keep][val] for val in labels.values()]\n",
    "colours = [list(i) for i in coltmp]\n",
    "loads.showPCDS(pointslist, colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8\n",
    "keep = PCsample & (las.z < 0)\n",
    "pcd = loads.points2pcd(POINTS[keep], colors=[1,0,0])\n",
    "downpcd = pcd.voxel_down_sample(voxel_size=0.05)\n",
    "print(f\"alpha={alpha:.3f}\")\n",
    "mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(downpcd, alpha)\n",
    "mesh.compute_vertex_normals()\n",
    "# pcd = loads.points2pcd(POINTS[keep], colors=[1,0,0])\n",
    "# downpcd = pcd.voxel_down_sample(voxel_size=0.05)\n",
    "o3d.visualization.draw_geometries([downpcd, mesh.paint_uniform_color([0.5, 0.3, 0.1])], mesh_show_back_face=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('filter with average with 1 iteration')\n",
    "mesh_out = mesh.filter_smooth_simple(number_of_iterations=2)\n",
    "mesh_out.compute_vertex_normals()\n",
    "print(mesh)\n",
    "vertices = np.asarray(mesh_out.vertices)\n",
    "pcd = loads.points2pcd(vertices, colors=[1,0,0])\n",
    "mesh_name = os.path.join(_data, name, 'dtm_mesh.obj')\n",
    "o3d.io.write_triangle_mesh(mesh_name, mesh_out)\n",
    "o3d.visualization.draw_geometries([pcd, mesh_out], mesh_show_back_face=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(_data,'DTM_vertices.csv'), vertices, fmt=\"%.8f\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-Do\n",
    "\n",
    "1) Fix algorithm to find `voxel size` from `downsampling`. It currently seems to work for the toy kiwifruit tree it isn't for the real data. Try:\n",
    "   * Check that the algorithm realy work by computing several `LAD`s for different `downsampling` values using the toy model.\n",
    "   * Remove outliers of foliage point cloud `FPC` as these might be adding noise to the mean of points per voxel. Try cliping or with a built-in `Open3D` function.\n",
    "2) Improve `ray tracing` algorithm:\n",
    "   * find a way to reduce the main sample i.e. `POINTS` and `SENSORS` to keep only the rays that pass trhough the plant region `PR`. It might be not that easy as many other process are involved.\n",
    "3) Once `LAD` algorithm works. Usea the leaf inclination angles (`LIA`) and the leaf area index (`LAI`) as input parameters to built a realistic model of the kiwifruit trees. One way to do this is using `Blensor` software. Here, we can create a Python script to create the kiwifruit trees with the option of change some of the tree features such as the leaf sizes and leaf angles. Then, in a recursive algorithm, modify these values until we get the same `LIA` and `LAI` distributions from the real LiDAR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = len(df)\n",
    "\n",
    "for DS in [0.005, 0.01, 0.05, 0.1, 0.2, 0.4]:\n",
    "\n",
    "    idx = np.random.randint(0, len(df), int(len(df) * DS))\n",
    "\n",
    "    print(DS, len(idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "760a6cd4159ac8b99590d0ad7ba9faed7c379184a996bf44e62e475912739812"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('plant-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
