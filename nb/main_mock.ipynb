{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "import numpy as np\n",
    "import os, sys, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "from scipy.stats import chisquare\n",
    "import pandas as pd\n",
    "import pyrr\n",
    "from tqdm import tqdm\n",
    "\n",
    "basedir = os.path.dirname(os.getcwd())\n",
    "_py = os.path.join(basedir, 'py')\n",
    "_data = os.path.join(basedir, 'data')\n",
    "_images = os.path.join(basedir, 'images')\n",
    "\n",
    "sys.path.insert(1, _py)\n",
    "import loads\n",
    "import lia\n",
    "import ray as rayt\n",
    "# import lad\n",
    "import figures\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib qt\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Params init\n",
    "\n",
    "Initialize parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "mockname = 'test'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare data\n",
    "\n",
    "Convert Blensor output txt files that have fake numpy extension to real npy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "loads.numpy2npy(mockname)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next wee create the module to segmentate trees. This will be tuned acordingly for each data set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def segtree(df, show=False):\n",
    "\n",
    "    trees = {}\n",
    "\n",
    "    if show:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # centres\n",
    "    x, y = [0], [0]\n",
    "    num = 0\n",
    "    dx, dy = 5, 5\n",
    "\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            \n",
    "            keep = np.ones(len(df['x']), dtype=bool)\n",
    "            keep &= (df['x'] < i+dx) & (df['x'] > i-dx)\n",
    "            keep &= (df['y'] < j+dy) & (df['y'] > j-dy)\n",
    "\n",
    "            trees['tree_%s' %(str(num))] = keep\n",
    "            \n",
    "            if show:\n",
    "                plt.scatter(df['x'][leaves & keep], df['y'][leaves & keep], s=0.5, label=num)\n",
    "                        \n",
    "            num += 1\n",
    "\n",
    "    if show:\n",
    "        plt.legend()\n",
    "    \n",
    "    return trees\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# load data into a pandas data frame\n",
    "df = loads.npy2pandas(mockname)\n",
    "# extract leaves. Boolean array output\n",
    "leaves = loads.extract_leaves(df, show=False)\n",
    "# extract trees. Dictionary with boolean arrays output\n",
    "trees = segtree(df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "s0600000.npy (22500, 16) (22500, 3)\n",
      "s0700000.npy (22500, 16) (22500, 3)\n",
      "s0100000.npy (22500, 16) (22500, 3)\n",
      "s0500000.npy (22500, 16) (22500, 3)\n",
      "s0400000.npy (22500, 16) (22500, 3)\n",
      "s0200000.npy (22500, 16) (22500, 3)\n",
      "s0300000.npy (22500, 16) (22500, 3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# show the point cloud from leaves of firs tree only\n",
    "keep = (trees['tree_0']) & (leaves)\n",
    "loads.showPCfromDF(df[keep])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute the `Leaf Inclination Angle` (LIA) for each tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "for key, val in trees.items():\n",
    "\n",
    "    keep = (val) & (leaves)\n",
    "    df_ = df[['x', 'y', 'z']][keep]\n",
    "    points = loads.DF2array(df_)\n",
    "    res = lia.bestfit_pars_la(points, mockname, treename=key, weigths=True)\n",
    "    lia.best_fit_pars_plot(res, key, mockname)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "voxel_size_w 0.0001 DONE...\n",
      "voxel_size_w 0.001 DONE...\n",
      "voxel_size_w 0.01 DONE...\n",
      "voxel_size_w 0.1 DONE...\n",
      "voxel_size_w 1 DONE...\n",
      "voxel_size_w BESTFIT:\t 0.01\n",
      "kd3_sr 0.001 DONE...\n",
      "kd3_sr 0.01 DONE...\n",
      "kd3_sr 0.1 DONE...\n",
      "kd3_sr 1.0 DONE...\n",
      "kd3_sr BESTFIT:\t 1.0\n",
      "max_nn 3 DONE...\n",
      "max_nn 5 DONE...\n",
      "max_nn 10 DONE...\n",
      "max_nn 20 DONE...\n",
      "max_nn 50 DONE...\n",
      "max_nn 100 DONE...\n",
      "max_nn BESTFIT:\t 5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# load bestfit results\n",
    "for key, val in trees.items():\n",
    "\n",
    "    keep = (val) & (leaves)\n",
    "    df_ = df[['x', 'y', 'z']][keep]\n",
    "    points = loads.DF2array(df_)\n",
    "\n",
    "    bestfit_file = os.path.join(_data, mockname, 'lia', 'bestfit_%s.npy' %(key))\n",
    "    res = np.load(bestfit_file, allow_pickle=True)\n",
    "    res = res.tolist()\n",
    "\n",
    "    text = 'leaf area=%.2f \\n %s=%.4f \\n %s=%.4f \\n %s=%.4f ' %(res['leafsize'], 'voxel_size_w', res['voxel_size_w_bestfit'],'kd3_sr', res['kd3_sr_bestfit'],'max_nn', res['max_nn_bestfit'])\n",
    "    print(text)\n",
    "\n",
    "    chi2 = lia.leaf_angle(points, mockname, key, res['voxel_size_w_bestfit'], \n",
    "                            res['kd3_sr_bestfit'], res['max_nn_bestfit'], save=True,\n",
    "                                savefig=True, text=text)\n",
    "    \n",
    "    print(chi2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "leaf area=0.04 \n",
      " voxel_size_w=0.0100 \n",
      " kd3_sr=1.0000 \n",
      " max_nn=5.0000 \n",
      "0.0009380330384670287\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `\u001dLeaf Area Density` (LAD)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "\n",
    "downsample = 0.10\n",
    "voxel_size = 0.15\n",
    "# to check everything looks fine\n",
    "show = False\n",
    "sample = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "\n",
    "POINTS = loads.DF2array(df[['x', 'y', 'z']])\n",
    "SENSORS = loads.DF2array(df[['sx', 'sy', 'sz']])\n",
    "\n",
    "if downsample is not None:\n",
    "\n",
    "    resdir = os.path.join(_data, mockname, 'lad_%s' %(str(downsample)))\n",
    "    if not os.path.exists(resdir):\n",
    "        os.makedirs(resdir)\n",
    "\n",
    "    outdir = os.path.join(resdir, 'inds.npy')\n",
    "    if os.path.exists(outdir):\n",
    "        print('inds file already exists for donwnsample of %.3f at %s' %(downsample, outdir))\n",
    "\n",
    "        inds = np.load(outdir)\n",
    "\n",
    "        points = POINTS[inds]\n",
    "        sensors = SENSORS[inds]\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('inds not been created yet for donwnsample of %.3f' %(downsample))\n",
    "        idx = np.random.randint(0, len(df), int(len(df) * downsample))\n",
    "        inds = np.zeros(len(df), dtype=bool)\n",
    "        inds[idx] = True\n",
    "\n",
    "        points = POINTS[inds]\n",
    "        sensors = SENSORS[inds]\n",
    "\n",
    "        np.save(outdir, inds)\n",
    "\n",
    "else:\n",
    "\n",
    "    resdir = os.path.join(_data, mockname, 'lad')\n",
    "    if not os.path.exists(resdir):\n",
    "        os.makedirs(resdir)\n",
    "\n",
    "if sample is not None:\n",
    "\n",
    "    idx = np.random.randint(0, len(df), int(sample))\n",
    "    points = POINTS[idx]\n",
    "    sensors = SENSORS[idx]\n",
    "\n",
    "for key, val in trees.items():\n",
    "\n",
    "    inPR = (val) & (leaves) & (inds)\n",
    "    pointsPR = POINTS[inPR]\n",
    "    m3s, m3count= rayt.main(points, sensors, pointsPR, voxel_size, resdir, key, show=show)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "inds file already exists for donwnsample of 0.100 at /Users/omar/projects/planttech/data/test/lad_0.1/inds.npy\n",
      "max --> [62, 61, 39]\n",
      "min --> [0, 0, 0]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "14986it [03:43, 66.95it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tot vox: \t 156240\n",
      "voxels hitted: \t 135168\n",
      "Percentage of voxels hitted by beam: 0.87\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "downsample = 0.10\n",
    "voxel_size = 0.15"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "if downsample is not None:\n",
    "    inds_file = os.path.join(resdir, 'inds.npy')\n",
    "    inds = np.load(inds_file)\n",
    "    resdir = os.path.join(_data, mockname, 'lad_%s' %(str(downsample)))\n",
    "    print('downsample:', downsample)\n",
    "else:\n",
    "    inds = np.ones(len(df), dtype=bool)\n",
    "    resdir = os.path.join(_data, mockname, 'lad')\n",
    "\n",
    "isfigures = os.path.join(resdir, 'figures')\n",
    "if not os.path.exists(isfigures):\n",
    "    os.makedirs(isfigures)\n",
    "\n",
    "print('voxel_size:', voxel_size)\n",
    "\n",
    "for key, val in trees.items():\n",
    "\n",
    "    inPR = (val) & (leaves) & (inds)\n",
    "    pointsPR = POINTS[inPR]\n",
    "    sensorsPR = SENSORS[inPR]\n",
    "\n",
    "    m3att = lad.compute_attributes(pointsPR, resdir, voxel_size, key)\n",
    "    # get in down sample boolean array for LPC size\n",
    "    inds_ = inds[(val) & (leaves)]\n",
    "    lias, ws = lad.downsample_lia(mockname, key, inds_)\n",
    "    voxk = lad.get_voxk(pointsPR, voxel_size)\n",
    "    bia = lad.get_bia(pointsPR, sensorsPR)\n",
    "    meshfile = lad.get_meshfile(mockname)\n",
    "\n",
    "    figext = '%s_%s' %(key, str(voxel_size))\n",
    "    # figext = None\n",
    "    alphas_k = lad.alpha_k(bia, voxk, lias, ws, resdir, meshfile, figext=figext, \n",
    "                            klia=False, use_true_lia=True)\n",
    "\n",
    "    kmax = m3att.shape[2]\n",
    "    kbins = int(kmax/15)\n",
    "    print(kbins)\n",
    "    \n",
    "    # lads_min = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,2], 1)\n",
    "    # lads_max = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,4], 1)\n",
    "    lads_mid = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,6], 1)\n",
    "    lads_0 = lad.get_LADS(m3att, voxel_size, kbins, alphas_k[:,6]*0+1, 1.0)\n",
    "    lads_mesh = lad.get_LADS_mesh(meshfile, voxel_size, kbins, kmax)\n",
    "\n",
    "    lads = {'Truth':lads_mesh, 'Correction Mean':lads_mid, 'No Correction':lads_0}\n",
    "\n",
    "    savefig = os.path.join(resdir, 'figures','LAD_%s.png' %(figext))\n",
    "    figures.plot_lads(lads, savefig=savefig)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "downsample: 0.1\n",
      "voxel_size: 0.15\n",
      "max --> [62, 61, 39]\n",
      "min --> [0, 0, 0]\n",
      "foliage voxel dimensions: \t (63, 62, 40)\n",
      "ray tracker voxel dimensions: \t (63, 62, 40)\n",
      "Number of voxels ocupied by points cloud: \t 4494\n",
      "Number of voxels ocupied by beam points cloud: \t 135168\n",
      "Total number of voxels in plant regions: \t 156240\n",
      "Number of voxels with attribute 1: \t 4494\n",
      "Number of voxels with attribute 2: \t 130674\n",
      "Number of voxels with attribute 3: \t 21072\n",
      "2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DEV ZONE..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d949bede1d2d28195f90229403804ad1488824f6ca2cb71c0e4905baa8d9072d"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('plant-env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}